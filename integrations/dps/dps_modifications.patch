diff --git a/guided_diffusion/condition_methods.py b/guided_diffusion/condition_methods.py
index 5453884..dc1de7a 100644
--- a/guided_diffusion/condition_methods.py
+++ b/guided_diffusion/condition_methods.py
@@ -16,21 +16,21 @@ def get_conditioning_method(name: str, operator, noiser, **kwargs):
         raise NameError(f"Name {name} is not defined!")
     return __CONDITIONING_METHOD__[name](operator=operator, noiser=noiser, **kwargs)
 
-    
+
 class ConditioningMethod(ABC):
     def __init__(self, operator, noiser, **kwargs):
         self.operator = operator
         self.noiser = noiser
-    
+
     def project(self, data, noisy_measurement, **kwargs):
         return self.operator.project(data=data, measurement=noisy_measurement, **kwargs)
-    
+
     def grad_and_value(self, x_prev, x_0_hat, measurement, **kwargs):
         if self.noiser.__name__ == 'gaussian':
             difference = measurement - self.operator.forward(x_0_hat, **kwargs)
             norm = torch.linalg.norm(difference)
             norm_grad = torch.autograd.grad(outputs=norm, inputs=x_prev)[0]
-        
+
         elif self.noiser.__name__ == 'poisson':
             Ax = self.operator.forward(x_0_hat, **kwargs)
             difference = measurement-Ax
@@ -40,19 +40,67 @@ class ConditioningMethod(ABC):
 
         else:
             raise NotImplementedError
-             
+
+        return norm_grad, norm
+
+    @abstractmethod
+    def conditioning(self, x_t, measurement, noisy_measurement=None, **kwargs):
+        pass
+
+class DISSConditioningMethod(ABC):
+    def __init__(self, operator, noiser, **kwargs):
+        self.operator = operator
+        self.noiser = noiser
+
+    def project(self, data, noisy_measurement, **kwargs):
+        return self.operator.project(data=data, measurement=noisy_measurement, **kwargs)
+
+    def grad_and_value(self, x_prev, x_0_hat, measurement, **kwargs):
+        gradient_rewards = kwargs['gradient_rewards']
+        if self.noiser.__name__ == 'gaussian':
+            difference = measurement - self.operator.forward(x_0_hat, **kwargs)
+            per_sample = difference.reshape(difference.shape[0], -1).norm(dim=1)
+            norm = per_sample.sum()
+
+            if gradient_rewards:  # non-empty list
+                # 1) collect each ∂Rᵢ/∂x₀̂ scaled by its own αᵢ
+                combined_grad_x0 = sum(
+                    gr.scale * gr.get_gradients(x_0_hat)
+                    for gr in gradient_rewards
+                )
+
+                # 2) one-shot backprop: norm + all Rᵢ
+                norm_grad, = torch.autograd.grad(
+                    outputs=(norm, x_0_hat),
+                    inputs=x_prev,
+                    grad_outputs=(torch.ones_like(norm), combined_grad_x0),
+                )
+            else:
+                # no reward grads, just the norm term
+                norm_grad = torch.autograd.grad(outputs=norm, inputs=x_prev)[0]
+
+        elif self.noiser.__name__ == 'poisson':
+            Ax = self.operator.forward(x_0_hat, **kwargs)
+            difference = measurement - Ax
+            norm = torch.linalg.norm(difference) / measurement.abs()
+            norm = norm.mean()
+            norm_grad = torch.autograd.grad(outputs=norm, inputs=x_prev)[0]
+
+        else:
+            raise NotImplementedError
+
         return norm_grad, norm
-   
+
     @abstractmethod
     def conditioning(self, x_t, measurement, noisy_measurement=None, **kwargs):
         pass
-    
+
 @register_conditioning_method(name='vanilla')
 class Identity(ConditioningMethod):
     # just pass the input without conditioning
     def conditioning(self, x_t):
         return x_t
-    
+
 @register_conditioning_method(name='projection')
 class Projection(ConditioningMethod):
     def conditioning(self, x_t, noisy_measurement, **kwargs):
@@ -65,16 +113,16 @@ class ManifoldConstraintGradient(ConditioningMethod):
     def __init__(self, operator, noiser, **kwargs):
         super().__init__(operator, noiser)
         self.scale = kwargs.get('scale', 1.0)
-        
+
     def conditioning(self, x_prev, x_t, x_0_hat, measurement, noisy_measurement, **kwargs):
         # posterior sampling
         norm_grad, norm = self.grad_and_value(x_prev=x_prev, x_0_hat=x_0_hat, measurement=measurement, **kwargs)
         x_t -= norm_grad * self.scale
-        
+
         # projection
         x_t = self.project(data=x_t, noisy_measurement=noisy_measurement, **kwargs)
         return x_t, norm
-        
+
 @register_conditioning_method(name='ps')
 class PosteriorSampling(ConditioningMethod):
     def __init__(self, operator, noiser, **kwargs):
@@ -85,7 +133,18 @@ class PosteriorSampling(ConditioningMethod):
         norm_grad, norm = self.grad_and_value(x_prev=x_prev, x_0_hat=x_0_hat, measurement=measurement, **kwargs)
         x_t -= norm_grad * self.scale
         return x_t, norm
-        
+
+@register_conditioning_method(name='diss_ps')
+class DISSPosteriorSampling(DISSConditioningMethod):
+    def __init__(self, operator, noiser, **kwargs):
+        super().__init__(operator, noiser)
+        self.scale = kwargs.get('scale', 1.0)
+
+    def conditioning(self, x_prev, x_t, x_0_hat, measurement, **kwargs):
+        norm_grad, norm = self.grad_and_value(x_prev=x_prev, x_0_hat=x_0_hat, measurement=measurement, **kwargs)
+        x_t -= norm_grad * self.scale
+        return x_t, norm
+
 @register_conditioning_method(name='ps+')
 class PosteriorSamplingPlus(ConditioningMethod):
     def __init__(self, operator, noiser, **kwargs):
@@ -100,7 +159,7 @@ class PosteriorSamplingPlus(ConditioningMethod):
             x_0_hat_noise = x_0_hat + 0.05 * torch.rand_like(x_0_hat)
             difference = measurement - self.operator.forward(x_0_hat_noise)
             norm += torch.linalg.norm(difference) / self.num_sampling
-        
+
         norm_grad = torch.autograd.grad(outputs=norm, inputs=x_prev)[0]
         x_t -= norm_grad * self.scale
         return x_t, norm
diff --git a/guided_diffusion/gaussian_diffusion.py b/guided_diffusion/gaussian_diffusion.py
index 862e342..49ee2a9 100644
--- a/guided_diffusion/gaussian_diffusion.py
+++ b/guided_diffusion/gaussian_diffusion.py
@@ -5,6 +5,7 @@ import matplotlib.pyplot as plt
 import numpy as np
 import torch
 from tqdm.auto import tqdm
+from torchvision import transforms
 
 from util.img_utils import clear_color
 from .posterior_mean_variance import get_mean_processor, get_var_processor
@@ -16,7 +17,7 @@ __SAMPLER__ = {}
 def register_sampler(name: str):
     def wrapper(cls):
         if __SAMPLER__.get(name, None):
-            raise NameError(f"Name {name} is already registered!") 
+            raise NameError(f"Name {name} is already registered!")
         __SAMPLER__[name] = cls
         return cls
     return wrapper
@@ -37,19 +38,19 @@ def create_sampler(sampler,
                    clip_denoised,
                    rescale_timesteps,
                    timestep_respacing=""):
-    
+
     sampler = get_sampler(name=sampler)
-    
+
     betas = get_named_beta_schedule(noise_schedule, steps)
     if not timestep_respacing:
         timestep_respacing = [steps]
-         
+
     return sampler(use_timesteps=space_timesteps(steps, timestep_respacing),
                    betas=betas,
                    model_mean_type=model_mean_type,
                    model_var_type=model_var_type,
                    dynamic_threshold=dynamic_threshold,
-                   clip_denoised=clip_denoised, 
+                   clip_denoised=clip_denoised,
                    rescale_timesteps=rescale_timesteps)
 
 
@@ -106,8 +107,8 @@ class GaussianDiffusion:
         self.mean_processor = get_mean_processor(model_mean_type,
                                                  betas=betas,
                                                  dynamic_threshold=dynamic_threshold,
-                                                 clip_denoised=clip_denoised)    
-    
+                                                 clip_denoised=clip_denoised)
+
         self.var_processor = get_var_processor(model_var_type,
                                                betas=betas)
 
@@ -119,7 +120,7 @@ class GaussianDiffusion:
         :param t: the number of diffusion steps (minus 1). Here, 0 means one step.
         :return: A tuple (mean, variance, log_variance), all of x_start's shape.
         """
-        
+
         mean = extract_and_expand(self.sqrt_alphas_cumprod, t, x_start) * x_start
         variance = extract_and_expand(1.0 - self.alphas_cumprod, t, x_start)
         log_variance = extract_and_expand(self.log_one_minus_alphas_cumprod, t, x_start)
@@ -139,7 +140,7 @@ class GaussianDiffusion:
         """
         noise = torch.randn_like(x_start)
         assert noise.shape == x_start.shape
-        
+
         coef1 = extract_and_expand(self.sqrt_alphas_cumprod, t, x_start)
         coef2 = extract_and_expand(self.sqrt_one_minus_alphas_cumprod, t, x_start)
 
@@ -173,51 +174,58 @@ class GaussianDiffusion:
                       measurement,
                       measurement_cond_fn,
                       record,
-                      save_root):
+                      save_root,
+                      **kwargs):
         """
         The function used for sampling from noise.
-        """ 
+        """
         img = x_start
         device = x_start.device
-
         pbar = tqdm(list(range(self.num_timesteps))[::-1])
+
         for idx in pbar:
-            time = torch.tensor([idx] * img.shape[0], device=device)
-            
+            #time = torch.tensor([idx] * img.shape[0], device=device)
+            time = torch.tensor([idx] * 1, device=device)  # added this line instead of the above line changed
+
             img = img.requires_grad_()
-            out = self.p_sample(x=img, t=time, model=model)
-            
+            if kwargs['search'] is not None:
+                out = self.p_sample(x=img, t=time, model=model, search=kwargs['search'], search_rewards=kwargs['search_rewards'])
+            else:
+                out = self.p_sample(x=img, t=time, model=model)
+
             # Give condition.
             noisy_measurement = self.q_sample(measurement, t=time)
 
             # TODO: how can we handle argument for different condition method?
-            img, distance = measurement_cond_fn(x_t=out['sample'],
-                                      measurement=measurement,
-                                      noisy_measurement=noisy_measurement,
-                                      x_prev=img,
-                                      x_0_hat=out['pred_xstart'])
+            img, distance = measurement_cond_fn(
+                x_t=out['sample'],
+                measurement=measurement,
+                noisy_measurement=noisy_measurement,
+                x_prev=img, x_0_hat=out['pred_xstart'],
+                gradient_rewards=kwargs['gradient_rewards']
+            )
             img = img.detach_()
-           
-            pbar.set_postfix({'distance': distance.item()}, refresh=False)
+
+            pbar.set_postfix({'distance': distance.item() / img.shape[0]}, refresh=False)
             if record:
                 if idx % 10 == 0:
                     file_path = os.path.join(save_root, f"progress/x_{str(idx).zfill(4)}.png")
-                    plt.imsave(file_path, clear_color(img))
+                    plt.imsave(file_path, clear_color(out['pred_xstart'][0].unsqueeze(0)))
 
-        return img       
-        
-    def p_sample(self, model, x, t):
+        return img.clamp(-1, 1)
+
+    def p_sample(self, model, x, t, **kwargs):
         raise NotImplementedError
 
     def p_mean_variance(self, model, x, t):
         model_output = model(x, self._scale_timesteps(t))
-        
+
         # In the case of "learned" variance, model will give twice channels.
         if model_output.shape[1] == 2 * x.shape[1]:
             model_output, model_var_values = torch.split(model_output, x.shape[1], dim=1)
         else:
-            # The name of variable is wrong. 
-            # This will just provide shape information, and 
+            # The name of variable is wrong.
+            # This will just provide shape information, and
             # will not be used for calculating something important in variance.
             model_var_values = model_output
 
@@ -268,7 +276,7 @@ def space_timesteps(num_timesteps, section_counts):
         section_counts = [int(x) for x in section_counts.split(",")]
     elif isinstance(section_counts, int):
         section_counts = [section_counts]
-    
+
     size_per = num_timesteps // len(section_counts)
     extra = num_timesteps % len(section_counts)
     start_idx = 0
@@ -362,10 +370,25 @@ class _WrappedModel:
 
 @register_sampler(name='ddpm')
 class DDPM(SpacedDiffusion):
-    def p_sample(self, model, x, t):
+    def p_sample(self, model, x, t, **kwargs):
         out = self.p_mean_variance(model, x, t)
         sample = out['mean']
 
+        if 'search' in kwargs:
+            search, search_rewards = kwargs['search'], kwargs['search_rewards']
+            step = search.start_step - t.item()
+            if search_rewards and step % search.base == 0 and step > 0:
+                x0hat = out['pred_xstart']
+                #x0_hat = self._ddim_x0(model, x_t=x, t=t, steps=5)
+                rewards = torch.zeros(x0hat.shape[0], device=x0hat.device)
+                for reward in search_rewards:
+                    with torch.no_grad():
+                        rew = reward.get_reward(x0hat)
+                    rewards += rew
+                resampled_idx = search.search(rewards, step)
+                sample, out['pred_xstart'] = sample[resampled_idx], out['pred_xstart'][resampled_idx]
+                print('resampled_indices: ', resampled_idx, flush=True)
+
         noise = torch.randn_like(x)
         if t != 0:  # no noise when t == 0
             sample += torch.exp(0.5 * out['log_variance']) * noise
@@ -377,9 +400,9 @@ class DDPM(SpacedDiffusion):
 class DDIM(SpacedDiffusion):
     def p_sample(self, model, x, t, eta=0.0):
         out = self.p_mean_variance(model, x, t)
-        
+
         eps = self.predict_eps_from_x_start(x, t, out['pred_xstart'])
-        
+
         alpha_bar = extract_and_expand(self.alphas_cumprod, t, x)
         alpha_bar_prev = extract_and_expand(self.alphas_cumprod_prev, t, x)
         sigma = (
@@ -397,7 +420,7 @@ class DDIM(SpacedDiffusion):
         sample = mean_pred
         if t != 0:
             sample += sigma * noise
-        
+
         return {"sample": sample, "pred_xstart": out["pred_xstart"]}
 
     def predict_eps_from_x_start(self, x_t, t, pred_xstart):
@@ -472,7 +495,7 @@ def expand_as(array, target):
         array = torch.from_numpy(array)
     elif isinstance(array, np.float):
         array = torch.tensor([array])
-   
+
     while array.ndim < target.ndim:
         array = array.unsqueeze(-1)
 
diff --git a/guided_diffusion/measurements.py b/guided_diffusion/measurements.py
index fdd6e68..3be1f2f 100644
--- a/guided_diffusion/measurements.py
+++ b/guided_diffusion/measurements.py
@@ -42,7 +42,7 @@ class LinearOperator(ABC):
     def transpose(self, data, **kwargs):
         # calculate A^T * X
         pass
-    
+
     def ortho_project(self, data, **kwargs):
         # calculate (I - A^T * A)X
         return data - self.transpose(self.forward(data, **kwargs), **kwargs)
@@ -56,13 +56,13 @@ class LinearOperator(ABC):
 class DenoiseOperator(LinearOperator):
     def __init__(self, device):
         self.device = device
-    
+
     def forward(self, data):
         return data
 
     def transpose(self, data):
         return data
-    
+
     def ortho_project(self, data):
         return data
 
@@ -99,16 +99,16 @@ class MotionBlurOperator(LinearOperator):
         self.kernel = Kernel(size=(kernel_size, kernel_size), intensity=intensity)
         kernel = torch.tensor(self.kernel.kernelMatrix, dtype=torch.float32)
         self.conv.update_weights(kernel)
-    
+
     def forward(self, data, **kwargs):
-        # A^T * A 
+        # A^T * A
         return self.conv(data)
 
     def transpose(self, data, **kwargs):
         return data
 
     def get_kernel(self):
-        kernel = self.kernel.kernelMatrix.type(torch.float32).to(self.device)
+        kernel = torch.from_numpy(self.kernel.kernelMatrix).type(torch.float32).to(self.device)
         return kernel.view(1, 1, self.kernel_size, self.kernel_size)
 
 
@@ -138,16 +138,16 @@ class InpaintingOperator(LinearOperator):
     '''This operator get pre-defined mask and return masked image.'''
     def __init__(self, device):
         self.device = device
-    
+
     def forward(self, data, **kwargs):
         try:
             return data * kwargs.get('mask', None).to(self.device)
         except:
             raise ValueError("Require mask")
-    
+
     def transpose(self, data, **kwargs):
         return data
-    
+
     def ortho_project(self, data, **kwargs):
         return data - self.forward(data, **kwargs)
 
@@ -158,14 +158,14 @@ class NonLinearOperator(ABC):
         pass
 
     def project(self, data, measurement, **kwargs):
-        return data + measurement - self.forward(data) 
+        return data + measurement - self.forward(data)
 
 @register_operator(name='phase_retrieval')
 class PhaseRetrievalOperator(NonLinearOperator):
     def __init__(self, oversample, device):
         self.pad = int((oversample / 8.0) * 256)
         self.device = device
-        
+
     def forward(self, data, **kwargs):
         padded = F.pad(data, (self.pad, self.pad, self.pad, self.pad))
         amplitude = fft2_m(padded).abs()
@@ -175,8 +175,9 @@ class PhaseRetrievalOperator(NonLinearOperator):
 class NonlinearBlurOperator(NonLinearOperator):
     def __init__(self, opt_yml_path, device):
         self.device = device
-        self.blur_model = self.prepare_nonlinear_blur_model(opt_yml_path)     
-         
+        self.blur_model = self.prepare_nonlinear_blur_model(opt_yml_path)
+        self.rand = torch.randn(1, 512, 2, 2).to(self.device) * 0.001
+
     def prepare_nonlinear_blur_model(self, opt_yml_path):
         '''
         Nonlinear deblur requires external codes (bkse).
@@ -188,12 +189,16 @@ class NonlinearBlurOperator(NonLinearOperator):
             model_path = opt["pretrained"]
         blur_model = KernelWizard(opt)
         blur_model.eval()
-        blur_model.load_state_dict(torch.load(model_path)) 
+        blur_model.load_state_dict(torch.load(model_path))
         blur_model = blur_model.to(self.device)
         return blur_model
-    
+
     def forward(self, data, **kwargs):
-        random_kernel = torch.randn(1, 512, 2, 2).to(self.device) * 1.2
+        B = data.size(0)
+        #random_kernel = torch.randn(1, 512, 2, 2).to(self.device) * 1.2
+        random_kernel = self.rand
+        random_kernel = random_kernel.repeat(B, 1, 1, 1)  # tile across batch
+
         data = (data + 1.0) / 2.0  #[-1, 1] -> [0, 1]
         blurred = self.blur_model.adaptKernel(data, kernel=random_kernel)
         blurred = (blurred * 2.0 - 1.0).clamp(-1, 1) #[0, 1] -> [-1, 1]
@@ -224,7 +229,7 @@ def get_noise(name: str, **kwargs):
 class Noise(ABC):
     def __call__(self, data):
         return self.forward(data)
-    
+
     @abstractmethod
     def forward(self, data):
         pass
@@ -238,7 +243,7 @@ class Clean(Noise):
 class GaussianNoise(Noise):
     def __init__(self, sigma):
         self.sigma = sigma
-    
+
     def forward(self, data):
         return data + torch.randn_like(data, device=data.device) * self.sigma
 
@@ -254,7 +259,7 @@ class PoissonNoise(Noise):
         '''
 
         # TODO: set one version of poisson
-       
+
         # version 3 (stack-overflow)
         import numpy as np
         data = (data + 1.0) / 2.0
@@ -272,7 +277,7 @@ class PoissonNoise(Noise):
         # else:
         #     low_clip = 0
 
-    
+
         # # Determine unique values in iamge & calculate the next power of two
         # vals = torch.Tensor([len(torch.unique(data))])
         # vals = 2 ** torch.ceil(torch.log2(vals))
@@ -286,5 +291,5 @@ class PoissonNoise(Noise):
 
         # if low_clip == -1:
         #     data = data * (old_max + 1.0) - 1.0
-       
+
         # return data.clamp(low_clip, 1.0)
\ No newline at end of file
diff --git a/util/img_utils.py b/util/img_utils.py
index 598c038..209d2d4 100644
--- a/util/img_utils.py
+++ b/util/img_utils.py
@@ -42,12 +42,18 @@ def clear(x):
     return normalize_np(x)
 
 
-def clear_color(x):
+def clear_color(x: torch.Tensor) -> np.ndarray:
     if torch.is_complex(x):
         x = torch.abs(x)
-    x = x.detach().cpu().squeeze().numpy()
-    return normalize_np(np.transpose(x, (1, 2, 0)))
 
+    if x.shape[1] == 3:
+        x = x.detach().cpu().squeeze().numpy()
+        return normalize_np(np.transpose(x, (1, 2, 0)))
+    elif x.shape[1] == 1:
+        x = x.detach().cpu().squeeze().numpy()
+        return normalize_np(x)
+    else:
+        raise NotImplementedError
 
 def normalize_np(img):
     """ Normalize img in arbitrary range to [0, 1] """
@@ -154,7 +160,7 @@ class Folder:
         return self.fold(patch1D)
 
 
-def random_sq_bbox(img, mask_shape, image_size=256, margin=(16, 16)):
+def random_sq_bbox(img, mask_shape, image_size=256, margin=(16, 16), start=None):
     """Generate a random sqaure mask for inpainting
     """
     B, C, H, W = img.shape
@@ -166,6 +172,8 @@ def random_sq_bbox(img, mask_shape, image_size=256, margin=(16, 16)):
     # bb
     t = np.random.randint(margin_height, maxt)
     l = np.random.randint(margin_width, maxl)
+    if start is not None:
+        t, l = start
 
     # make mask
     mask = torch.ones([B, C, H, W], device=img.device)
@@ -198,7 +206,8 @@ class mask_generator:
         mask, t, tl, w, wh = random_sq_bbox(img,
                               mask_shape=(mask_h, mask_w),
                               image_size=self.image_size,
-                              margin=self.margin)
+                              margin=self.margin,
+                              start=(140, 100))
         return mask, t, tl, w, wh
 
     def _retrieve_random(self, img):
