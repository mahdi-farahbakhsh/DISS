2025-06-18 20:25:06,940 [MPGD] >> Device set to cuda:0.
2025-06-18 20:25:15,663 [MPGD] >> Operation: inpainting / Noise: gaussian
2025-06-18 20:25:15,663 [MPGD] >> Conditioning method : mpgd_wo_proj
2025-06-18 20:28:51,415 [MPGD] >> Inference for image 0
/scratch/user/vishnukunde/.conda/envs/mpgd/lib/python3.8/site-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
/scratch/user/vishnukunde/semiblind-dps/DISS/integrations/mpgd/AdaFace/face_alignment/mtcnn_pytorch/src/matlab_cp2tform.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.
To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.
  r, _, _, _ = lstsq(X, U)
/scratch/user/vishnukunde/semiblind-dps/DISS/integrations/mpgd/AdaFace/inference.py:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)
  tensor = torch.tensor([brg_img.transpose(2,0,1)]).float()
Search algorithm: group_recursive
reward grad scale: 1.0
InceptionResnetV1(
  (conv2d_1a): BasicConv2d(
    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)
    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (conv2d_2a): BasicConv2d(
    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (conv2d_2b): BasicConv2d(
    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2d_3b): BasicConv2d(
    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (conv2d_4a): BasicConv2d(
    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (conv2d_4b): BasicConv2d(
    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (repeat_1): Sequential(
    (0): Block35(
      (branch0): BasicConv2d(
        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (branch2): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (1): Block35(
      (branch0): BasicConv2d(
        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (branch2): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (2): Block35(
      (branch0): BasicConv2d(
        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (branch2): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (3): Block35(
      (branch0): BasicConv2d(
        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (branch2): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (4): Block35(
      (branch0): BasicConv2d(
        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (branch2): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
  )
  (mixed_6a): Mixed_6a(
    (branch0): BasicConv2d(
      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (branch1): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (2): BasicConv2d(
        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
    )
    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (repeat_2): Sequential(
    (0): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (1): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (2): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (3): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (4): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (5): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (6): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (7): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (8): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (9): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
  )
  (mixed_7a): Mixed_7a(
    (branch0): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
    )
    (branch1): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
    )
    (branch2): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (2): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
    )
    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (repeat_3): Sequential(
    (0): Block8(
      (branch0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (1): Block8(
      (branch0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (2): Block8(
      (branch0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (3): Block8(
      (branch0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (4): Block8(
      (branch0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
  )
  (block8): Block8(
    (branch0): BasicConv2d(
      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (branch1): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (2): BasicConv2d(
        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
    )
    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
  )
  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)
  (dropout): Dropout(p=0.6, inplace=False)
  (last_linear): Linear(in_features=1792, out_features=512, bias=False)
  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  (logits): Linear(in_features=512, out_features=8631, bias=True)
)
batch size: 8
num particles: 8
n_images: 70
ref_face_img: tensor([[[[ 0.2863,  0.2784,  0.2784,  ...,  0.5529,  0.5608,  0.5608],
          [ 0.2941,  0.2863,  0.2863,  ...,  0.5608,  0.5608,  0.5608],
          [ 0.3020,  0.3020,  0.3020,  ...,  0.5608,  0.5608,  0.5608],
          ...,
          [-0.7333, -0.7333, -0.7333,  ..., -0.0353, -0.0510, -0.0667],
          [-0.7333, -0.7333, -0.7333,  ..., -0.0510, -0.0588, -0.0745],
          [-0.7333, -0.7333, -0.7333,  ..., -0.0510, -0.0667, -0.0745]],

         [[ 0.2863,  0.2863,  0.2863,  ...,  0.6000,  0.6078,  0.6078],
          [ 0.2941,  0.3020,  0.3020,  ...,  0.6078,  0.6078,  0.6078],
          [ 0.3098,  0.3098,  0.3098,  ...,  0.6078,  0.6078,  0.6078],
          ...,
          [-0.7333, -0.7333, -0.7333,  ..., -0.0431, -0.0667, -0.0745],
          [-0.7333, -0.7333, -0.7333,  ..., -0.0588, -0.0667, -0.0824],
          [-0.7333, -0.7333, -0.7333,  ..., -0.0588, -0.0745, -0.0902]],

         [[ 0.3569,  0.3647,  0.3725,  ...,  0.7098,  0.7176,  0.7176],
          [ 0.3725,  0.3804,  0.3882,  ...,  0.7176,  0.7176,  0.7176],
          [ 0.3804,  0.3961,  0.3961,  ...,  0.7176,  0.7176,  0.7176],
          ...,
          [-0.7255, -0.7255, -0.7333,  ..., -0.0196, -0.0353, -0.0510],
          [-0.7255, -0.7333, -0.7333,  ..., -0.0275, -0.0431, -0.0588],
          [-0.7255, -0.7333, -0.7333,  ..., -0.0275, -0.0431, -0.0588]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
Generating deterministic box mask
t, l, h, w: 150 100 64 64
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
  1%|          | 1/100 [00:05<09:29,  5.76s/it, distance=272]  2%|▏         | 2/100 [00:05<04:01,  2.46s/it, distance=202]  3%|▎         | 3/100 [00:06<02:14,  1.39s/it, distance=172]  5%|▌         | 5/100 [00:06<01:02,  1.53it/s, distance=142]  7%|▋         | 7/100 [00:06<00:37,  2.49it/s, distance=118]  9%|▉         | 9/100 [00:06<00:30,  2.97it/s, distance=107] 11%|█         | 11/100 [00:07<00:21,  4.05it/s, distance=101] 13%|█▎        | 13/100 [00:07<00:16,  5.18it/s, distance=91.5] 15%|█▌        | 15/100 [00:07<00:13,  6.31it/s, distance=79.5] 17%|█▋        | 17/100 [00:07<00:15,  5.52it/s, distance=66.7] 19%|█▉        | 19/100 [00:08<00:12,  6.61it/s, distance=61]   21%|██        | 21/100 [00:08<00:10,  7.59it/s, distance=54.8] 23%|██▎       | 23/100 [00:08<00:09,  8.45it/s, distance=49.7] 25%|██▌       | 25/100 [00:08<00:11,  6.57it/s, distance=49.7] 27%|██▋       | 27/100 [00:08<00:09,  7.56it/s, distance=46.1] 29%|██▉       | 29/100 [00:09<00:08,  8.43it/s, distance=44.6] 31%|███       | 31/100 [00:09<00:07,  9.15it/s, distance=41.6] 33%|███▎      | 33/100 [00:09<00:09,  6.81it/s, distance=40.5] 35%|███▌      | 35/100 [00:09<00:08,  7.77it/s, distance=38.8] 37%|███▋      | 37/100 [00:10<00:07,  8.60it/s, distance=37.4] 39%|███▉      | 39/100 [00:10<00:06,  9.30it/s, distance=35.9] 41%|████      | 41/100 [00:10<00:08,  6.89it/s, distance=35.1] 43%|████▎     | 43/100 [00:10<00:07,  7.84it/s, distance=34]   45%|████▌     | 45/100 [00:11<00:06,  8.66it/s, distance=33.2] 47%|████▋     | 47/100 [00:11<00:05,  9.32it/s, distance=32.4] 49%|████▉     | 49/100 [00:11<00:07,  6.95it/s, distance=31.5] 51%|█████     | 51/100 [00:11<00:06,  7.90it/s, distance=31]   53%|█████▎    | 53/100 [00:12<00:05,  8.70it/s, distance=30.5] 55%|█████▌    | 55/100 [00:12<00:04,  9.37it/s, distance=30]   57%|█████▋    | 57/100 [00:12<00:06,  6.96it/s, distance=29.5] 59%|█████▉    | 59/100 [00:12<00:05,  7.91it/s, distance=29.1] 61%|██████    | 61/100 [00:13<00:04,  8.72it/s, distance=28.6] 63%|██████▎   | 63/100 [00:13<00:03,  9.38it/s, distance=28.2] 65%|██████▌   | 65/100 [00:13<00:05,  6.94it/s, distance=27.6] 67%|██████▋   | 67/100 [00:13<00:04,  7.88it/s, distance=27.2] 69%|██████▉   | 69/100 [00:14<00:03,  8.69it/s, distance=26.9] 71%|███████   | 71/100 [00:14<00:03,  9.36it/s, distance=26.5] 73%|███████▎  | 73/100 [00:14<00:03,  6.95it/s, distance=26.2] 75%|███████▌  | 75/100 [00:14<00:03,  7.91it/s, distance=25.8] 77%|███████▋  | 77/100 [00:15<00:02,  8.71it/s, distance=25.4] 79%|███████▉  | 79/100 [00:15<00:02,  9.38it/s, distance=25.1] 81%|████████  | 81/100 [00:15<00:02,  6.94it/s, distance=24.7] 83%|████████▎ | 83/100 [00:15<00:02,  7.88it/s, distance=24.4] 85%|████████▌ | 85/100 [00:16<00:01,  8.69it/s, distance=24]   87%|████████▋ | 87/100 [00:16<00:01,  9.35it/s, distance=23.6] 89%|████████▉ | 89/100 [00:16<00:01,  6.91it/s, distance=23.3] 91%|█████████ | 91/100 [00:16<00:01,  7.86it/s, distance=22.7] 93%|█████████▎| 93/100 [00:17<00:00,  8.67it/s, distance=22.1] 95%|█████████▌| 95/100 [00:17<00:00,  9.34it/s, distance=21.4] 97%|█████████▋| 97/100 [00:17<00:00,  9.88it/s, distance=20.3] 99%|█████████▉| 99/100 [00:17<00:00, 10.30it/s, distance=18.3]100%|██████████| 100/100 [00:17<00:00,  5.66it/s, distance=15.2]
2025-06-18 20:30:17,852 [MPGD] >> Inference for image 1
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -1.9734e+00, -2.0169e+00,
        -5.1200e+08, -1.9841e+00, -2.0034e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9316, -2.0293, -1.7812, -1.9133, -1.8693, -1.8546, -2.0792, -1.8155],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02425099 0.00343961 0.49116849 0.03494571 0.08427958 0.113247
 0.00126607 0.24740255]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5516, -1.7207, -1.6734, -1.7671, -1.7298, -1.5822, -1.6834, -1.6742],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.53687028 0.01824192 0.04694182 0.00720783 0.01520135 0.29091476
 0.03842776 0.04619429]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4633, -1.4513, -1.3767, -1.4890, -1.5873, -1.5435, -1.3099, -1.4705],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03205637 0.0407829  0.18124247 0.01920723 0.00268732 0.00645419
 0.68978455 0.02778496]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2940, -1.2768, -1.1279, -1.2735, -1.4022, -1.1104, -1.2877, -1.3217],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01373099 0.01936088 0.38081965 0.020685   0.00157628 0.54037189
 0.01556256 0.00789275]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9040, -0.9613, -1.0858, -1.0873, -0.9123, -1.0378, -1.0094, -1.0329],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.40300847 0.12800205 0.0106192  0.01029711 0.34091332 0.02772619
 0.04887777 0.03055588]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7173, -0.9203, -0.7546, -0.8454, -0.7458, -0.7758, -0.8048, -0.9149],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.37915574 0.00653603 0.1797967  0.02923933 0.21449651 0.11764391
 0.065844   0.00728778]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7300, -0.7481, -0.7458, -0.7774, -0.6509, -0.7449, -0.6009, -0.7106],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04325178 0.0301033  0.03151853 0.01676114 0.21028103 0.03210059
 0.57220931 0.06377432]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5795, -0.6577, -0.6483, -0.6757, -0.5901, -0.6250, -0.6522, -0.6524],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.30433449 0.06373025 0.0768441  0.04446626 0.24628084 0.12241169
 0.07107511 0.07085726]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5865, -0.6335, -0.6233, -0.6608, -0.6506, -0.5527, -0.6071, -0.5942],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17066282 0.06667718 0.08170096 0.03857926 0.04733875 0.33580609
 0.11302262 0.14621232]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5458, -0.5640, -0.5377, -0.5552, -0.5221, -0.6055, -0.5440, -0.5979],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14269065 0.09932546 0.16807626 0.11841525 0.22962183 0.04330679
 0.14814981 0.05041396]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4741, -0.5031, -0.4986, -0.5134, -0.5058, -0.5095, -0.5053, -0.5125],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.21500324 0.12047425 0.1316241  0.09788457 0.1140629  0.10595359
 0.11517195 0.0998254 ]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.098
key: ssim
value: 0.841
key: lpips
value: 0.144
key: facenet_l2
value: 0.405
key: adaface_l2
value: 0.473
ref_face_img: tensor([[[[ 0.6078,  0.6078,  0.6078,  ...,  0.4275,  0.4196,  0.4196],
          [ 0.6078,  0.6078,  0.6078,  ...,  0.4275,  0.4196,  0.4196],
          [ 0.6078,  0.6157,  0.6157,  ...,  0.4275,  0.4196,  0.4196],
          ...,
          [ 0.5059,  0.4824,  0.4431,  ..., -0.3882, -0.3804, -0.3725],
          [ 0.5059,  0.4824,  0.4431,  ..., -0.4353, -0.4275, -0.4196],
          [ 0.5137,  0.4902,  0.4588,  ..., -0.4745, -0.4667, -0.4588]],

         [[ 0.5843,  0.5922,  0.5922,  ...,  0.4118,  0.4039,  0.4039],
          [ 0.5922,  0.5922,  0.5922,  ...,  0.4118,  0.4039,  0.4039],
          [ 0.5922,  0.6000,  0.5922,  ...,  0.4118,  0.4118,  0.4039],
          ...,
          [ 0.4902,  0.4667,  0.4353,  ..., -0.3882, -0.3804, -0.3725],
          [ 0.4902,  0.4667,  0.4353,  ..., -0.4353, -0.4275, -0.4196],
          [ 0.4902,  0.4667,  0.4431,  ..., -0.4745, -0.4667, -0.4588]],

         [[ 0.6078,  0.6157,  0.6157,  ...,  0.4510,  0.4431,  0.4431],
          [ 0.6078,  0.6157,  0.6157,  ...,  0.4510,  0.4431,  0.4431],
          [ 0.6157,  0.6157,  0.6157,  ...,  0.4510,  0.4431,  0.4431],
          ...,
          [ 0.5137,  0.4902,  0.4510,  ..., -0.3725, -0.3647, -0.3569],
          [ 0.5137,  0.4824,  0.4510,  ..., -0.4196, -0.4118, -0.4039],
          [ 0.5137,  0.4902,  0.4588,  ..., -0.4588, -0.4510, -0.4431]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:37,  2.65it/s, distance=270]  3%|▎         | 3/100 [00:00<00:15,  6.07it/s, distance=163]  5%|▌         | 5/100 [00:00<00:11,  8.00it/s, distance=145]  7%|▋         | 7/100 [00:00<00:10,  9.16it/s, distance=123]  9%|▉         | 9/100 [00:01<00:14,  6.46it/s, distance=111] 11%|█         | 11/100 [00:01<00:11,  7.64it/s, distance=96.5] 13%|█▎        | 13/100 [00:01<00:10,  8.58it/s, distance=87]   15%|█▌        | 15/100 [00:01<00:09,  9.34it/s, distance=80.2] 17%|█▋        | 17/100 [00:02<00:12,  6.88it/s, distance=83.2] 19%|█▉        | 19/100 [00:02<00:10,  7.87it/s, distance=72.6] 21%|██        | 21/100 [00:02<00:09,  8.71it/s, distance=64.4] 23%|██▎       | 23/100 [00:02<00:08,  9.39it/s, distance=60.2] 25%|██▌       | 25/100 [00:03<00:10,  7.01it/s, distance=55.2] 27%|██▋       | 27/100 [00:03<00:09,  7.95it/s, distance=50.7] 29%|██▉       | 29/100 [00:03<00:08,  8.75it/s, distance=48]   31%|███       | 31/100 [00:03<00:07,  9.40it/s, distance=42.9] 33%|███▎      | 33/100 [00:04<00:09,  7.03it/s, distance=40.5] 35%|███▌      | 35/100 [00:04<00:08,  7.96it/s, distance=39.2] 37%|███▋      | 37/100 [00:04<00:07,  8.76it/s, distance=37.5] 39%|███▉      | 39/100 [00:04<00:06,  9.42it/s, distance=36.2] 41%|████      | 41/100 [00:05<00:08,  7.02it/s, distance=33.4] 43%|████▎     | 43/100 [00:05<00:07,  7.97it/s, distance=33.2] 45%|████▌     | 45/100 [00:05<00:06,  8.76it/s, distance=32.5] 47%|████▋     | 47/100 [00:05<00:05,  9.42it/s, distance=31.7] 49%|████▉     | 49/100 [00:06<00:07,  6.96it/s, distance=31.4] 51%|█████     | 51/100 [00:06<00:06,  7.89it/s, distance=30.7] 53%|█████▎    | 53/100 [00:06<00:05,  8.68it/s, distance=30.1] 55%|█████▌    | 55/100 [00:06<00:04,  9.34it/s, distance=29.5] 57%|█████▋    | 57/100 [00:07<00:06,  6.98it/s, distance=28.8] 59%|█████▉    | 59/100 [00:07<00:05,  7.92it/s, distance=28.4] 61%|██████    | 61/100 [00:07<00:04,  8.71it/s, distance=28]   63%|██████▎   | 63/100 [00:07<00:03,  9.37it/s, distance=27.6] 65%|██████▌   | 65/100 [00:08<00:04,  7.01it/s, distance=27.3] 67%|██████▋   | 67/100 [00:08<00:04,  7.94it/s, distance=26.9] 69%|██████▉   | 69/100 [00:08<00:03,  8.74it/s, distance=26.6] 71%|███████   | 71/100 [00:08<00:03,  9.40it/s, distance=26.3] 73%|███████▎  | 73/100 [00:09<00:03,  7.02it/s, distance=25.9] 75%|███████▌  | 75/100 [00:09<00:03,  7.95it/s, distance=25.6] 77%|███████▋  | 77/100 [00:09<00:02,  8.75it/s, distance=25.3] 79%|███████▉  | 79/100 [00:09<00:02,  9.41it/s, distance=24.9] 81%|████████  | 81/100 [00:10<00:02,  7.02it/s, distance=24.6] 83%|████████▎ | 83/100 [00:10<00:02,  7.96it/s, distance=24.2] 85%|████████▌ | 85/100 [00:10<00:01,  8.75it/s, distance=23.8] 87%|████████▋ | 87/100 [00:10<00:01,  9.41it/s, distance=23.5] 89%|████████▉ | 89/100 [00:11<00:01,  7.01it/s, distance=23.1] 91%|█████████ | 91/100 [00:11<00:01,  7.94it/s, distance=22.6] 93%|█████████▎| 93/100 [00:11<00:00,  8.74it/s, distance=22.1] 95%|█████████▌| 95/100 [00:11<00:00,  9.40it/s, distance=21.3] 97%|█████████▋| 97/100 [00:11<00:00,  9.92it/s, distance=20.3] 99%|█████████▉| 99/100 [00:12<00:00, 10.32it/s, distance=18.3]100%|██████████| 100/100 [00:12<00:00,  8.25it/s, distance=15.2]
2025-06-18 20:30:31,270 [MPGD] >> Inference for image 2
reward_name: adaface, curr_reward: tensor([-2.1141e+00, -5.1200e+08, -2.0357e+00, -2.0861e+00, -5.1200e+08,
        -5.1200e+08, -1.9468e+00, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.2238, -2.0375, -2.1645, -2.0632, -2.1291, -2.0145, -2.1350, -2.0259],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00496687 0.20630655 0.01626147 0.12327201 0.03300845 0.32662726
 0.02936266 0.26019472]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5722, -1.4920, -1.5130, -1.5165, -1.5411, -1.6295, -1.6180, -1.7188],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06697229 0.33353307 0.21882824 0.204242   0.12474184 0.02131263
 0.0267964  0.00357352]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3639, -1.3408, -1.3138, -1.3585, -1.2595, -1.3881, -1.3061, -1.1979],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02177637 0.03451923 0.0592647  0.02425525 0.17573566 0.01341253
 0.0691838  0.60185246]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1497, -1.1673, -1.0676, -1.0958, -1.2181, -1.1584, -1.1171, -1.1181],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06802381 0.04783894 0.35151148 0.19982568 0.0173257  0.05708582
 0.13041124 0.12797732]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0485, -0.8699, -0.9364, -0.9588, -0.9720, -0.9081, -0.9896, -1.0301],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01283656 0.45696743 0.12077019 0.07713965 0.05932404 0.21271687
 0.04168384 0.01856142]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9615, -0.8825, -0.9172, -0.8057, -0.8643, -0.8541, -0.9168, -0.8723],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01827303 0.08856713 0.04431879 0.41153845 0.1274566  0.15645664
 0.04460543 0.10878392]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6674, -0.6769, -0.7184, -0.7764, -0.8289, -0.7633, -0.7831, -0.7611],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.36493423 0.30194242 0.13169073 0.04125049 0.0144275  0.05361221
 0.03610331 0.05603912]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5783, -0.5642, -0.5328, -0.5508, -0.6077, -0.5890, -0.5887, -0.6631],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11231215 0.1489366  0.2791622  0.19460006 0.06241811 0.0907489
 0.09123138 0.0205906 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5151, -0.5347, -0.5490, -0.5066, -0.5401, -0.4934, -0.5287, -0.5847],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15310598 0.10338868 0.07776916 0.18141531 0.09292874 0.23657256
 0.11672597 0.0380936 ]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4331, -0.4238, -0.4363, -0.4427, -0.4483, -0.4425, -0.4665, -0.3868],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11668058 0.14048768 0.10939942 0.09634519 0.08600583 0.09668409
 0.05986472 0.29453248]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4026, -0.3927, -0.3574, -0.4093, -0.3937, -0.4351, -0.3761, -0.4103],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10175205 0.12392619 0.25113091 0.08888481 0.12154763 0.05307844
 0.17258102 0.08709895]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.873
key: ssim
value: 0.828
key: lpips
value: 0.132
key: facenet_l2
value: 0.320
key: adaface_l2
value: 0.401
ref_face_img: tensor([[[[ 0.8118,  0.8275,  0.8353,  ...,  0.0353,  0.0431,  0.0431],
          [ 0.8196,  0.8275,  0.8353,  ...,  0.0510,  0.0588,  0.0588],
          [ 0.8196,  0.8353,  0.8431,  ...,  0.0667,  0.0745,  0.0745],
          ...,
          [-0.4196, -0.3725, -0.3098,  ...,  0.0353,  0.1686, -0.0745],
          [-0.4118, -0.3647, -0.3176,  ...,  0.0745,  0.1843,  0.1922],
          [-0.4118, -0.3725, -0.2863,  ...,  0.1922,  0.0745,  0.1608]],

         [[ 0.6706,  0.6863,  0.6941,  ..., -0.3569, -0.3490, -0.3490],
          [ 0.6784,  0.6941,  0.7020,  ..., -0.3490, -0.3412, -0.3412],
          [ 0.6784,  0.6941,  0.7020,  ..., -0.3412, -0.3333, -0.3333],
          ...,
          [-0.8039, -0.7490, -0.6627,  ..., -0.3490, -0.2471, -0.5059],
          [-0.8039, -0.7490, -0.6706,  ..., -0.3176, -0.2235, -0.2235],
          [-0.7961, -0.7490, -0.6627,  ..., -0.2000, -0.3176, -0.2471]],

         [[ 0.4824,  0.4980,  0.5059,  ..., -0.5686, -0.5529, -0.5529],
          [ 0.4902,  0.5059,  0.5137,  ..., -0.5765, -0.5608, -0.5608],
          [ 0.4902,  0.5059,  0.5137,  ..., -0.5765, -0.5686, -0.5686],
          ...,
          [-0.9059, -0.8745, -0.8353,  ..., -0.6549, -0.5451, -0.7961],
          [-0.8980, -0.8824, -0.8588,  ..., -0.6471, -0.5451, -0.5373],
          [-0.9059, -0.8980, -0.8353,  ..., -0.5608, -0.6549, -0.5608]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.91it/s, distance=319]  3%|▎         | 3/100 [00:00<00:14,  6.52it/s, distance=172]  5%|▌         | 5/100 [00:00<00:11,  8.37it/s, distance=127]  7%|▋         | 7/100 [00:00<00:09,  9.42it/s, distance=109]  9%|▉         | 9/100 [00:01<00:14,  6.42it/s, distance=94.1] 11%|█         | 11/100 [00:01<00:11,  7.61it/s, distance=80.4] 13%|█▎        | 13/100 [00:01<00:10,  8.58it/s, distance=74.1] 15%|█▌        | 15/100 [00:01<00:09,  9.34it/s, distance=66.6] 17%|█▋        | 17/100 [00:02<00:12,  6.84it/s, distance=61.6] 19%|█▉        | 19/100 [00:02<00:10,  7.83it/s, distance=57.8] 21%|██        | 21/100 [00:02<00:09,  8.67it/s, distance=53.8] 23%|██▎       | 23/100 [00:02<00:08,  9.37it/s, distance=50.2] 25%|██▌       | 25/100 [00:03<00:10,  6.90it/s, distance=48.1] 27%|██▋       | 27/100 [00:03<00:09,  7.87it/s, distance=44.8] 29%|██▉       | 29/100 [00:03<00:08,  8.68it/s, distance=42.5] 31%|███       | 31/100 [00:03<00:07,  9.36it/s, distance=41.2] 33%|███▎      | 33/100 [00:04<00:09,  6.92it/s, distance=39.3] 35%|███▌      | 35/100 [00:04<00:08,  7.88it/s, distance=38.2] 37%|███▋      | 37/100 [00:04<00:07,  8.69it/s, distance=37]   39%|███▉      | 39/100 [00:04<00:06,  9.37it/s, distance=36.1] 41%|████      | 41/100 [00:05<00:08,  6.88it/s, distance=36.1] 43%|████▎     | 43/100 [00:05<00:07,  7.85it/s, distance=34.7] 45%|████▌     | 45/100 [00:05<00:06,  8.66it/s, distance=33.5] 47%|████▋     | 47/100 [00:05<00:05,  9.34it/s, distance=32.7] 49%|████▉     | 49/100 [00:06<00:07,  6.87it/s, distance=31.8] 51%|█████     | 51/100 [00:06<00:06,  7.83it/s, distance=31.4] 53%|█████▎    | 53/100 [00:06<00:05,  8.64it/s, distance=30.7] 55%|█████▌    | 55/100 [00:06<00:04,  9.33it/s, distance=30.1] 57%|█████▋    | 57/100 [00:07<00:06,  6.86it/s, distance=29.5] 59%|█████▉    | 59/100 [00:07<00:05,  7.83it/s, distance=28.9] 61%|██████    | 61/100 [00:07<00:04,  8.64it/s, distance=28.6] 63%|██████▎   | 63/100 [00:07<00:03,  9.33it/s, distance=28.1] 65%|██████▌   | 65/100 [00:08<00:05,  6.85it/s, distance=27.5] 67%|██████▋   | 67/100 [00:08<00:04,  7.81it/s, distance=27.2] 69%|██████▉   | 69/100 [00:08<00:03,  8.63it/s, distance=26.9] 71%|███████   | 71/100 [00:08<00:03,  9.32it/s, distance=26.5] 73%|███████▎  | 73/100 [00:09<00:03,  6.86it/s, distance=26.2] 75%|███████▌  | 75/100 [00:09<00:03,  7.82it/s, distance=25.8] 77%|███████▋  | 77/100 [00:09<00:02,  8.64it/s, distance=25.5] 79%|███████▉  | 79/100 [00:09<00:02,  9.32it/s, distance=25.2] 81%|████████  | 81/100 [00:10<00:02,  6.86it/s, distance=24.8] 83%|████████▎ | 83/100 [00:10<00:02,  7.82it/s, distance=24.5] 85%|████████▌ | 85/100 [00:10<00:01,  8.64it/s, distance=24.1] 87%|████████▋ | 87/100 [00:10<00:01,  9.33it/s, distance=23.7] 89%|████████▉ | 89/100 [00:11<00:01,  6.86it/s, distance=23.2] 91%|█████████ | 91/100 [00:11<00:01,  7.81it/s, distance=22.7] 93%|█████████▎| 93/100 [00:11<00:00,  8.63it/s, distance=22.2] 95%|█████████▌| 95/100 [00:11<00:00,  9.32it/s, distance=21.5] 97%|█████████▋| 97/100 [00:11<00:00,  9.88it/s, distance=20.5] 99%|█████████▉| 99/100 [00:12<00:00, 10.29it/s, distance=18.6]100%|██████████| 100/100 [00:12<00:00,  8.19it/s, distance=15.7]
2025-06-18 20:30:44,668 [MPGD] >> Inference for image 3
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.0879e+00, -2.0555e+00, -5.1200e+08, -5.1200e+08,
        -2.0641e+00, -2.1589e+00, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7996, -1.8330, -1.8233, -1.8259, -1.7503, -1.8277, -1.8690, -1.7334],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10008809 0.0514067  0.06232889 0.05923362 0.26868378 0.05710448
 0.02499775 0.37615668]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8769, -1.7885, -1.7050, -1.7913, -1.7524, -1.6938, -1.7108, -1.7225],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00693232 0.04068155 0.21583393 0.03846674 0.0837533  0.26996282
 0.1921654  0.15220394]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8258, -1.6450, -1.6054, -1.7346, -1.6512, -1.6543, -1.6281, -1.5647],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00233758 0.08702323 0.19190994 0.01448043 0.0768893  0.07219163
 0.12191834 0.43324956]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5009, -1.4323, -1.4933, -1.3278, -1.4820, -1.2943, -1.4266, -1.5736],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00939602 0.03708154 0.01094289 0.29946277 0.01372264 0.58563262
 0.04156436 0.00219715]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2287, -1.1596, -1.1556, -1.2244, -1.2554, -1.1165, -1.0950, -1.1860],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02685128 0.10686667 0.11587707 0.02925188 0.01575026 0.25307226
 0.38927095 0.06305964]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9865, -1.0721, -0.9953, -1.0373, -0.9397, -1.0225, -1.0126, -0.9983],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14693599 0.02651759 0.12323486 0.05323954 0.37514892 0.07158078
 0.08719808 0.11614425]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7680, -0.7963, -0.8124, -0.7575, -0.8598, -0.8021, -0.8105, -0.7811],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.19707395 0.1119096  0.08108862 0.24292252 0.03140499 0.09970642
 0.08417992 0.15171397]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7167, -0.6986, -0.7405, -0.7585, -0.7318, -0.7339, -0.6436, -0.8215],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10660392 0.15321424 0.06625406 0.04623766 0.07882084 0.07550221
 0.4602734  0.01309367]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6171, -0.6077, -0.6650, -0.6498, -0.7016, -0.6693, -0.6123, -0.6482],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1892573  0.22813872 0.07257719 0.09838815 0.03492416 0.06665733
 0.20844381 0.10161334]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6155, -0.6245, -0.6303, -0.5354, -0.5785, -0.6004, -0.6155, -0.6484],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.079888   0.06671875 0.05940629 0.39699837 0.16751576 0.108052
 0.07999063 0.0414302 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5700, -0.5937, -0.5369, -0.6021, -0.5548, -0.5824, -0.5907, -0.5932],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13300451 0.08293013 0.25815183 0.07006382 0.18025933 0.10393941
 0.08799143 0.08365954]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 27.290
key: ssim
value: 0.872
key: lpips
value: 0.096
key: facenet_l2
value: 0.419
key: adaface_l2
value: 0.619
ref_face_img: tensor([[[[ 0.9843,  0.9843,  0.9843,  ...,  0.9451,  0.9373,  0.9294],
          [ 0.9843,  0.9843,  0.9843,  ...,  0.9451,  0.9373,  0.9294],
          [ 0.9843,  0.9843,  0.9843,  ...,  0.9451,  0.9373,  0.9294],
          ...,
          [ 0.8980,  0.8902,  0.8745,  ..., -0.4980, -0.4745, -0.4510],
          [ 0.8980,  0.8824,  0.8745,  ..., -0.4980, -0.4745, -0.4510],
          [ 0.8902,  0.8824,  0.8667,  ..., -0.4902, -0.4745, -0.4510]],

         [[ 0.9922,  0.9922,  0.9922,  ...,  0.9765,  0.9686,  0.9529],
          [ 0.9922,  0.9922,  0.9922,  ...,  0.9765,  0.9686,  0.9529],
          [ 0.9922,  0.9922,  0.9922,  ...,  0.9765,  0.9686,  0.9529],
          ...,
          [ 0.8588,  0.8431,  0.8196,  ..., -0.8039, -0.7882, -0.7725],
          [ 0.8510,  0.8353,  0.8039,  ..., -0.8039, -0.7882, -0.7725],
          [ 0.8353,  0.8196,  0.7961,  ..., -0.7961, -0.7882, -0.7725]],

         [[ 0.8353,  0.8431,  0.8431,  ...,  0.7961,  0.7882,  0.7725],
          [ 0.8353,  0.8431,  0.8431,  ...,  0.7961,  0.7882,  0.7725],
          [ 0.8353,  0.8431,  0.8431,  ...,  0.7961,  0.7882,  0.7725],
          ...,
          [ 0.6471,  0.6235,  0.6000,  ..., -0.9137, -0.9059, -0.8902],
          [ 0.6314,  0.6078,  0.5843,  ..., -0.9137, -0.8980, -0.8902],
          [ 0.6157,  0.6000,  0.5686,  ..., -0.9137, -0.8980, -0.8902]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.92it/s, distance=315]  3%|▎         | 3/100 [00:00<00:14,  6.55it/s, distance=198]  5%|▌         | 5/100 [00:00<00:11,  8.39it/s, distance=138]  7%|▋         | 7/100 [00:00<00:09,  9.43it/s, distance=114]  9%|▉         | 9/100 [00:01<00:14,  6.37it/s, distance=94.3] 11%|█         | 11/100 [00:01<00:11,  7.56it/s, distance=86.2] 13%|█▎        | 13/100 [00:01<00:10,  8.51it/s, distance=78.8] 15%|█▌        | 15/100 [00:01<00:09,  9.27it/s, distance=76.3] 17%|█▋        | 17/100 [00:02<00:12,  6.57it/s, distance=64.4] 19%|█▉        | 19/100 [00:02<00:10,  7.59it/s, distance=59.5] 21%|██        | 21/100 [00:02<00:09,  8.46it/s, distance=54.7] 23%|██▎       | 23/100 [00:02<00:08,  9.18it/s, distance=51.6] 25%|██▌       | 25/100 [00:03<00:11,  6.66it/s, distance=49.3] 27%|██▋       | 27/100 [00:03<00:09,  7.65it/s, distance=47.3] 29%|██▉       | 29/100 [00:03<00:08,  8.50it/s, distance=45.2] 31%|███       | 31/100 [00:03<00:07,  9.21it/s, distance=43.7] 33%|███▎      | 33/100 [00:04<00:10,  6.69it/s, distance=43]   35%|███▌      | 35/100 [00:04<00:08,  7.66it/s, distance=41.1] 37%|███▋      | 37/100 [00:04<00:07,  8.49it/s, distance=39.5] 39%|███▉      | 39/100 [00:04<00:06,  9.19it/s, distance=38.3] 41%|████      | 41/100 [00:05<00:08,  6.62it/s, distance=37.2] 43%|████▎     | 43/100 [00:05<00:07,  7.58it/s, distance=36.6] 45%|████▌     | 45/100 [00:05<00:06,  8.42it/s, distance=35.7] 47%|████▋     | 47/100 [00:05<00:05,  9.12it/s, distance=34.9] 49%|████▉     | 49/100 [00:06<00:07,  6.58it/s, distance=33.7] 51%|█████     | 51/100 [00:06<00:06,  7.56it/s, distance=33.5] 53%|█████▎    | 53/100 [00:06<00:05,  8.40it/s, distance=32.7] 55%|█████▌    | 55/100 [00:06<00:04,  9.13it/s, distance=32.1] 57%|█████▋    | 57/100 [00:07<00:06,  6.63it/s, distance=31.8] 59%|█████▉    | 59/100 [00:07<00:05,  7.60it/s, distance=31.1] 61%|██████    | 61/100 [00:07<00:04,  8.46it/s, distance=30.7] 63%|██████▎   | 63/100 [00:07<00:04,  9.17it/s, distance=30.1] 65%|██████▌   | 65/100 [00:08<00:05,  6.64it/s, distance=29.7] 67%|██████▋   | 67/100 [00:08<00:04,  7.61it/s, distance=29.2] 69%|██████▉   | 69/100 [00:08<00:03,  8.46it/s, distance=28.8] 71%|███████   | 71/100 [00:09<00:03,  9.17it/s, distance=28.3] 73%|███████▎  | 73/100 [00:09<00:04,  6.64it/s, distance=28]   75%|███████▌  | 75/100 [00:09<00:03,  7.60it/s, distance=27.6] 77%|███████▋  | 77/100 [00:09<00:02,  8.46it/s, distance=27.1] 79%|███████▉  | 79/100 [00:10<00:02,  9.18it/s, distance=26.7] 81%|████████  | 81/100 [00:10<00:02,  6.63it/s, distance=26.2] 83%|████████▎ | 83/100 [00:10<00:02,  7.61it/s, distance=25.8] 85%|████████▌ | 85/100 [00:10<00:01,  8.45it/s, distance=25.3] 87%|████████▋ | 87/100 [00:11<00:01,  9.18it/s, distance=24.8] 89%|████████▉ | 89/100 [00:11<00:01,  6.63it/s, distance=24.5] 91%|█████████ | 91/100 [00:11<00:01,  7.61it/s, distance=23.9] 93%|█████████▎| 93/100 [00:11<00:00,  8.46it/s, distance=23.2] 95%|█████████▌| 95/100 [00:12<00:00,  9.18it/s, distance=22.4] 97%|█████████▋| 97/100 [00:12<00:00,  9.76it/s, distance=21.2] 99%|█████████▉| 99/100 [00:12<00:00, 10.20it/s, distance=19.1]100%|██████████| 100/100 [00:12<00:00,  8.00it/s, distance=16.1]
2025-06-18 20:30:58,521 [MPGD] >> Inference for image 4
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.0233e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -1.9031e+00, -5.1200e+08, -2.0602e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8734, -1.8194, -1.7069, -1.8051, -1.8583, -1.7787, -1.8091, -1.9363],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02096855 0.06169506 0.58545473 0.08224564 0.02833732 0.13947048
 0.07587389 0.00595433]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4725, -1.5946, -1.5593, -1.5964, -1.7082, -1.5801, -1.6805, -1.5363],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.56605184 0.04917165 0.0997952  0.04743494 0.00507359 0.06582712
 0.00882931 0.15781636]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1689, -1.1144, -1.1239, -1.1410, -1.2147, -1.2084, -1.2613, -1.3863],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10876922 0.32292754 0.26704584 0.18999524 0.04344706 0.04930365
 0.01710706 0.0014044 ]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0664, -1.0248, -1.0986, -1.0619, -1.1067, -1.0966, -1.1010, -1.0986],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14429423 0.33113662 0.07575842 0.1578455  0.06436188 0.07875959
 0.0721848  0.07565897]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9864, -0.9620, -1.0379, -1.0098, -0.8904, -0.9273, -0.9900, -0.8138],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02166521 0.03529027 0.00772543 0.01356762 0.14768646 0.07067662
 0.02017356 0.68321484]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8072, -0.8457, -0.7583, -0.8628, -0.7702, -0.7409, -0.7018, -0.7657],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04798457 0.02222182 0.12766674 0.01579593 0.10048976 0.18081491
 0.39505376 0.10997251]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6709, -0.6509, -0.7252, -0.7350, -0.6686, -0.6410, -0.6599, -0.6692],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12119911 0.18072933 0.04085611 0.03358714 0.12692149 0.22040116
 0.15097652 0.12532913]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6783, -0.5827, -0.6696, -0.6587, -0.7265, -0.6611, -0.6826, -0.6968],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07224088 0.4888264  0.08596146 0.10693756 0.02759364 0.10208648
 0.06640091 0.04995267]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5503, -0.6053, -0.5598, -0.5942, -0.5967, -0.5859, -0.5916, -0.5890],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.2293956  0.07630747 0.18968982 0.09525554 0.09070455 0.1125169
 0.10037006 0.10576006]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6009, -0.5698, -0.5691, -0.5565, -0.5565, -0.6007, -0.5638, -0.5175],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05549263 0.10346732 0.10486752 0.13482922 0.13477555 0.05577349
 0.11659036 0.29420391]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5395, -0.5275, -0.5078, -0.4719, -0.5351, -0.5455, -0.4958, -0.4724],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06165876 0.07843071 0.11621067 0.23805752 0.06731003 0.05470743
 0.14771131 0.23591358]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.925
key: ssim
value: 0.880
key: lpips
value: 0.074
key: facenet_l2
value: 0.304
key: adaface_l2
value: 0.505
ref_face_img: tensor([[[[-0.7569, -0.7647, -0.7647,  ..., -0.8275, -0.8275, -0.8275],
          [-0.7412, -0.7490, -0.7490,  ..., -0.8353, -0.8353, -0.8353],
          [-0.7098, -0.7255, -0.7333,  ..., -0.8353, -0.8353, -0.8353],
          ...,
          [-0.2392, -0.2157, -0.2000,  ..., -0.9529, -0.9529, -0.9529],
          [-0.2157, -0.1922, -0.1765,  ..., -0.9529, -0.9529, -0.9529],
          [-0.2078, -0.1922, -0.1765,  ..., -0.9529, -0.9529, -0.9529]],

         [[-0.8196, -0.8196, -0.8196,  ..., -0.8039, -0.8039, -0.8039],
          [-0.8118, -0.8118, -0.8118,  ..., -0.8039, -0.8039, -0.8118],
          [-0.7961, -0.8039, -0.7961,  ..., -0.8118, -0.8118, -0.8118],
          ...,
          [-0.4902, -0.4824, -0.4667,  ..., -0.9529, -0.9529, -0.9529],
          [-0.4824, -0.4667, -0.4588,  ..., -0.9529, -0.9529, -0.9529],
          [-0.4824, -0.4667, -0.4588,  ..., -0.9529, -0.9529, -0.9529]],

         [[-0.8510, -0.8510, -0.8588,  ..., -0.7333, -0.7333, -0.7333],
          [-0.8510, -0.8510, -0.8431,  ..., -0.7412, -0.7412, -0.7412],
          [-0.8431, -0.8431, -0.8431,  ..., -0.7490, -0.7490, -0.7490],
          ...,
          [-0.6471, -0.6392, -0.6235,  ..., -0.9529, -0.9529, -0.9529],
          [-0.6392, -0.6314, -0.6157,  ..., -0.9529, -0.9529, -0.9529],
          [-0.6314, -0.6314, -0.6157,  ..., -0.9529, -0.9529, -0.9529]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.88it/s, distance=265]  3%|▎         | 3/100 [00:00<00:14,  6.50it/s, distance=187]  5%|▌         | 5/100 [00:00<00:11,  8.35it/s, distance=157]  7%|▋         | 7/100 [00:00<00:09,  9.43it/s, distance=133]  9%|▉         | 9/100 [00:01<00:14,  6.42it/s, distance=119] 11%|█         | 11/100 [00:01<00:11,  7.61it/s, distance=106] 13%|█▎        | 13/100 [00:01<00:10,  8.56it/s, distance=98.2] 15%|█▌        | 15/100 [00:01<00:09,  9.30it/s, distance=91.1] 17%|█▋        | 17/100 [00:02<00:12,  6.70it/s, distance=84.3] 19%|█▉        | 19/100 [00:02<00:10,  7.70it/s, distance=80.3] 21%|██        | 21/100 [00:02<00:09,  8.55it/s, distance=76.8] 23%|██▎       | 23/100 [00:02<00:08,  9.26it/s, distance=71.8] 25%|██▌       | 25/100 [00:03<00:11,  6.78it/s, distance=68]   27%|██▋       | 27/100 [00:03<00:09,  7.75it/s, distance=64.1] 29%|██▉       | 29/100 [00:03<00:08,  8.57it/s, distance=61.5] 31%|███       | 31/100 [00:03<00:07,  9.27it/s, distance=58]   33%|███▎      | 33/100 [00:04<00:09,  6.79it/s, distance=54.8] 35%|███▌      | 35/100 [00:04<00:08,  7.75it/s, distance=54.3] 37%|███▋      | 37/100 [00:04<00:07,  8.58it/s, distance=52.1] 39%|███▉      | 39/100 [00:04<00:06,  9.27it/s, distance=50.3] 41%|████      | 41/100 [00:05<00:08,  6.83it/s, distance=47.5] 43%|████▎     | 43/100 [00:05<00:07,  7.78it/s, distance=47.1] 45%|████▌     | 45/100 [00:05<00:06,  8.61it/s, distance=44.4] 47%|████▋     | 47/100 [00:05<00:05,  9.29it/s, distance=42.5] 49%|████▉     | 49/100 [00:06<00:07,  6.85it/s, distance=41.7] 51%|█████     | 51/100 [00:06<00:06,  7.80it/s, distance=40.1] 53%|█████▎    | 53/100 [00:06<00:05,  8.63it/s, distance=38.8] 55%|█████▌    | 55/100 [00:06<00:04,  9.31it/s, distance=37.5] 57%|█████▋    | 57/100 [00:07<00:06,  6.83it/s, distance=36.3] 59%|█████▉    | 59/100 [00:07<00:05,  7.79it/s, distance=35.5] 61%|██████    | 61/100 [00:07<00:04,  8.61it/s, distance=34.6] 63%|██████▎   | 63/100 [00:07<00:03,  9.29it/s, distance=33.6] 65%|██████▌   | 65/100 [00:08<00:05,  6.84it/s, distance=32.5] 67%|██████▋   | 67/100 [00:08<00:04,  7.80it/s, distance=32]   69%|██████▉   | 69/100 [00:08<00:03,  8.62it/s, distance=31.4] 71%|███████   | 71/100 [00:08<00:03,  9.31it/s, distance=30.7] 73%|███████▎  | 73/100 [00:09<00:03,  6.86it/s, distance=29.8] 75%|███████▌  | 75/100 [00:09<00:03,  7.83it/s, distance=29.3] 77%|███████▋  | 77/100 [00:09<00:02,  8.64it/s, distance=28.8] 79%|███████▉  | 79/100 [00:09<00:02,  9.32it/s, distance=28.2] 81%|████████  | 81/100 [00:10<00:02,  6.87it/s, distance=27.6] 83%|████████▎ | 83/100 [00:10<00:02,  7.83it/s, distance=27.1] 85%|████████▌ | 85/100 [00:10<00:01,  8.65it/s, distance=26.5] 87%|████████▋ | 87/100 [00:10<00:01,  9.32it/s, distance=25.9] 89%|████████▉ | 89/100 [00:11<00:01,  6.87it/s, distance=25.4] 91%|█████████ | 91/100 [00:11<00:01,  7.83it/s, distance=24.7] 93%|█████████▎| 93/100 [00:11<00:00,  8.64it/s, distance=23.9] 95%|█████████▌| 95/100 [00:11<00:00,  9.32it/s, distance=23]   97%|█████████▋| 97/100 [00:12<00:00,  9.86it/s, distance=21.8] 99%|█████████▉| 99/100 [00:12<00:00, 10.27it/s, distance=19.6]100%|██████████| 100/100 [00:12<00:00,  8.15it/s, distance=16.5]
2025-06-18 20:31:12,137 [MPGD] >> Inference for image 5
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -2.1436e+00, -2.1116e+00, -5.1200e+08,
        -2.1056e+00, -5.1200e+08, -2.0483e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0953, -1.9427, -2.1089, -1.8611, -1.9268, -1.8817, -2.0400, -1.8740],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00313959 0.0663915  0.00239213 0.33993616 0.09122344 0.22486543
 0.00949065 0.26256109]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5273, -1.6254, -1.5210, -1.4152, -1.6174, -1.4745, -1.5456, -1.4332],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0454909  0.00639489 0.05157833 0.42801964 0.00750358 0.13075653
 0.03154871 0.29870743]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1663, -1.2722, -1.2598, -1.3169, -1.1069, -1.3023, -1.2064, -1.1510],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15420693 0.01855197 0.02378671 0.00758679 0.50667905 0.01017152
 0.06925931 0.20975773]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0681, -1.1528, -1.4396, -1.2181, -1.2400, -1.1680, -1.3694, -1.2315],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [6.93461916e-01 1.27342916e-01 4.10920527e-04 3.45011746e-02
 2.22601737e-02 9.39501182e-02 1.67404418e-03 2.63987368e-02]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1653, -1.1761, -1.2408, -1.2385, -1.2115, -1.1682, -1.1902, -1.2902],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.23314928 0.18800266 0.05154897 0.05396315 0.092498   0.21990377
 0.14175284 0.01918132]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1589, -1.2657, -1.1794, -1.1671, -1.1048, -1.1589, -1.1017, -1.1165],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08296498 0.00980518 0.05500455 0.07047038 0.24477064 0.08288017
 0.26034623 0.19375788]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1716, -1.1668, -1.1567, -1.0545, -1.1870, -1.1018, -1.1417, -1.0352],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02797103 0.03081505 0.03768086 0.29077358 0.02055505 0.11288384
 0.05091089 0.4284097 ]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9239, -0.9971, -1.0330, -1.0675, -1.0299, -0.9359, -0.9778, -1.0073],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.35266286 0.08151294 0.03975822 0.01995495 0.0423149  0.27721527
 0.12006245 0.06651842]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8557, -0.8489, -0.8501, -0.7796, -0.9189, -0.8652, -0.8445, -0.7839],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06933173 0.07944308 0.07755033 0.31804899 0.01959989 0.05733379
 0.0867531  0.29193909]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7710, -0.7471, -0.7775, -0.7387, -0.8298, -0.8012, -0.7430, -0.7933],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11559146 0.18653664 0.10158395 0.22059564 0.03569703 0.0632421
 0.2026254  0.07412779]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7358, -0.7253, -0.7259, -0.6922, -0.7472, -0.7072, -0.7697, -0.6875],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08655196 0.10678467 0.10562195 0.20727789 0.06891025 0.15345463
 0.04392509 0.22747356]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.375
key: ssim
value: 0.871
key: lpips
value: 0.079
key: facenet_l2
value: 0.393
key: adaface_l2
value: 0.714
ref_face_img: tensor([[[[-0.7961, -0.7961, -0.7961,  ..., -0.5059, -0.4039, -0.3098],
          [-0.7961, -0.7961, -0.7961,  ..., -0.4902, -0.3804, -0.2941],
          [-0.7961, -0.7961, -0.7961,  ..., -0.4510, -0.3255, -0.2706],
          ...,
          [-0.8980, -0.8980, -0.8980,  ..., -0.8353, -0.8353, -0.8275],
          [-0.8980, -0.8980, -0.8902,  ..., -0.8353, -0.8353, -0.8275],
          [-0.8980, -0.8980, -0.8902,  ..., -0.8353, -0.8353, -0.8275]],

         [[-0.7961, -0.7961, -0.7961,  ..., -0.5059, -0.4039, -0.3176],
          [-0.7961, -0.7961, -0.7961,  ..., -0.4980, -0.3961, -0.3020],
          [-0.7961, -0.7961, -0.7961,  ..., -0.4745, -0.3490, -0.2784],
          ...,
          [-0.8980, -0.8980, -0.8980,  ..., -0.8196, -0.8196, -0.8275],
          [-0.8980, -0.8980, -0.8902,  ..., -0.8196, -0.8196, -0.8275],
          [-0.8980, -0.8980, -0.8902,  ..., -0.8196, -0.8196, -0.8275]],

         [[-0.7961, -0.7961, -0.7961,  ..., -0.4980, -0.3882, -0.2784],
          [-0.7961, -0.7961, -0.7961,  ..., -0.4824, -0.3725, -0.2627],
          [-0.7961, -0.7961, -0.7961,  ..., -0.4510, -0.3176, -0.2392],
          ...,
          [-0.8980, -0.8980, -0.8980,  ..., -0.8275, -0.8275, -0.8275],
          [-0.8980, -0.8980, -0.8902,  ..., -0.8275, -0.8275, -0.8275],
          [-0.8980, -0.8980, -0.8902,  ..., -0.8275, -0.8275, -0.8275]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.93it/s, distance=335]  3%|▎         | 3/100 [00:00<00:14,  6.56it/s, distance=142]  5%|▌         | 5/100 [00:00<00:11,  8.38it/s, distance=118]  7%|▋         | 7/100 [00:00<00:09,  9.45it/s, distance=104]  9%|▉         | 9/100 [00:01<00:14,  6.45it/s, distance=88.4] 11%|█         | 11/100 [00:01<00:11,  7.63it/s, distance=77.9] 13%|█▎        | 13/100 [00:01<00:10,  8.57it/s, distance=74.1] 15%|█▌        | 15/100 [00:01<00:09,  9.31it/s, distance=67.2] 17%|█▋        | 17/100 [00:02<00:12,  6.82it/s, distance=65.7] 19%|█▉        | 19/100 [00:02<00:10,  7.82it/s, distance=57.1] 21%|██        | 21/100 [00:02<00:09,  8.66it/s, distance=53.8] 23%|██▎       | 23/100 [00:02<00:08,  9.34it/s, distance=51.3] 25%|██▌       | 25/100 [00:03<00:10,  6.88it/s, distance=49.3] 27%|██▋       | 27/100 [00:03<00:09,  7.84it/s, distance=47.1] 29%|██▉       | 29/100 [00:03<00:08,  8.66it/s, distance=44.4] 31%|███       | 31/100 [00:03<00:07,  9.34it/s, distance=43.1] 33%|███▎      | 33/100 [00:04<00:09,  6.86it/s, distance=42.8] 35%|███▌      | 35/100 [00:04<00:08,  7.82it/s, distance=39.7] 37%|███▋      | 37/100 [00:04<00:07,  8.63it/s, distance=39]   39%|███▉      | 39/100 [00:04<00:06,  9.31it/s, distance=37.4] 41%|████      | 41/100 [00:05<00:08,  6.84it/s, distance=35.8] 43%|████▎     | 43/100 [00:05<00:07,  7.80it/s, distance=34.6] 45%|████▌     | 45/100 [00:05<00:06,  8.62it/s, distance=34]   47%|████▋     | 47/100 [00:05<00:05,  9.30it/s, distance=33.4] 49%|████▉     | 49/100 [00:06<00:07,  6.84it/s, distance=32.6] 51%|█████     | 51/100 [00:06<00:06,  7.79it/s, distance=32]   53%|█████▎    | 53/100 [00:06<00:05,  8.60it/s, distance=31.5] 55%|█████▌    | 55/100 [00:06<00:04,  9.28it/s, distance=30.8] 57%|█████▋    | 57/100 [00:07<00:06,  6.84it/s, distance=30.3] 59%|█████▉    | 59/100 [00:07<00:05,  7.79it/s, distance=29.8] 61%|██████    | 61/100 [00:07<00:04,  8.61it/s, distance=29.3] 63%|██████▎   | 63/100 [00:07<00:03,  9.29it/s, distance=28.8] 65%|██████▌   | 65/100 [00:08<00:05,  6.85it/s, distance=28.5] 67%|██████▋   | 67/100 [00:08<00:04,  7.81it/s, distance=27.9] 69%|██████▉   | 69/100 [00:08<00:03,  8.63it/s, distance=27.5] 71%|███████   | 71/100 [00:08<00:03,  9.31it/s, distance=27.1] 73%|███████▎  | 73/100 [00:09<00:03,  6.87it/s, distance=26.7] 75%|███████▌  | 75/100 [00:09<00:03,  7.82it/s, distance=26.3] 77%|███████▋  | 77/100 [00:09<00:02,  8.64it/s, distance=26]   79%|███████▉  | 79/100 [00:09<00:02,  9.32it/s, distance=25.6] 81%|████████  | 81/100 [00:10<00:02,  6.88it/s, distance=25.2] 83%|████████▎ | 83/100 [00:10<00:02,  7.83it/s, distance=24.9] 85%|████████▌ | 85/100 [00:10<00:01,  8.64it/s, distance=24.5] 87%|████████▋ | 87/100 [00:10<00:01,  9.32it/s, distance=24.1] 89%|████████▉ | 89/100 [00:11<00:01,  6.87it/s, distance=23.6] 91%|█████████ | 91/100 [00:11<00:01,  7.82it/s, distance=23.1] 93%|█████████▎| 93/100 [00:11<00:00,  8.62it/s, distance=22.5] 95%|█████████▌| 95/100 [00:11<00:00,  9.30it/s, distance=21.7] 97%|█████████▋| 97/100 [00:11<00:00,  9.83it/s, distance=20.7] 99%|█████████▉| 99/100 [00:12<00:00, 10.25it/s, distance=18.7]100%|██████████| 100/100 [00:12<00:00,  8.17it/s, distance=15.8]
2025-06-18 20:31:25,557 [MPGD] >> Inference for image 6
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.1316e+00, -5.1200e+08, -2.1386e+00, -5.1200e+08,
        -5.1200e+08, -1.9611e+00, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9366, -1.8544, -1.8575, -1.8747, -1.8919, -2.0302, -2.0016, -1.9475],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05498912 0.28499835 0.26785657 0.18989037 0.13455849 0.00847007
 0.01499095 0.04424608]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3502, -1.4320, -1.3350, -1.4590, -1.4942, -1.3643, -1.3666, -1.3377],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.18252916 0.03554419 0.24731134 0.02070711 0.01024805 0.13763569
 0.13141177 0.23461268]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3140, -1.1442, -1.1736, -1.3515, -1.3839, -1.1072, -1.3559, -1.3258],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00893185 0.2667535  0.14805886 0.00421812 0.00220664 0.5589122
 0.00386467 0.00705418]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1262, -1.0777, -0.9982, -1.0170, -1.0156, -1.0070, -0.9713, -1.1001],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01442776 0.03809317 0.1869293  0.12815005 0.13188605 0.15657018
 0.31961013 0.02433337]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0466, -0.9455, -0.8407, -0.9406, -0.9485, -1.0227, -1.0554, -1.1421],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01136058 0.08592172 0.69767482 0.09461298 0.08089282 0.01832533
 0.00952934 0.00168241]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8293, -0.8434, -0.9520, -0.8972, -0.9192, -0.8618, -0.8423, -0.9527],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.2747641  0.20716033 0.02358319 0.07054258 0.04549387 0.14340705
 0.21179665 0.02325222]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8994, -0.7499, -0.7855, -0.8563, -0.8638, -0.9202, -0.8712, -0.8591],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02519202 0.50086101 0.24578855 0.05960841 0.05131064 0.01661575
 0.04422312 0.05640048]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8122, -0.8153, -0.8011, -0.8754, -0.7534, -0.7475, -0.8012, -0.8524],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08294533 0.07800104 0.10354069 0.02345932 0.26872131 0.30276892
 0.10345791 0.03710548]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7799, -0.7612, -0.7932, -0.7752, -0.7453, -0.8095, -0.8129, -0.7997],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12403362 0.18021999 0.09503872 0.13641843 0.24800217 0.06866691
 0.06415725 0.08346291]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7847, -0.7815, -0.8230, -0.7645, -0.7902, -0.7689, -0.7701, -0.7966],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11872718 0.12656582 0.05517134 0.17785214 0.10632939 0.16284124
 0.15896796 0.09354493]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7902, -0.7461, -0.7188, -0.7651, -0.7516, -0.7756, -0.7983, -0.7938],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06887927 0.16628933 0.28721192 0.11377256 0.14905128 0.09223024
 0.05852204 0.06404335]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.190
key: ssim
value: 0.833
key: lpips
value: 0.111
key: facenet_l2
value: 0.249
key: adaface_l2
value: 0.637
ref_face_img: tensor([[[[ 0.4039,  0.4118,  0.4196,  ...,  0.0039, -0.0039, -0.0039],
          [ 0.4039,  0.4118,  0.4196,  ...,  0.0039, -0.0039, -0.0039],
          [ 0.4039,  0.4118,  0.4196,  ...,  0.0039, -0.0039, -0.0039],
          ...,
          [ 0.2157,  0.2157,  0.2078,  ...,  0.1059,  0.1373,  0.1608],
          [ 0.2078,  0.2078,  0.2078,  ...,  0.1059,  0.1216,  0.1451],
          [ 0.2078,  0.2078,  0.2157,  ...,  0.1216,  0.1294,  0.1373]],

         [[ 0.5451,  0.5529,  0.5608,  ..., -0.2392, -0.2471, -0.2471],
          [ 0.5451,  0.5529,  0.5608,  ..., -0.2471, -0.2471, -0.2471],
          [ 0.5451,  0.5529,  0.5608,  ..., -0.2471, -0.2549, -0.2549],
          ...,
          [ 0.4353,  0.4353,  0.4353,  ..., -0.3647, -0.3333, -0.3098],
          [ 0.4353,  0.4353,  0.4353,  ..., -0.3490, -0.3412, -0.3255],
          [ 0.4353,  0.4353,  0.4353,  ..., -0.3490, -0.3412, -0.3333]],

         [[ 0.6392,  0.6471,  0.6471,  ..., -0.4667, -0.4745, -0.4745],
          [ 0.6392,  0.6471,  0.6471,  ..., -0.4745, -0.4745, -0.4745],
          [ 0.6392,  0.6471,  0.6471,  ..., -0.4745, -0.4824, -0.4824],
          ...,
          [ 0.5294,  0.5294,  0.5294,  ..., -0.6627, -0.6392, -0.6235],
          [ 0.5294,  0.5294,  0.5294,  ..., -0.6549, -0.6471, -0.6314],
          [ 0.5294,  0.5294,  0.5294,  ..., -0.6471, -0.6471, -0.6392]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:35,  2.79it/s, distance=290]  3%|▎         | 3/100 [00:00<00:15,  6.38it/s, distance=171]  5%|▌         | 5/100 [00:00<00:11,  8.23it/s, distance=132]  7%|▋         | 7/100 [00:00<00:09,  9.34it/s, distance=112]  9%|▉         | 9/100 [00:01<00:14,  6.37it/s, distance=99.5] 11%|█         | 11/100 [00:01<00:11,  7.55it/s, distance=90.3] 13%|█▎        | 13/100 [00:01<00:10,  8.51it/s, distance=79.8] 15%|█▌        | 15/100 [00:01<00:09,  9.25it/s, distance=70.5] 17%|█▋        | 17/100 [00:02<00:12,  6.58it/s, distance=63]   19%|█▉        | 19/100 [00:02<00:10,  7.60it/s, distance=58.7] 21%|██        | 21/100 [00:02<00:09,  8.46it/s, distance=55.1] 23%|██▎       | 23/100 [00:02<00:08,  9.18it/s, distance=50.3] 25%|██▌       | 25/100 [00:03<00:11,  6.63it/s, distance=49.7] 27%|██▋       | 27/100 [00:03<00:09,  7.61it/s, distance=44.9] 29%|██▉       | 29/100 [00:03<00:08,  8.45it/s, distance=42.8] 31%|███       | 31/100 [00:03<00:07,  9.17it/s, distance=41.6] 33%|███▎      | 33/100 [00:04<00:10,  6.62it/s, distance=38.9] 35%|███▌      | 35/100 [00:04<00:08,  7.59it/s, distance=38.4] 37%|███▋      | 37/100 [00:04<00:07,  8.44it/s, distance=37.5] 39%|███▉      | 39/100 [00:04<00:06,  9.16it/s, distance=36.4] 41%|████      | 41/100 [00:05<00:08,  6.61it/s, distance=35.7] 43%|████▎     | 43/100 [00:05<00:07,  7.59it/s, distance=34.3] 45%|████▌     | 45/100 [00:05<00:06,  8.43it/s, distance=33.9] 47%|████▋     | 47/100 [00:05<00:05,  9.14it/s, distance=33.1] 49%|████▉     | 49/100 [00:06<00:07,  6.62it/s, distance=32.5] 51%|█████     | 51/100 [00:06<00:06,  7.59it/s, distance=31.9] 53%|█████▎    | 53/100 [00:06<00:05,  8.44it/s, distance=31.2] 55%|█████▌    | 55/100 [00:06<00:04,  9.14it/s, distance=30.8] 57%|█████▋    | 57/100 [00:07<00:06,  6.63it/s, distance=30.1] 59%|█████▉    | 59/100 [00:07<00:05,  7.60it/s, distance=29.6] 61%|██████    | 61/100 [00:07<00:04,  8.44it/s, distance=29.2] 63%|██████▎   | 63/100 [00:08<00:04,  9.16it/s, distance=28.8] 65%|██████▌   | 65/100 [00:08<00:05,  6.64it/s, distance=28.5] 67%|██████▋   | 67/100 [00:08<00:04,  7.61it/s, distance=28.1] 69%|██████▉   | 69/100 [00:08<00:03,  8.45it/s, distance=27.7] 71%|███████   | 71/100 [00:09<00:03,  9.15it/s, distance=27.3] 73%|███████▎  | 73/100 [00:09<00:04,  6.65it/s, distance=26.8] 75%|███████▌  | 75/100 [00:09<00:03,  7.62it/s, distance=26.5] 77%|███████▋  | 77/100 [00:09<00:02,  8.47it/s, distance=26.1] 79%|███████▉  | 79/100 [00:10<00:02,  9.16it/s, distance=25.8] 81%|████████  | 81/100 [00:10<00:02,  6.65it/s, distance=25.5] 83%|████████▎ | 83/100 [00:10<00:02,  7.62it/s, distance=25.1] 85%|████████▌ | 85/100 [00:10<00:01,  8.46it/s, distance=24.7] 87%|████████▋ | 87/100 [00:11<00:01,  9.17it/s, distance=24.3] 89%|████████▉ | 89/100 [00:11<00:01,  6.64it/s, distance=23.8] 91%|█████████ | 91/100 [00:11<00:01,  7.61it/s, distance=23.3] 93%|█████████▎| 93/100 [00:11<00:00,  8.44it/s, distance=22.7] 95%|█████████▌| 95/100 [00:12<00:00,  9.15it/s, distance=21.9] 97%|█████████▋| 97/100 [00:12<00:00,  9.72it/s, distance=20.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.16it/s, distance=18.8]100%|██████████| 100/100 [00:12<00:00,  7.99it/s, distance=15.8]
2025-06-18 20:31:39,271 [MPGD] >> Inference for image 7
reward_name: adaface, curr_reward: tensor([-2.0541e+00, -2.0914e+00, -2.0397e+00, -2.0588e+00, -5.1200e+08,
        -2.0268e+00, -5.1200e+08, -2.0131e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0001, -1.7774, -1.8117, -1.9188, -1.7157, -1.8227, -1.8933, -1.9489],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00209745 0.18046618 0.09083682 0.01067168 0.61936768 0.07293419
 0.01777631 0.00584969]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4132, -1.3179, -1.2140, -1.2833, -1.1782, -1.3322, -1.2668, -1.4933],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00479084 0.03221505 0.25750421 0.0643133  0.52657029 0.02418495
 0.08945691 0.00096444]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0554, -1.0599, -1.0691, -1.0010, -0.9278, -0.9610, -1.0356, -0.9650],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0306228  0.02799619 0.02330749 0.09094843 0.39276205 0.20218695
 0.04547844 0.18669766]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9220, -0.9558, -0.9991, -0.9618, -1.0833, -0.9203, -0.8841, -0.8606],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11373995 0.05788279 0.02430794 0.05129206 0.00451146 0.11757065
 0.24237323 0.38832193]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8450, -0.7975, -0.7500, -0.7221, -0.6507, -0.9015, -0.7588, -0.6828],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00977654 0.02529258 0.0653365  0.1143682  0.47630929 0.00316143
 0.0548792  0.25087626]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6151, -0.6534, -0.7510, -0.6940, -0.7398, -0.5603, -0.6562, -0.6236],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16415981 0.07629335 0.01083501 0.03383598 0.01355095 0.4907004
 0.07212082 0.13850368]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5378, -0.5704, -0.5166, -0.5353, -0.5338, -0.4947, -0.5313, -0.5887],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11052345 0.0575372  0.16880815 0.11618527 0.11973522 0.26147557
 0.12578718 0.03994795]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5074, -0.5015, -0.4879, -0.5481, -0.5250, -0.5432, -0.5755, -0.5102],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15521582 0.17477364 0.22930429 0.06884117 0.10930747 0.07594987
 0.03980851 0.14679923]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5306, -0.5591, -0.5014, -0.5595, -0.5169, -0.5763, -0.5414, -0.5286],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13362539 0.07559249 0.23960214 0.0749018  0.1758924  0.05355248
 0.10765166 0.13918166]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5128, -0.5322, -0.4967, -0.5120, -0.5163, -0.5074, -0.5444, -0.5205],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13308296 0.09027728 0.18376867 0.13530381 0.12427023 0.14829385
 0.07082132 0.11418186]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5446, -0.5461, -0.5126, -0.5101, -0.4776, -0.5260, -0.5289, -0.4981],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06655762 0.06454527 0.12603295 0.13269491 0.25397625 0.09644275
 0.09113848 0.16861177]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.058
key: ssim
value: 0.865
key: lpips
value: 0.067
key: facenet_l2
value: 0.319
key: adaface_l2
value: 0.711
ref_face_img: tensor([[[[ 0.5216,  0.5373,  0.5373,  ...,  0.4824,  0.4745,  0.4745],
          [ 0.5216,  0.5373,  0.5373,  ...,  0.4745,  0.4745,  0.4745],
          [ 0.5216,  0.5373,  0.5373,  ...,  0.4745,  0.4745,  0.4745],
          ...,
          [-0.6157, -0.6157, -0.6157,  ..., -0.3020, -0.3020, -0.3020],
          [-0.6078, -0.6078, -0.6078,  ..., -0.3020, -0.3020, -0.3020],
          [-0.5922, -0.5922, -0.5922,  ..., -0.3020, -0.3020, -0.3020]],

         [[ 0.7098,  0.7255,  0.7333,  ...,  0.6941,  0.6941,  0.6941],
          [ 0.7098,  0.7255,  0.7333,  ...,  0.6941,  0.6941,  0.6941],
          [ 0.7098,  0.7255,  0.7333,  ...,  0.6941,  0.6941,  0.6941],
          ...,
          [-0.8353, -0.8353, -0.8353,  ..., -0.1843, -0.1686, -0.1686],
          [-0.8275, -0.8275, -0.8275,  ..., -0.1843, -0.1765, -0.1686],
          [-0.8196, -0.8196, -0.8196,  ..., -0.1922, -0.1765, -0.1765]],

         [[ 0.8039,  0.8275,  0.8353,  ...,  0.8039,  0.8039,  0.8039],
          [ 0.8039,  0.8275,  0.8353,  ...,  0.8039,  0.8039,  0.8039],
          [ 0.8039,  0.8275,  0.8353,  ...,  0.8039,  0.8039,  0.8039],
          ...,
          [-0.9451, -0.9451, -0.9451,  ..., -0.1608, -0.1451, -0.1451],
          [-0.9373, -0.9373, -0.9373,  ..., -0.1686, -0.1529, -0.1451],
          [-0.9373, -0.9373, -0.9373,  ..., -0.1765, -0.1608, -0.1529]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.91it/s, distance=306]  3%|▎         | 3/100 [00:00<00:14,  6.53it/s, distance=183]  5%|▌         | 5/100 [00:00<00:11,  8.37it/s, distance=129]  7%|▋         | 7/100 [00:00<00:09,  9.43it/s, distance=115]  9%|▉         | 9/100 [00:01<00:14,  6.37it/s, distance=98.1] 11%|█         | 11/100 [00:01<00:11,  7.55it/s, distance=90.3] 13%|█▎        | 13/100 [00:01<00:10,  8.51it/s, distance=82.2] 15%|█▌        | 15/100 [00:01<00:09,  9.26it/s, distance=72.6] 17%|█▋        | 17/100 [00:02<00:12,  6.62it/s, distance=58.8] 19%|█▉        | 19/100 [00:02<00:10,  7.63it/s, distance=55]   21%|██        | 21/100 [00:02<00:09,  8.49it/s, distance=50.5] 23%|██▎       | 23/100 [00:02<00:08,  9.20it/s, distance=46]   25%|██▌       | 25/100 [00:03<00:11,  6.71it/s, distance=44.2] 27%|██▋       | 27/100 [00:03<00:09,  7.68it/s, distance=41.4] 29%|██▉       | 29/100 [00:03<00:08,  8.51it/s, distance=39.8] 31%|███       | 31/100 [00:03<00:07,  9.21it/s, distance=38.2] 33%|███▎      | 33/100 [00:04<00:09,  6.71it/s, distance=36.3] 35%|███▌      | 35/100 [00:04<00:08,  7.67it/s, distance=35.3] 37%|███▋      | 37/100 [00:04<00:07,  8.50it/s, distance=34.6] 39%|███▉      | 39/100 [00:04<00:06,  9.20it/s, distance=33.3] 41%|████      | 41/100 [00:05<00:08,  6.71it/s, distance=32.4] 43%|████▎     | 43/100 [00:05<00:07,  7.68it/s, distance=31.8] 45%|████▌     | 45/100 [00:05<00:06,  8.50it/s, distance=31]   47%|████▋     | 47/100 [00:05<00:05,  9.19it/s, distance=30.6] 49%|████▉     | 49/100 [00:06<00:07,  6.69it/s, distance=29.8] 51%|█████     | 51/100 [00:06<00:06,  7.66it/s, distance=29.3] 53%|█████▎    | 53/100 [00:06<00:05,  8.49it/s, distance=28.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.18it/s, distance=28.4] 57%|█████▋    | 57/100 [00:07<00:06,  6.66it/s, distance=28.2] 59%|█████▉    | 59/100 [00:07<00:05,  7.62it/s, distance=27.7] 61%|██████    | 61/100 [00:07<00:04,  8.47it/s, distance=27.1] 63%|██████▎   | 63/100 [00:07<00:04,  9.16it/s, distance=26.9] 65%|██████▌   | 65/100 [00:08<00:05,  6.69it/s, distance=26.3] 67%|██████▋   | 67/100 [00:08<00:04,  7.65it/s, distance=26.1] 69%|██████▉   | 69/100 [00:08<00:03,  8.48it/s, distance=25.8] 71%|███████   | 71/100 [00:08<00:03,  9.17it/s, distance=25.5] 73%|███████▎  | 73/100 [00:09<00:04,  6.68it/s, distance=25.1] 75%|███████▌  | 75/100 [00:09<00:03,  7.64it/s, distance=24.9] 77%|███████▋  | 77/100 [00:09<00:02,  8.48it/s, distance=24.6] 79%|███████▉  | 79/100 [00:09<00:02,  9.18it/s, distance=24.3] 81%|████████  | 81/100 [00:10<00:02,  6.70it/s, distance=24.1] 83%|████████▎ | 83/100 [00:10<00:02,  7.66it/s, distance=23.8] 85%|████████▌ | 85/100 [00:10<00:01,  8.49it/s, distance=23.4] 87%|████████▋ | 87/100 [00:10<00:01,  9.18it/s, distance=23]   89%|████████▉ | 89/100 [00:11<00:01,  6.71it/s, distance=22.6] 91%|█████████ | 91/100 [00:11<00:01,  7.67it/s, distance=22.1] 93%|█████████▎| 93/100 [00:11<00:00,  8.51it/s, distance=21.6] 95%|█████████▌| 95/100 [00:12<00:00,  9.21it/s, distance=20.9] 97%|█████████▋| 97/100 [00:12<00:00,  9.76it/s, distance=19.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.20it/s, distance=18]  100%|██████████| 100/100 [00:12<00:00,  8.04it/s, distance=14.9]
2025-06-18 20:31:52,971 [MPGD] >> Inference for image 8
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.1103e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -2.1126e+00, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8726, -1.7886, -1.8503, -1.7974, -1.7064, -1.8891, -1.7001, -1.8178],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01325838 0.07119235 0.02070746 0.05965463 0.36812703 0.00954177
 0.41779369 0.03972469]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4485, -1.4293, -1.3687, -1.5195, -1.5483, -1.4616, -1.4199, -1.5386],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09546059 0.14005841 0.47024984 0.02306466 0.01297038 0.07338004
 0.16907478 0.0157413 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1264, -1.0841, -1.0568, -1.0783, -1.0015, -1.0986, -0.9007, -0.9618],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00704792 0.0164262  0.02833014 0.01841241 0.08566104 0.01227773
 0.64226091 0.18958364]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8922, -0.8556, -0.8816, -0.8563, -0.9273, -0.7832, -0.9940, -0.8857],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05884338 0.12254304 0.07271922 0.12082643 0.02917508 0.52120316
 0.00769426 0.06699543]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7525, -0.7686, -0.7059, -0.7062, -0.6872, -0.8973, -0.6869, -0.7327],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06349411 0.04604623 0.16142103 0.16056891 0.23453389 0.00350893
 0.23590001 0.09452689]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7460, -0.7355, -0.7550, -0.8057, -0.7281, -0.8211, -0.8667, -0.8005],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.18345165 0.22624316 0.15318767 0.05559284 0.26253072 0.04088137
 0.01641899 0.0616936 ]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8064, -0.8079, -0.7835, -0.8110, -0.7152, -0.6969, -0.6967, -0.7263],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02983979 0.02891302 0.04716027 0.02722064 0.18494129 0.26630442
 0.26770839 0.14791218]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6774, -0.7779, -0.7353, -0.7613, -0.6754, -0.7430, -0.7842, -0.8158],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.3198143  0.04292697 0.10053424 0.05971822 0.33290884 0.08620868
 0.03780751 0.02008123]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6415, -0.6197, -0.7552, -0.7102, -0.7257, -0.6810, -0.7654, -0.7236],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.26177722 0.40493089 0.02692399 0.06632845 0.0485785  0.11883485
 0.02197759 0.05064853]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6120, -0.5988, -0.5624, -0.5970, -0.5664, -0.6501, -0.5703, -0.5721],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07226934 0.09409595 0.19506256 0.09758198 0.18013047 0.03373749
 0.16640548 0.16071673]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5920, -0.5678, -0.6473, -0.5735, -0.5906, -0.6225, -0.5993, -0.6262],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13611763 0.2209275  0.04510117 0.19739525 0.14003266 0.07407876
 0.11761401 0.06873302]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.168
key: ssim
value: 0.845
key: lpips
value: 0.100
key: facenet_l2
value: 0.369
key: adaface_l2
value: 0.659
ref_face_img: tensor([[[[ 0.5059,  0.5216,  0.5216,  ...,  0.2392,  0.2235,  0.2000],
          [ 0.5059,  0.5216,  0.5216,  ...,  0.2392,  0.2157,  0.2000],
          [ 0.5059,  0.5216,  0.5216,  ...,  0.2392,  0.2157,  0.2000],
          ...,
          [-0.8353, -0.8353, -0.8431,  ..., -0.1686, -0.1686, -0.1765],
          [-0.8275, -0.8275, -0.8275,  ..., -0.1686, -0.1686, -0.1843],
          [-0.8196, -0.8196, -0.8196,  ..., -0.1686, -0.1765, -0.1843]],

         [[ 0.4275,  0.4353,  0.4510,  ...,  0.2157,  0.1922,  0.1765],
          [ 0.4275,  0.4353,  0.4510,  ...,  0.2157,  0.1922,  0.1765],
          [ 0.4275,  0.4353,  0.4510,  ...,  0.2157,  0.1922,  0.1765],
          ...,
          [-0.8510, -0.8510, -0.8431,  ..., -0.5294, -0.5294, -0.5373],
          [-0.8431, -0.8431, -0.8431,  ..., -0.5373, -0.5451, -0.5451],
          [-0.8353, -0.8353, -0.8353,  ..., -0.5451, -0.5451, -0.5451]],

         [[ 0.3333,  0.3412,  0.3569,  ...,  0.1137,  0.0902,  0.0667],
          [ 0.3333,  0.3412,  0.3569,  ...,  0.1137,  0.0902,  0.0667],
          [ 0.3333,  0.3412,  0.3569,  ...,  0.1137,  0.0902,  0.0667],
          ...,
          [-0.8275, -0.8275, -0.8275,  ..., -0.7412, -0.7412, -0.7490],
          [-0.8196, -0.8275, -0.8275,  ..., -0.7490, -0.7490, -0.7490],
          [-0.8196, -0.8196, -0.8196,  ..., -0.7490, -0.7490, -0.7569]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.85it/s, distance=312]  3%|▎         | 3/100 [00:00<00:15,  6.45it/s, distance=146]  5%|▌         | 5/100 [00:00<00:11,  8.29it/s, distance=134]  7%|▋         | 7/100 [00:00<00:09,  9.36it/s, distance=123]  9%|▉         | 9/100 [00:01<00:13,  6.53it/s, distance=96.9] 11%|█         | 11/100 [00:01<00:11,  7.69it/s, distance=88.5] 13%|█▎        | 13/100 [00:01<00:10,  8.63it/s, distance=82.4] 15%|█▌        | 15/100 [00:01<00:09,  9.36it/s, distance=73.6] 17%|█▋        | 17/100 [00:02<00:12,  6.85it/s, distance=60.1] 19%|█▉        | 19/100 [00:02<00:10,  7.84it/s, distance=57.4] 21%|██        | 21/100 [00:02<00:09,  8.67it/s, distance=52.6] 23%|██▎       | 23/100 [00:02<00:08,  9.33it/s, distance=49.4] 25%|██▌       | 25/100 [00:03<00:10,  6.92it/s, distance=48.6] 27%|██▋       | 27/100 [00:03<00:09,  7.87it/s, distance=49]   29%|██▉       | 29/100 [00:03<00:08,  8.67it/s, distance=46.1] 31%|███       | 31/100 [00:03<00:07,  9.34it/s, distance=45.5] 33%|███▎      | 33/100 [00:04<00:09,  6.93it/s, distance=41.8] 35%|███▌      | 35/100 [00:04<00:08,  7.87it/s, distance=43.4] 37%|███▋      | 37/100 [00:04<00:07,  8.68it/s, distance=43.7] 39%|███▉      | 39/100 [00:04<00:06,  9.35it/s, distance=39.8] 41%|████      | 41/100 [00:05<00:08,  6.89it/s, distance=37.5] 43%|████▎     | 43/100 [00:05<00:07,  7.84it/s, distance=37.4] 45%|████▌     | 45/100 [00:05<00:06,  8.65it/s, distance=35.2] 47%|████▋     | 47/100 [00:05<00:05,  9.32it/s, distance=34.4] 49%|████▉     | 49/100 [00:06<00:07,  6.87it/s, distance=34]   51%|█████     | 51/100 [00:06<00:06,  7.82it/s, distance=32.9] 53%|█████▎    | 53/100 [00:06<00:05,  8.63it/s, distance=32.2] 55%|█████▌    | 55/100 [00:06<00:04,  9.30it/s, distance=31.4] 57%|█████▋    | 57/100 [00:07<00:06,  6.86it/s, distance=30.5] 59%|█████▉    | 59/100 [00:07<00:05,  7.82it/s, distance=30.4] 61%|██████    | 61/100 [00:07<00:04,  8.62it/s, distance=29.9] 63%|██████▎   | 63/100 [00:07<00:03,  9.30it/s, distance=29.4] 65%|██████▌   | 65/100 [00:08<00:05,  6.87it/s, distance=28.8] 67%|██████▋   | 67/100 [00:08<00:04,  7.81it/s, distance=28.6] 69%|██████▉   | 69/100 [00:08<00:03,  8.63it/s, distance=28.2] 71%|███████   | 71/100 [00:08<00:03,  9.29it/s, distance=27.7] 73%|███████▎  | 73/100 [00:09<00:03,  6.86it/s, distance=27.5] 75%|███████▌  | 75/100 [00:09<00:03,  7.80it/s, distance=27.1] 77%|███████▋  | 77/100 [00:09<00:02,  8.61it/s, distance=26.6] 79%|███████▉  | 79/100 [00:09<00:02,  9.28it/s, distance=26.3] 81%|████████  | 81/100 [00:10<00:02,  6.84it/s, distance=25.8] 83%|████████▎ | 83/100 [00:10<00:02,  7.79it/s, distance=25.4] 85%|████████▌ | 85/100 [00:10<00:01,  8.61it/s, distance=25]   87%|████████▋ | 87/100 [00:10<00:01,  9.29it/s, distance=24.6] 89%|████████▉ | 89/100 [00:11<00:01,  6.83it/s, distance=24]   91%|█████████ | 91/100 [00:11<00:01,  7.78it/s, distance=23.5] 93%|█████████▎| 93/100 [00:11<00:00,  8.59it/s, distance=22.9] 95%|█████████▌| 95/100 [00:11<00:00,  9.26it/s, distance=22.1] 97%|█████████▋| 97/100 [00:11<00:00,  9.80it/s, distance=20.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.22it/s, distance=18.8]100%|██████████| 100/100 [00:12<00:00,  8.18it/s, distance=15.6]
2025-06-18 20:32:06,296 [MPGD] >> Inference for image 9
reward_name: adaface, curr_reward: tensor([-2.1241e+00, -2.2264e+00, -2.1848e+00, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -2.1446e+00, -2.0566e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9760, -2.1068, -2.0693, -2.0911, -2.1884, -2.0882, -1.9091, -2.0004],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17042014 0.01245199 0.02637175 0.01704527 0.00243319 0.01804544
 0.6487818  0.10445041]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7597, -1.7642, -1.8337, -1.6236, -1.7748, -1.7795, -1.7293, -1.6991],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04173849 0.03814254 0.00950211 0.63490775 0.03085378 0.02809862
 0.07663966 0.14011705]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7028, -1.5227, -1.5700, -1.3790, -1.5333, -1.7746, -1.6329, -1.6265],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [1.35066561e-03 4.95420112e-02 1.92568724e-02 8.77775490e-01
 4.00805273e-02 3.21309687e-04 5.46297004e-03 6.21015335e-03]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5660, -1.5026, -1.2598, -1.3520, -1.4505, -1.5188, -1.5214, -1.5648],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00181953 0.0064642  0.83090498 0.13149923 0.01833991 0.00467394
 0.00443599 0.00186223]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2105, -1.1146, -1.0847, -1.2860, -1.0923, -1.0635, -1.0182, -1.1182],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00969586 0.06596508 0.12008128 0.00214358 0.10318272 0.18339735
 0.45407    0.06146412]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9946, -0.9755, -0.9099, -0.9459, -0.9557, -0.9184, -0.9797, -0.9121],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04190312 0.06139045 0.22792962 0.11093545 0.0911833  0.19214733
 0.05635907 0.21815167]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9157, -0.9073, -0.9301, -0.8803, -0.8793, -0.8018, -0.9038, -0.9728],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05444608 0.06436515 0.04080863 0.11039459 0.11253999 0.53113265
 0.06895087 0.01736205]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8246, -0.8975, -0.8283, -0.8430, -0.7704, -0.8302, -0.8143, -0.7538],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0829557  0.01930985 0.07703132 0.05742196 0.24547314 0.07415894
 0.10203975 0.34160934]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7932, -0.7183, -0.7451, -0.7099, -0.8074, -0.7494, -0.7868, -0.7606],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05098691 0.22837047 0.13362758 0.2700423  0.03842568 0.12254707
 0.05798311 0.09801689]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7272, -0.7194, -0.7362, -0.7122, -0.6984, -0.6858, -0.6776, -0.7571],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0856261  0.10020854 0.07159719 0.1156217  0.1525711  0.19609928
 0.23111746 0.04715863]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7456, -0.7228, -0.6874, -0.7030, -0.7106, -0.6801, -0.6868, -0.6173],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03323856 0.05243456 0.10636473 0.0778591  0.06684394 0.12318266
 0.10778267 0.43229378]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.535
key: ssim
value: 0.846
key: lpips
value: 0.101
key: facenet_l2
value: 0.311
key: adaface_l2
value: 0.579
ref_face_img: tensor([[[[ 0.5765,  0.5765,  0.5686,  ...,  0.8275,  0.8118,  0.7961],
          [ 0.5765,  0.5765,  0.5686,  ...,  0.8196,  0.7961,  0.7882],
          [ 0.5765,  0.5765,  0.5765,  ...,  0.8039,  0.7882,  0.7647],
          ...,
          [ 0.6627,  0.6627,  0.6549,  ...,  0.2941,  0.2784,  0.2627],
          [ 0.6627,  0.6627,  0.6549,  ...,  0.3255,  0.3020,  0.2941],
          [ 0.6627,  0.6549,  0.6549,  ...,  0.3412,  0.3255,  0.3176]],

         [[ 0.5608,  0.5608,  0.5529,  ...,  0.8196,  0.8039,  0.7961],
          [ 0.5608,  0.5608,  0.5608,  ...,  0.8196,  0.7961,  0.7804],
          [ 0.5608,  0.5608,  0.5608,  ...,  0.8039,  0.7804,  0.7647],
          ...,
          [ 0.6471,  0.6471,  0.6392,  ...,  0.0588,  0.0353,  0.0275],
          [ 0.6471,  0.6392,  0.6392,  ...,  0.0824,  0.0745,  0.0588],
          [ 0.6392,  0.6314,  0.6314,  ...,  0.0980,  0.0902,  0.0824]],

         [[ 0.6706,  0.6706,  0.6706,  ...,  0.8275,  0.8118,  0.7961],
          [ 0.6706,  0.6706,  0.6706,  ...,  0.8196,  0.7961,  0.7882],
          [ 0.6706,  0.6784,  0.6706,  ...,  0.8039,  0.7882,  0.7647],
          ...,
          [ 0.7412,  0.7333,  0.7333,  ..., -0.0353, -0.0510, -0.0667],
          [ 0.7333,  0.7333,  0.7255,  ..., -0.0118, -0.0275, -0.0353],
          [ 0.7255,  0.7176,  0.7176,  ...,  0.0039, -0.0039, -0.0118]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
  1%|          | 1/100 [00:00<00:35,  2.80it/s, distance=291]  3%|▎         | 3/100 [00:00<00:15,  6.38it/s, distance=171]  5%|▌         | 5/100 [00:00<00:11,  8.24it/s, distance=127]  7%|▋         | 7/100 [00:00<00:09,  9.33it/s, distance=115]  9%|▉         | 9/100 [00:01<00:13,  6.51it/s, distance=101] 11%|█         | 11/100 [00:01<00:11,  7.68it/s, distance=90] 13%|█▎        | 13/100 [00:01<00:10,  8.61it/s, distance=81.7] 15%|█▌        | 15/100 [00:01<00:09,  9.34it/s, distance=70.3] 17%|█▋        | 17/100 [00:02<00:12,  6.85it/s, distance=65.3] 19%|█▉        | 19/100 [00:02<00:10,  7.84it/s, distance=64.2] 21%|██        | 21/100 [00:02<00:09,  8.67it/s, distance=57.3] 23%|██▎       | 23/100 [00:02<00:08,  9.34it/s, distance=53.9] 25%|██▌       | 25/100 [00:03<00:10,  6.90it/s, distance=50]   27%|██▋       | 27/100 [00:03<00:09,  7.85it/s, distance=51.1] 29%|██▉       | 29/100 [00:03<00:08,  8.66it/s, distance=48.5] 31%|███       | 31/100 [00:03<00:07,  9.32it/s, distance=45.9] 33%|███▎      | 33/100 [00:04<00:09,  6.93it/s, distance=44.4] 35%|███▌      | 35/100 [00:04<00:08,  7.88it/s, distance=42.5] 37%|███▋      | 37/100 [00:04<00:07,  8.67it/s, distance=41.1] 39%|███▉      | 39/100 [00:04<00:06,  9.33it/s, distance=39]   41%|████      | 41/100 [00:05<00:08,  6.92it/s, distance=37.5] 43%|████▎     | 43/100 [00:05<00:07,  7.87it/s, distance=36.9] 45%|████▌     | 45/100 [00:05<00:06,  8.67it/s, distance=35.8] 47%|████▋     | 47/100 [00:05<00:05,  9.33it/s, distance=34.9] 49%|████▉     | 49/100 [00:06<00:07,  6.92it/s, distance=34.5] 51%|█████     | 51/100 [00:06<00:06,  7.86it/s, distance=33.6] 53%|█████▎    | 53/100 [00:06<00:05,  8.67it/s, distance=32.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.33it/s, distance=32.2] 57%|█████▋    | 57/100 [00:07<00:06,  6.93it/s, distance=31.7] 59%|█████▉    | 59/100 [00:07<00:05,  7.86it/s, distance=31.2] 61%|██████    | 61/100 [00:07<00:04,  8.66it/s, distance=30.7] 63%|██████▎   | 63/100 [00:07<00:03,  9.31it/s, distance=30.2] 65%|██████▌   | 65/100 [00:08<00:05,  6.96it/s, distance=29.6] 67%|██████▋   | 67/100 [00:08<00:04,  7.90it/s, distance=29.2] 69%|██████▉   | 69/100 [00:08<00:03,  8.69it/s, distance=28.8] 71%|███████   | 71/100 [00:08<00:03,  9.34it/s, distance=28.4] 73%|███████▎  | 73/100 [00:09<00:03,  6.97it/s, distance=28]   75%|███████▌  | 75/100 [00:09<00:03,  7.91it/s, distance=27.6] 77%|███████▋  | 77/100 [00:09<00:02,  8.70it/s, distance=27.1] 79%|███████▉  | 79/100 [00:09<00:02,  9.36it/s, distance=26.6] 81%|████████  | 81/100 [00:10<00:02,  7.00it/s, distance=26.3] 83%|████████▎ | 83/100 [00:10<00:02,  7.94it/s, distance=25.9] 85%|████████▌ | 85/100 [00:10<00:01,  8.72it/s, distance=25.4] 87%|████████▋ | 87/100 [00:10<00:01,  9.38it/s, distance=24.9] 89%|████████▉ | 89/100 [00:11<00:01,  7.00it/s, distance=24.4] 91%|█████████ | 91/100 [00:11<00:01,  7.93it/s, distance=23.8] 93%|█████████▎| 93/100 [00:11<00:00,  8.72it/s, distance=23.2] 95%|█████████▌| 95/100 [00:11<00:00,  9.37it/s, distance=22.3] 97%|█████████▋| 97/100 [00:11<00:00,  9.88it/s, distance=21.2] 99%|█████████▉| 99/100 [00:12<00:00, 10.28it/s, distance=19]  100%|██████████| 100/100 [00:12<00:00,  8.22it/s, distance=15.8]
2025-06-18 20:32:19,543 [MPGD] >> Inference for image 10
reward_name: adaface, curr_reward: tensor([-2.1257e+00, -2.1055e+00, -2.0942e+00, -5.1200e+08, -2.1178e+00,
        -5.1200e+08, -1.9454e+00, -2.1419e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0352, -1.9792, -1.9291, -2.0627, -2.0181, -2.0759, -1.9646, -1.9522],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04131422 0.12655748 0.34488663 0.02383832 0.0582439  0.01830378
 0.16955082 0.21730485]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6081, -1.6259, -1.7018, -1.6199, -1.5069, -1.7140, -1.6349, -1.5504],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07098086 0.04977746 0.01088999 0.05607569 0.53726087 0.00854394
 0.04153863 0.22493256]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5903, -1.4989, -1.4335, -1.4989, -1.4793, -1.5661, -1.4711, -1.5926],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0169269  0.10526668 0.38937198 0.10541561 0.15586364 0.02746233
 0.18351753 0.01617534]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3492, -1.3710, -1.4795, -1.2500, -1.4064, -1.3594, -1.4068, -1.4953],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09514393 0.06160874 0.00702916 0.69300747 0.03032886 0.07765213
 0.03010158 0.00512813]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3227, -1.3113, -1.3448, -1.1715, -1.3267, -1.2217, -1.3039, -1.1956],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02168065 0.02727407 0.01393614 0.44628506 0.02002395 0.16345474
 0.03160898 0.2757364 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1638, -1.1343, -1.1340, -1.1505, -1.1477, -1.1752, -1.1603, -1.2102],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10459016 0.1885504  0.1898165  0.13638715 0.1440743  0.08317532
 0.11206951 0.04133667]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1357, -1.0714, -1.1351, -0.9910, -1.0372, -1.1110, -1.1092, -1.1249],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02819628 0.1020605  0.02853659 0.5097696  0.20222071 0.04626797
 0.04795922 0.03498914]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9544, -0.9993, -1.0344, -0.9395, -1.0496, -0.9984, -0.9975, -0.9241],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17324172 0.07055279 0.03492608 0.2333497  0.02577974 0.07180132
 0.07310157 0.31724709]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9458, -0.9685, -0.8524, -0.9066, -0.9241, -0.9199, -0.9236, -0.9550],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06287704 0.03991859 0.40671897 0.13777027 0.0969387  0.10558938
 0.09790517 0.05228188]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8970, -0.8720, -0.8302, -0.8821, -0.8012, -0.8753, -0.8127, -0.9003],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04450434 0.07340908 0.16947389 0.05990465 0.30220909 0.06870411
 0.24013962 0.04165522]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8401, -0.7381, -0.8066, -0.7708, -0.8074, -0.7905, -0.8400, -0.7904],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04352169 0.33498768 0.0850354  0.17401517 0.0837657  0.11740299
 0.04361143 0.11765995]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 31.132
key: ssim
value: 0.855
key: lpips
value: 0.085
key: facenet_l2
value: 0.317
key: adaface_l2
value: 0.692
ref_face_img: tensor([[[[-0.6392, -0.6471, -0.6549,  ..., -0.8196, -0.8275, -0.8118],
          [-0.6314, -0.6392, -0.6392,  ..., -0.8275, -0.8196, -0.7961],
          [-0.6314, -0.6392, -0.6314,  ..., -0.8118, -0.8118, -0.8039],
          ...,
          [-0.7412, -0.6471, -0.6000,  ..., -0.8745, -0.8510, -0.8118],
          [-0.6627, -0.6078, -0.5216,  ..., -0.8588, -0.8431, -0.8196],
          [-0.6471, -0.5922, -0.5137,  ..., -0.8588, -0.8510, -0.8196]],

         [[-0.5137, -0.5216, -0.5294,  ..., -0.7725, -0.7804, -0.7882],
          [-0.5059, -0.5137, -0.5137,  ..., -0.7804, -0.7725, -0.7647],
          [-0.5059, -0.5137, -0.5059,  ..., -0.7804, -0.7804, -0.7804],
          ...,
          [-0.8196, -0.7569, -0.7412,  ..., -0.8588, -0.8431, -0.8039],
          [-0.7412, -0.7098, -0.6784,  ..., -0.8275, -0.8196, -0.8118],
          [-0.7176, -0.7020, -0.6627,  ..., -0.8275, -0.8275, -0.8118]],

         [[-0.2549, -0.2627, -0.2706,  ..., -0.8510, -0.8588, -0.8588],
          [-0.2392, -0.2549, -0.2549,  ..., -0.8588, -0.8510, -0.8353],
          [-0.2471, -0.2549, -0.2471,  ..., -0.8431, -0.8431, -0.8353],
          ...,
          [-0.9294, -0.8745, -0.8667,  ..., -0.9059, -0.8824, -0.8431],
          [-0.8588, -0.8431, -0.7961,  ..., -0.8902, -0.8745, -0.8510],
          [-0.8431, -0.8275, -0.7804,  ..., -0.8902, -0.8824, -0.8510]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.90it/s, distance=262]  3%|▎         | 3/100 [00:00<00:14,  6.51it/s, distance=178]  5%|▌         | 5/100 [00:00<00:11,  8.35it/s, distance=136]  7%|▋         | 7/100 [00:00<00:09,  9.41it/s, distance=117]  9%|▉         | 9/100 [00:01<00:14,  6.46it/s, distance=98.9] 11%|█         | 11/100 [00:01<00:11,  7.63it/s, distance=85.2] 13%|█▎        | 13/100 [00:01<00:10,  8.57it/s, distance=78]   15%|█▌        | 15/100 [00:01<00:09,  9.31it/s, distance=72.2] 17%|█▋        | 17/100 [00:02<00:12,  6.72it/s, distance=66.7] 19%|█▉        | 19/100 [00:02<00:10,  7.72it/s, distance=62.5] 21%|██        | 21/100 [00:02<00:09,  8.56it/s, distance=55.6] 23%|██▎       | 23/100 [00:02<00:08,  9.24it/s, distance=52.5] 25%|██▌       | 25/100 [00:03<00:11,  6.80it/s, distance=50.4] 27%|██▋       | 27/100 [00:03<00:09,  7.76it/s, distance=47.7] 29%|██▉       | 29/100 [00:03<00:08,  8.58it/s, distance=45.2] 31%|███       | 31/100 [00:03<00:07,  9.26it/s, distance=44.1] 33%|███▎      | 33/100 [00:04<00:09,  6.79it/s, distance=41.3] 35%|███▌      | 35/100 [00:04<00:08,  7.75it/s, distance=40.7] 37%|███▋      | 37/100 [00:04<00:07,  8.57it/s, distance=39.7] 39%|███▉      | 39/100 [00:04<00:06,  9.25it/s, distance=37.9] 41%|████      | 41/100 [00:05<00:08,  6.80it/s, distance=38.5] 43%|████▎     | 43/100 [00:05<00:07,  7.75it/s, distance=36.1] 45%|████▌     | 45/100 [00:05<00:06,  8.56it/s, distance=35.4] 47%|████▋     | 47/100 [00:05<00:05,  9.25it/s, distance=34.6] 49%|████▉     | 49/100 [00:06<00:07,  6.81it/s, distance=33.6] 51%|█████     | 51/100 [00:06<00:06,  7.76it/s, distance=33.2] 53%|█████▎    | 53/100 [00:06<00:05,  8.58it/s, distance=32.3] 55%|█████▌    | 55/100 [00:06<00:04,  9.25it/s, distance=31.6] 57%|█████▋    | 57/100 [00:07<00:06,  6.80it/s, distance=31]   59%|█████▉    | 59/100 [00:07<00:05,  7.74it/s, distance=30.6] 61%|██████    | 61/100 [00:07<00:04,  8.56it/s, distance=30.1] 63%|██████▎   | 63/100 [00:07<00:04,  9.24it/s, distance=29.6] 65%|██████▌   | 65/100 [00:08<00:05,  6.78it/s, distance=29.2] 67%|██████▋   | 67/100 [00:08<00:04,  7.73it/s, distance=28.7] 69%|██████▉   | 69/100 [00:08<00:03,  8.54it/s, distance=28.3] 71%|███████   | 71/100 [00:08<00:03,  9.23it/s, distance=27.8] 73%|███████▎  | 73/100 [00:09<00:03,  6.77it/s, distance=27.4] 75%|███████▌  | 75/100 [00:09<00:03,  7.73it/s, distance=27]   77%|███████▋  | 77/100 [00:09<00:02,  8.54it/s, distance=26.6] 79%|███████▉  | 79/100 [00:09<00:02,  9.22it/s, distance=26.3] 81%|████████  | 81/100 [00:10<00:02,  6.80it/s, distance=25.9] 83%|████████▎ | 83/100 [00:10<00:02,  7.74it/s, distance=25.5] 85%|████████▌ | 85/100 [00:10<00:01,  8.57it/s, distance=25]   87%|████████▋ | 87/100 [00:10<00:01,  9.25it/s, distance=24.6] 89%|████████▉ | 89/100 [00:11<00:01,  6.78it/s, distance=24.1] 91%|█████████ | 91/100 [00:11<00:01,  7.73it/s, distance=23.6] 93%|█████████▎| 93/100 [00:11<00:00,  8.55it/s, distance=22.9] 95%|█████████▌| 95/100 [00:11<00:00,  9.23it/s, distance=22.1] 97%|█████████▋| 97/100 [00:12<00:00,  9.78it/s, distance=21]   99%|█████████▉| 99/100 [00:12<00:00, 10.20it/s, distance=18.9]100%|██████████| 100/100 [00:12<00:00,  8.11it/s, distance=15.7]
2025-06-18 20:32:33,010 [MPGD] >> Inference for image 11
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.0783e+00, -2.2212e+00, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -2.0839e+00, -2.1131e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7078, -1.8392, -2.0100, -1.8656, -1.9060, -1.8480, -1.7101, -1.8505],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.4526103  0.03269018 0.00107399 0.01929135 0.00859983 0.02744405
 0.4322008  0.0260895 ]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6225, -1.6194, -1.5644, -1.4869, -1.5954, -1.5194, -1.5319, -1.5256],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02329378 0.02477037 0.07440269 0.35028701 0.03999741 0.18290325
 0.14255141 0.16179408]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5105, -1.3732, -1.2890, -1.5080, -1.4041, -1.5277, -1.4127, -1.4444],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00823273 0.12825498 0.69064603 0.0086567  0.06920936 0.00584301
 0.05827118 0.03088602]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3271, -1.2117, -1.3085, -1.2375, -1.3365, -1.2502, -1.3167, -1.1139],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01039414 0.10436349 0.01505419 0.06238605 0.00861105 0.04837473
 0.01278052 0.73803581]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1464, -1.1733, -1.2321, -1.2539, -1.1860, -1.2117, -1.1533, -1.1097],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17996666 0.10501173 0.03240602 0.02095889 0.08150983 0.04873326
 0.15665641 0.3747572 ]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1763, -0.9714, -1.0769, -1.0430, -1.1592, -1.0800, -1.0277, -1.0852],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00855772 0.51525344 0.06245691 0.12300054 0.01202483 0.05865695
 0.16714025 0.05290937]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8917, -0.8587, -0.8801, -0.9279, -0.9002, -0.8745, -0.8874, -0.8733],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10568397 0.20426355 0.13330591 0.05120512 0.08905086 0.14891494
 0.11510436 0.15247129]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8170, -0.8838, -0.8763, -0.8497, -0.8476, -0.7719, -0.7966, -0.7956],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12304975 0.03233087 0.03753585 0.06388521 0.06668845 0.3028045
 0.18493369 0.18877168]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7709, -0.8547, -0.7986, -0.7931, -0.7200, -0.7940, -0.7695, -0.8166],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13841152 0.02586603 0.07946237 0.08875225 0.38268572 0.08720097
 0.14221934 0.0554018 ]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6950, -0.7529, -0.6839, -0.7351, -0.7267, -0.7046, -0.6938, -0.6605],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13540941 0.04252335 0.16901368 0.06076194 0.0718959  0.11182365
 0.13865794 0.26991412]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6912, -0.6578, -0.6952, -0.6348, -0.6805, -0.6903, -0.6840, -0.6269],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07153853 0.13939211 0.06598621 0.22084665 0.08849185 0.07283064
 0.08250966 0.25840435]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 31.380
key: ssim
value: 0.872
key: lpips
value: 0.076
key: facenet_l2
value: 0.340
key: adaface_l2
value: 0.657
ref_face_img: tensor([[[[ 0.3255,  0.3804,  0.4196,  ..., -0.6235, -0.6471, -0.6549],
          [ 0.3176,  0.3804,  0.4353,  ..., -0.6235, -0.6471, -0.6471],
          [ 0.3020,  0.3647,  0.4275,  ..., -0.6235, -0.6392, -0.6471],
          ...,
          [ 0.7255,  0.7255,  0.7255,  ...,  0.6157,  0.6157,  0.6157],
          [ 0.7333,  0.7255,  0.7255,  ...,  0.6157,  0.6157,  0.6157],
          [ 0.7333,  0.7255,  0.7176,  ...,  0.6000,  0.6000,  0.6000]],

         [[ 0.3098,  0.3647,  0.4039,  ..., -0.6314, -0.6471, -0.6549],
          [ 0.3020,  0.3647,  0.4118,  ..., -0.6235, -0.6471, -0.6471],
          [ 0.2863,  0.3490,  0.4118,  ..., -0.6235, -0.6392, -0.6471],
          ...,
          [ 0.6314,  0.6314,  0.6314,  ...,  0.6157,  0.6157,  0.6157],
          [ 0.6392,  0.6392,  0.6314,  ...,  0.6078,  0.6078,  0.6078],
          [ 0.6392,  0.6392,  0.6314,  ...,  0.6000,  0.6000,  0.6000]],

         [[ 0.2784,  0.3412,  0.3804,  ..., -0.6314, -0.6549, -0.6627],
          [ 0.2706,  0.3333,  0.3882,  ..., -0.6314, -0.6471, -0.6549],
          [ 0.2549,  0.3176,  0.3804,  ..., -0.6235, -0.6471, -0.6549],
          ...,
          [ 0.5765,  0.5765,  0.5686,  ...,  0.6157,  0.6157,  0.6157],
          [ 0.5843,  0.5765,  0.5686,  ...,  0.6078,  0.6078,  0.6078],
          [ 0.5843,  0.5765,  0.5686,  ...,  0.6000,  0.5922,  0.5922]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.87it/s, distance=282]  3%|▎         | 3/100 [00:00<00:15,  6.45it/s, distance=155]  5%|▌         | 5/100 [00:00<00:11,  8.30it/s, distance=125]  7%|▋         | 7/100 [00:00<00:09,  9.37it/s, distance=117]  9%|▉         | 9/100 [00:01<00:14,  6.49it/s, distance=97.8] 11%|█         | 11/100 [00:01<00:11,  7.66it/s, distance=89.9] 13%|█▎        | 13/100 [00:01<00:10,  8.59it/s, distance=81.2] 15%|█▌        | 15/100 [00:01<00:09,  9.32it/s, distance=78.2] 17%|█▋        | 17/100 [00:02<00:12,  6.87it/s, distance=67.1] 19%|█▉        | 19/100 [00:02<00:10,  7.86it/s, distance=83.6] 21%|██        | 21/100 [00:02<00:09,  8.68it/s, distance=72.2] 23%|██▎       | 23/100 [00:02<00:08,  9.35it/s, distance=64]   25%|██▌       | 25/100 [00:03<00:10,  6.93it/s, distance=58.7] 27%|██▋       | 27/100 [00:03<00:09,  7.87it/s, distance=47.9] 29%|██▉       | 29/100 [00:03<00:08,  8.67it/s, distance=42.5] 31%|███       | 31/100 [00:03<00:07,  9.33it/s, distance=39.6] 33%|███▎      | 33/100 [00:04<00:09,  6.90it/s, distance=37.2] 35%|███▌      | 35/100 [00:04<00:08,  7.85it/s, distance=35.6] 37%|███▋      | 37/100 [00:04<00:07,  8.65it/s, distance=34.8] 39%|███▉      | 39/100 [00:04<00:06,  9.31it/s, distance=33.6] 41%|████      | 41/100 [00:05<00:08,  6.88it/s, distance=33.1] 43%|████▎     | 43/100 [00:05<00:07,  7.82it/s, distance=32.2] 45%|████▌     | 45/100 [00:05<00:06,  8.63it/s, distance=31.5] 47%|████▋     | 47/100 [00:05<00:05,  9.29it/s, distance=30.7] 49%|████▉     | 49/100 [00:06<00:07,  6.89it/s, distance=30.3] 51%|█████     | 51/100 [00:06<00:06,  7.83it/s, distance=29.6] 53%|█████▎    | 53/100 [00:06<00:05,  8.64it/s, distance=29]   55%|█████▌    | 55/100 [00:06<00:04,  9.30it/s, distance=28.5] 57%|█████▋    | 57/100 [00:07<00:06,  6.86it/s, distance=28.2] 59%|█████▉    | 59/100 [00:07<00:05,  7.81it/s, distance=27.7] 61%|██████    | 61/100 [00:07<00:04,  8.61it/s, distance=27.4] 63%|██████▎   | 63/100 [00:07<00:03,  9.28it/s, distance=27]   65%|██████▌   | 65/100 [00:08<00:05,  6.86it/s, distance=26.7] 67%|██████▋   | 67/100 [00:08<00:04,  7.81it/s, distance=26.4] 69%|██████▉   | 69/100 [00:08<00:03,  8.61it/s, distance=26.1] 71%|███████   | 71/100 [00:08<00:03,  9.27it/s, distance=25.7] 73%|███████▎  | 73/100 [00:09<00:03,  6.88it/s, distance=25.4] 75%|███████▌  | 75/100 [00:09<00:03,  7.82it/s, distance=25.1] 77%|███████▋  | 77/100 [00:09<00:02,  8.62it/s, distance=24.9] 79%|███████▉  | 79/100 [00:09<00:02,  9.28it/s, distance=24.6] 81%|████████  | 81/100 [00:10<00:02,  6.88it/s, distance=24.3] 83%|████████▎ | 83/100 [00:10<00:02,  7.83it/s, distance=24]   85%|████████▌ | 85/100 [00:10<00:01,  8.63it/s, distance=23.6] 87%|████████▋ | 87/100 [00:10<00:01,  9.29it/s, distance=23.3] 89%|████████▉ | 89/100 [00:11<00:01,  6.91it/s, distance=22.8] 91%|█████████ | 91/100 [00:11<00:01,  7.85it/s, distance=22.4] 93%|█████████▎| 93/100 [00:11<00:00,  8.64it/s, distance=21.9] 95%|█████████▌| 95/100 [00:11<00:00,  9.30it/s, distance=21.2] 97%|█████████▋| 97/100 [00:11<00:00,  9.83it/s, distance=20.2] 99%|█████████▉| 99/100 [00:12<00:00, 10.24it/s, distance=18.2]100%|██████████| 100/100 [00:13<00:00,  7.32it/s, distance=15] 
2025-06-18 20:32:47,856 [MPGD] >> Inference for image 12
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.1874e+00, -5.1200e+08, -5.1200e+08, -2.1493e+00,
        -1.9828e+00, -5.1200e+08, -2.0475e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7377, -1.8447, -1.7995, -1.9179, -1.7586, -1.6897, -1.7955, -1.6666],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10909571 0.01282139 0.03170958 0.00297145 0.07175363 0.28497438
 0.03435808 0.45231578]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7145, -1.6062, -1.5977, -1.6825, -1.7030, -1.6934, -1.6913, -1.7106],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03648236 0.31835113 0.37692669 0.06918935 0.04587031 0.05563172
 0.05807572 0.03947271]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4873, -1.5781, -1.4457, -1.6750, -1.6470, -1.6168, -1.6355, -1.6609],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.27142914 0.04416621 0.62413316 0.00635276 0.01112079 0.02037116
 0.01399952 0.00842725]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3500, -1.1422, -1.2343, -1.1251, -1.3328, -1.2313, -1.2432, -1.3361],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00536095 0.34187041 0.05421659 0.48102475 0.00755894 0.05753939
 0.04534767 0.0070813 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0424, -0.9429, -0.9569, -0.9850, -1.0207, -0.8853, -0.9107, -1.0274],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01754181 0.12839918 0.09697172 0.05529645 0.02707599 0.40638534
 0.24464952 0.02367998]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9386, -0.8913, -0.9165, -0.8768, -0.9326, -0.8365, -0.8387, -0.8260],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02916379 0.0751355  0.04536717 0.10032203 0.03286599 0.22491994
 0.21503797 0.27718761]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8522, -0.8144, -0.8208, -0.7640, -0.8139, -0.7784, -0.8131, -0.8695],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04939595 0.10504753 0.09255049 0.28786101 0.1062793  0.21594962
 0.10801162 0.03490448]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8584, -0.7826, -0.8442, -0.8049, -0.7860, -0.8222, -0.7321, -0.8008],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03148441 0.14321035 0.0418095  0.09172248 0.13390692 0.06494834
 0.39326535 0.09965265]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7254, -0.7325, -0.7525, -0.7450, -0.7233, -0.7608, -0.7727, -0.7374],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17150894 0.14863498 0.09966619 0.11583949 0.17860999 0.08442136
 0.06657691 0.13474214]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8016, -0.8028, -0.6907, -0.7393, -0.7308, -0.7775, -0.7406, -0.7593],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03828418 0.03741127 0.35182129 0.13313343 0.15801372 0.06206974
 0.12988762 0.08937875]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6993, -0.6929, -0.7195, -0.6865, -0.7393, -0.7162, -0.7180, -0.7272],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15335331 0.17434753 0.10246697 0.19811998 0.06897114 0.10942263
 0.10550868 0.08780977]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.314
key: ssim
value: 0.832
key: lpips
value: 0.094
key: facenet_l2
value: 0.400
key: adaface_l2
value: 0.689
ref_face_img: tensor([[[[ 0.3412,  0.3412,  0.3412,  ..., -0.3333, -0.3333, -0.3333],
          [ 0.3412,  0.3412,  0.3412,  ..., -0.3255, -0.3255, -0.3255],
          [ 0.3333,  0.3412,  0.3412,  ..., -0.3176, -0.3176, -0.3176],
          ...,
          [ 0.2627,  0.2549,  0.2549,  ..., -0.6157, -0.6078, -0.6078],
          [ 0.2627,  0.2549,  0.2549,  ..., -0.5922, -0.5922, -0.5922],
          [ 0.2627,  0.2627,  0.2549,  ..., -0.5765, -0.5686, -0.5686]],

         [[-0.2471, -0.2314, -0.2235,  ..., -0.2941, -0.2941, -0.2941],
          [-0.2471, -0.2392, -0.2235,  ..., -0.2941, -0.2941, -0.2941],
          [-0.2471, -0.2392, -0.2235,  ..., -0.2863, -0.2863, -0.2863],
          ...,
          [-0.0353, -0.0431, -0.0431,  ..., -0.5373, -0.5294, -0.5294],
          [-0.0353, -0.0431, -0.0431,  ..., -0.5216, -0.5216, -0.5137],
          [-0.0353, -0.0431, -0.0431,  ..., -0.5137, -0.5059, -0.5059]],

         [[-0.4745, -0.4667, -0.4510,  ..., -0.3098, -0.3098, -0.3098],
          [-0.4824, -0.4667, -0.4510,  ..., -0.3098, -0.3098, -0.3098],
          [-0.4824, -0.4667, -0.4510,  ..., -0.3020, -0.3020, -0.3098],
          ...,
          [-0.7647, -0.7804, -0.7882,  ..., -0.5843, -0.5843, -0.5843],
          [-0.7647, -0.7725, -0.7804,  ..., -0.5765, -0.5765, -0.5765],
          [-0.7569, -0.7725, -0.7804,  ..., -0.5686, -0.5686, -0.5686]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:32,  3.01it/s, distance=296]  3%|▎         | 3/100 [00:00<00:14,  6.64it/s, distance=167]  5%|▌         | 5/100 [00:00<00:11,  8.45it/s, distance=142]  7%|▋         | 7/100 [00:00<00:09,  9.47it/s, distance=122]  9%|▉         | 9/100 [00:01<00:13,  6.58it/s, distance=107] 11%|█         | 11/100 [00:01<00:11,  7.74it/s, distance=96.5] 13%|█▎        | 13/100 [00:01<00:10,  8.65it/s, distance=84.6] 15%|█▌        | 15/100 [00:01<00:09,  9.36it/s, distance=78.6] 17%|█▋        | 17/100 [00:02<00:12,  6.64it/s, distance=74.8] 19%|█▉        | 19/100 [00:02<00:10,  7.62it/s, distance=67.3] 21%|██        | 21/100 [00:02<00:09,  8.48it/s, distance=60.8] 23%|██▎       | 23/100 [00:02<00:08,  9.19it/s, distance=56]   25%|██▌       | 25/100 [00:03<00:11,  6.80it/s, distance=48.6] 27%|██▋       | 27/100 [00:03<00:09,  7.77it/s, distance=46.3] 29%|██▉       | 29/100 [00:03<00:08,  8.58it/s, distance=42.7] 31%|███       | 31/100 [00:03<00:07,  9.26it/s, distance=40.7] 33%|███▎      | 33/100 [00:04<00:09,  6.82it/s, distance=37.8] 35%|███▌      | 35/100 [00:04<00:08,  7.78it/s, distance=36.9] 37%|███▋      | 37/100 [00:04<00:07,  8.59it/s, distance=35.5] 39%|███▉      | 39/100 [00:04<00:06,  9.26it/s, distance=34.1] 41%|████      | 41/100 [00:05<00:08,  6.86it/s, distance=33.2] 43%|████▎     | 43/100 [00:05<00:07,  7.81it/s, distance=32.1] 45%|████▌     | 45/100 [00:05<00:06,  8.61it/s, distance=31.4] 47%|████▋     | 47/100 [00:05<00:05,  9.27it/s, distance=30.8] 49%|████▉     | 49/100 [00:06<00:07,  6.89it/s, distance=30]   51%|█████     | 51/100 [00:06<00:06,  7.83it/s, distance=29.6] 53%|█████▎    | 53/100 [00:06<00:05,  8.63it/s, distance=29]   55%|█████▌    | 55/100 [00:06<00:04,  9.29it/s, distance=28.5] 57%|█████▋    | 57/100 [00:07<00:06,  6.89it/s, distance=27.9] 59%|█████▉    | 59/100 [00:07<00:05,  7.83it/s, distance=27.6] 61%|██████    | 61/100 [00:07<00:04,  8.63it/s, distance=27.4] 63%|██████▎   | 63/100 [00:07<00:03,  9.29it/s, distance=27]   65%|██████▌   | 65/100 [00:08<00:05,  6.89it/s, distance=26.7] 67%|██████▋   | 67/100 [00:08<00:04,  7.83it/s, distance=26.4] 69%|██████▉   | 69/100 [00:08<00:03,  8.63it/s, distance=26]   71%|███████   | 71/100 [00:08<00:03,  9.29it/s, distance=25.6] 73%|███████▎  | 73/100 [00:09<00:03,  6.89it/s, distance=25.3] 75%|███████▌  | 75/100 [00:09<00:03,  7.83it/s, distance=25]   77%|███████▋  | 77/100 [00:09<00:02,  8.63it/s, distance=24.7] 79%|███████▉  | 79/100 [00:09<00:02,  9.29it/s, distance=24.4] 81%|████████  | 81/100 [00:10<00:02,  6.89it/s, distance=24.1] 83%|████████▎ | 83/100 [00:10<00:02,  7.83it/s, distance=23.8] 85%|████████▌ | 85/100 [00:10<00:01,  8.62it/s, distance=23.5] 87%|████████▋ | 87/100 [00:10<00:01,  9.28it/s, distance=23.1] 89%|████████▉ | 89/100 [00:11<00:01,  6.85it/s, distance=22.7] 91%|█████████ | 91/100 [00:11<00:01,  7.80it/s, distance=22.3] 93%|█████████▎| 93/100 [00:11<00:00,  8.60it/s, distance=21.8] 95%|█████████▌| 95/100 [00:11<00:00,  9.28it/s, distance=21.1] 97%|█████████▋| 97/100 [00:11<00:00,  9.81it/s, distance=20.1] 99%|█████████▉| 99/100 [00:12<00:00, 10.22it/s, distance=18.1]100%|██████████| 100/100 [00:12<00:00,  8.16it/s, distance=15] 
2025-06-18 20:33:01,235 [MPGD] >> Inference for image 13
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.1392e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.2071, -2.0586, -2.1069, -1.9929, -2.0024, -1.8931, -2.2449, -2.1348],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [1.43059609e-03 2.78673629e-02 1.06028409e-02 1.03683247e-01
 8.58647109e-02 7.63809106e-01 6.71370064e-04 6.07076614e-03]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6069, -1.7509, -1.9337, -1.7898, -1.6603, -1.7787, -1.8115, -1.7674],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.65955876 0.03699996 0.00095621 0.01701186 0.22661297 0.02123806
 0.01102234 0.02659983]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2938, -1.5585, -1.4197, -1.5861, -1.3758, -1.6350, -1.5299, -1.4346],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.73926359 0.00371489 0.05959834 0.00213907 0.14361104 0.00080446
 0.00657926 0.04428934]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3580, -1.3081, -1.3278, -1.2359, -1.3061, -1.3056, -1.2244, -1.1829],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01419762 0.03854197 0.0259844  0.16349947 0.04013583 0.0405323
 0.20561813 0.47149029]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0859, -1.1242, -1.2214, -1.0981, -1.2272, -1.0608, -1.1153, -1.1607],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.20795883 0.0966961  0.01384762 0.16319599 0.01234131 0.34376882
 0.11553478 0.04665655]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1522, -1.1059, -1.0887, -0.9221, -1.0118, -1.0918, -0.9642, -0.9519],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00444739 0.0112424  0.01586335 0.44399925 0.07373823 0.01488748
 0.19126397 0.24455792]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9102, -0.8624, -0.8833, -0.8900, -0.8931, -0.9410, -0.8903, -0.9064],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08830309 0.22948595 0.1512914  0.1321235  0.12435623 0.04770075
 0.13143966 0.09529943]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9060, -0.8159, -0.8170, -0.8655, -0.8169, -0.8853, -0.9133, -0.8076],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03258999 0.19727091 0.19324167 0.07322295 0.19334259 0.04927635
 0.02814918 0.23290636]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8638, -0.7576, -0.8561, -0.8399, -0.7841, -0.8051, -0.7807, -0.8377],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0367117  0.30682494 0.04276063 0.05919827 0.1806655  0.1187277
 0.19334752 0.06176374]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7853, -0.7570, -0.7025, -0.7702, -0.7391, -0.7595, -0.7910, -0.7121],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05327391 0.09388069 0.27898291 0.072134   0.13437826 0.08920653
 0.04755788 0.23058582]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7337, -0.7334, -0.7713, -0.7185, -0.6604, -0.6981, -0.6822, -0.7114],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06863076 0.06908443 0.03236079 0.09298169 0.29743444 0.14005154
 0.19229987 0.10715648]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.092
key: ssim
value: 0.817
key: lpips
value: 0.126
key: facenet_l2
value: 0.293
key: adaface_l2
value: 0.568
ref_face_img: tensor([[[[-0.8980, -0.8980, -0.9059,  ..., -0.8824, -0.8745, -0.8667],
          [-0.8980, -0.8980, -0.9059,  ..., -0.8824, -0.8745, -0.8667],
          [-0.8980, -0.8980, -0.8980,  ..., -0.8745, -0.8745, -0.8667],
          ...,
          [-0.6627, -0.6627, -0.6627,  ..., -0.5843, -0.5843, -0.5843],
          [-0.6549, -0.6627, -0.6627,  ..., -0.5765, -0.5765, -0.5765],
          [-0.6549, -0.6549, -0.6549,  ..., -0.5686, -0.5686, -0.5686]],

         [[-0.8824, -0.8824, -0.8824,  ..., -0.8510, -0.8510, -0.8431],
          [-0.8824, -0.8824, -0.8824,  ..., -0.8510, -0.8510, -0.8431],
          [-0.8824, -0.8824, -0.8824,  ..., -0.8510, -0.8510, -0.8431],
          ...,
          [-0.6471, -0.6471, -0.6471,  ..., -0.6000, -0.6000, -0.6000],
          [-0.6471, -0.6471, -0.6471,  ..., -0.6000, -0.6000, -0.6000],
          [-0.6392, -0.6392, -0.6392,  ..., -0.5922, -0.5922, -0.5922]],

         [[-0.8588, -0.8588, -0.8588,  ..., -0.8118, -0.8118, -0.8118],
          [-0.8588, -0.8588, -0.8588,  ..., -0.8118, -0.8118, -0.8118],
          [-0.8588, -0.8588, -0.8588,  ..., -0.8118, -0.8118, -0.8118],
          ...,
          [-0.5686, -0.5686, -0.5686,  ..., -0.5608, -0.5608, -0.5608],
          [-0.5608, -0.5608, -0.5608,  ..., -0.5529, -0.5529, -0.5529],
          [-0.5608, -0.5608, -0.5608,  ..., -0.5529, -0.5529, -0.5529]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.91it/s, distance=305]  3%|▎         | 3/100 [00:00<00:14,  6.53it/s, distance=198]  5%|▌         | 5/100 [00:00<00:11,  8.34it/s, distance=154]  7%|▋         | 7/100 [00:00<00:09,  9.39it/s, distance=133]  9%|▉         | 9/100 [00:01<00:14,  6.48it/s, distance=113] 11%|█         | 11/100 [00:01<00:11,  7.65it/s, distance=99.3] 13%|█▎        | 13/100 [00:01<00:10,  8.58it/s, distance=89]   15%|█▌        | 15/100 [00:01<00:09,  9.31it/s, distance=83.4] 17%|█▋        | 17/100 [00:02<00:12,  6.83it/s, distance=80.8] 19%|█▉        | 19/100 [00:02<00:10,  7.82it/s, distance=73.9] 21%|██        | 21/100 [00:02<00:09,  8.64it/s, distance=69.8] 23%|██▎       | 23/100 [00:02<00:08,  9.32it/s, distance=65.1] 25%|██▌       | 25/100 [00:03<00:10,  6.98it/s, distance=58.9] 27%|██▋       | 27/100 [00:03<00:09,  7.92it/s, distance=56.8] 29%|██▉       | 29/100 [00:03<00:08,  8.71it/s, distance=54.6] 31%|███       | 31/100 [00:03<00:07,  9.35it/s, distance=52.7] 33%|███▎      | 33/100 [00:04<00:09,  6.97it/s, distance=49.3] 35%|███▌      | 35/100 [00:04<00:08,  7.90it/s, distance=49.2] 37%|███▋      | 37/100 [00:04<00:07,  8.69it/s, distance=47.7] 39%|███▉      | 39/100 [00:04<00:06,  9.34it/s, distance=45.6] 41%|████      | 41/100 [00:05<00:08,  6.94it/s, distance=43.7] 43%|████▎     | 43/100 [00:05<00:07,  7.88it/s, distance=42.7] 45%|████▌     | 45/100 [00:05<00:06,  8.67it/s, distance=41.2] 47%|████▋     | 47/100 [00:05<00:05,  9.31it/s, distance=39.7] 49%|████▉     | 49/100 [00:06<00:07,  6.92it/s, distance=38.7] 51%|█████     | 51/100 [00:06<00:06,  7.87it/s, distance=38.2] 53%|█████▎    | 53/100 [00:06<00:05,  8.66it/s, distance=37]   55%|█████▌    | 55/100 [00:06<00:04,  9.31it/s, distance=36.1] 57%|█████▋    | 57/100 [00:07<00:06,  6.92it/s, distance=35.3] 59%|█████▉    | 59/100 [00:07<00:05,  7.87it/s, distance=34.4] 61%|██████    | 61/100 [00:07<00:04,  8.66it/s, distance=33.7] 63%|██████▎   | 63/100 [00:07<00:03,  9.32it/s, distance=33]   65%|██████▌   | 65/100 [00:08<00:05,  6.92it/s, distance=32.2] 67%|██████▋   | 67/100 [00:08<00:04,  7.86it/s, distance=31.7] 69%|██████▉   | 69/100 [00:08<00:03,  8.66it/s, distance=31.2] 71%|███████   | 71/100 [00:08<00:03,  9.32it/s, distance=30.6] 73%|███████▎  | 73/100 [00:09<00:03,  6.94it/s, distance=30.1] 75%|███████▌  | 75/100 [00:09<00:03,  7.88it/s, distance=29.6] 77%|███████▋  | 77/100 [00:09<00:02,  8.67it/s, distance=29.1] 79%|███████▉  | 79/100 [00:09<00:02,  9.32it/s, distance=28.5] 81%|████████  | 81/100 [00:10<00:02,  6.94it/s, distance=27.9] 83%|████████▎ | 83/100 [00:10<00:02,  7.88it/s, distance=27.4] 85%|████████▌ | 85/100 [00:10<00:01,  8.67it/s, distance=26.8] 87%|████████▋ | 87/100 [00:10<00:01,  9.32it/s, distance=26.2] 89%|████████▉ | 89/100 [00:11<00:01,  6.90it/s, distance=25.6] 91%|█████████ | 91/100 [00:11<00:01,  7.84it/s, distance=25]   93%|█████████▎| 93/100 [00:11<00:00,  8.64it/s, distance=24.2] 95%|█████████▌| 95/100 [00:11<00:00,  9.29it/s, distance=23.3] 97%|█████████▋| 97/100 [00:11<00:00,  9.81it/s, distance=22]   99%|█████████▉| 99/100 [00:12<00:00, 10.22it/s, distance=19.7]100%|██████████| 100/100 [00:12<00:00,  8.21it/s, distance=16.6]
2025-06-18 20:33:14,534 [MPGD] >> Inference for image 14
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -2.0867e+00, -5.1200e+08, -2.1406e+00,
        -5.1200e+08, -2.0730e+00, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0708, -2.1110, -2.0836, -2.0923, -2.1019, -1.9161, -1.9336, -2.1647],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.024258   0.01085668 0.01880459 0.0158072  0.01303226 0.5358497
 0.37767681 0.00371475]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5341, -1.5679, -1.4362, -1.5155, -1.5992, -1.5864, -1.3351, -1.6592],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01555658 0.00791163 0.1103074  0.02256473 0.00422849 0.00546293
 0.83269483 0.0012734 ]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2051, -1.1308, -1.2308, -1.2103, -1.2107, -1.1459, -1.2715, -1.0804],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04265908 0.18827679 0.02548303 0.03846458 0.0381134  0.13932071
 0.01129114 0.51639128]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1674, -1.0351, -1.1483, -1.1654, -1.1785, -1.0282, -1.1947, -1.1400],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02709607 0.38241811 0.03974615 0.02820315 0.02168902 0.43822193
 0.01570696 0.04691861]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1182, -1.0026, -1.0095, -1.0040, -0.9960, -1.0302, -0.9116, -0.9329],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00666484 0.06728946 0.05859555 0.06546879 0.07684191 0.03876167
 0.41522841 0.27114937]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9822, -0.8307, -0.9308, -0.9393, -0.8826, -0.9014, -0.8363, -0.8780],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01520884 0.31475112 0.0425384  0.03588184 0.11157607 0.07653799
 0.28130229 0.12220344]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8323, -0.8191, -0.8906, -0.8055, -0.8326, -0.8186, -0.8685, -0.8450],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12679121 0.16509362 0.03947486 0.21637369 0.12585034 0.16671179
 0.06146589 0.0982386 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8353, -0.8334, -0.8024, -0.8363, -0.8451, -0.8165, -0.8562, -0.8408],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11389055 0.11834332 0.21969251 0.11174044 0.09360511 0.16581988
 0.07497711 0.10193108]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8155, -0.7768, -0.8441, -0.8273, -0.8939, -0.7643, -0.7873, -0.7735],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08622378 0.18707211 0.04867589 0.0681121  0.01799236 0.2400945
 0.15178308 0.20004619]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8012, -0.8005, -0.7828, -0.7963, -0.8496, -0.8146, -0.7676, -0.7952],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11363429 0.11542154 0.16421357 0.12543987 0.04318172 0.08696967
 0.22280109 0.12833825]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7827, -0.7826, -0.8075, -0.7754, -0.8117, -0.7981, -0.7901, -0.8292],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15830953 0.15847662 0.09629095 0.18315048 0.08862828 0.11619691
 0.13650069 0.06244654]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 25.051
key: ssim
value: 0.850
key: lpips
value: 0.095
key: facenet_l2
value: 0.551
key: adaface_l2
value: 0.710
ref_face_img: tensor([[[[0.1216, 0.1216, 0.1216,  ..., 0.1686, 0.1686, 0.1686],
          [0.1216, 0.1216, 0.1216,  ..., 0.1686, 0.1686, 0.1686],
          [0.1216, 0.1216, 0.1216,  ..., 0.1686, 0.1686, 0.1686],
          ...,
          [0.4196, 0.3961, 0.3569,  ..., 0.6471, 0.6627, 0.6627],
          [0.4196, 0.3961, 0.3569,  ..., 0.6471, 0.6627, 0.6627],
          [0.4118, 0.3882, 0.3569,  ..., 0.6471, 0.6549, 0.6549]],

         [[0.6314, 0.6314, 0.6314,  ..., 0.6627, 0.6627, 0.6627],
          [0.6314, 0.6314, 0.6314,  ..., 0.6627, 0.6627, 0.6627],
          [0.6314, 0.6314, 0.6314,  ..., 0.6706, 0.6627, 0.6706],
          ...,
          [0.5843, 0.5686, 0.5608,  ..., 0.7255, 0.7333, 0.7333],
          [0.5843, 0.5765, 0.5608,  ..., 0.7255, 0.7333, 0.7412],
          [0.5843, 0.5686, 0.5608,  ..., 0.7176, 0.7333, 0.7333]],

         [[0.8745, 0.8745, 0.8745,  ..., 0.2627, 0.2627, 0.2627],
          [0.8745, 0.8745, 0.8745,  ..., 0.2627, 0.2627, 0.2627],
          [0.8745, 0.8745, 0.8745,  ..., 0.2706, 0.2627, 0.2627],
          ...,
          [0.7882, 0.7882, 0.7804,  ..., 0.7882, 0.8039, 0.8118],
          [0.7882, 0.7882, 0.7804,  ..., 0.7882, 0.8039, 0.8118],
          [0.7882, 0.7882, 0.7804,  ..., 0.7882, 0.8039, 0.8039]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.91it/s, distance=327]  3%|▎         | 3/100 [00:00<00:14,  6.51it/s, distance=176]  5%|▌         | 5/100 [00:00<00:11,  8.33it/s, distance=135]  7%|▋         | 7/100 [00:00<00:09,  9.37it/s, distance=117]  9%|▉         | 9/100 [00:01<00:14,  6.45it/s, distance=105] 11%|█         | 11/100 [00:01<00:11,  7.61it/s, distance=96.4] 13%|█▎        | 13/100 [00:01<00:10,  8.55it/s, distance=84.4] 15%|█▌        | 15/100 [00:01<00:09,  9.28it/s, distance=76.5] 17%|█▋        | 17/100 [00:02<00:12,  6.81it/s, distance=69]   19%|█▉        | 19/100 [00:02<00:10,  7.80it/s, distance=63.9] 21%|██        | 21/100 [00:02<00:09,  8.62it/s, distance=61.1] 23%|██▎       | 23/100 [00:02<00:08,  9.29it/s, distance=59.9] 25%|██▌       | 25/100 [00:03<00:10,  6.89it/s, distance=54.8] 27%|██▋       | 27/100 [00:03<00:09,  7.84it/s, distance=52.8] 29%|██▉       | 29/100 [00:03<00:08,  8.64it/s, distance=50.3] 31%|███       | 31/100 [00:03<00:07,  9.30it/s, distance=48.5] 33%|███▎      | 33/100 [00:04<00:09,  6.92it/s, distance=45.4] 35%|███▌      | 35/100 [00:04<00:08,  7.86it/s, distance=42.9] 37%|███▋      | 37/100 [00:04<00:07,  8.65it/s, distance=40.6] 39%|███▉      | 39/100 [00:04<00:06,  9.31it/s, distance=38.9] 41%|████      | 41/100 [00:05<00:08,  6.94it/s, distance=37.7] 43%|████▎     | 43/100 [00:05<00:07,  7.87it/s, distance=36.9] 45%|████▌     | 45/100 [00:05<00:06,  8.67it/s, distance=36]   47%|████▋     | 47/100 [00:05<00:05,  9.32it/s, distance=35.3] 49%|████▉     | 49/100 [00:06<00:07,  6.93it/s, distance=34.4] 51%|█████     | 51/100 [00:06<00:06,  7.86it/s, distance=33.6] 53%|█████▎    | 53/100 [00:06<00:05,  8.66it/s, distance=33]   55%|█████▌    | 55/100 [00:06<00:04,  9.31it/s, distance=32.2] 57%|█████▋    | 57/100 [00:07<00:06,  6.92it/s, distance=31.6] 59%|█████▉    | 59/100 [00:07<00:05,  7.85it/s, distance=31.1] 61%|██████    | 61/100 [00:07<00:04,  8.65it/s, distance=30.6] 63%|██████▎   | 63/100 [00:07<00:03,  9.32it/s, distance=30.1] 65%|██████▌   | 65/100 [00:08<00:05,  6.91it/s, distance=29.5] 67%|██████▋   | 67/100 [00:08<00:04,  7.86it/s, distance=29.1] 69%|██████▉   | 69/100 [00:08<00:03,  8.65it/s, distance=28.7] 71%|███████   | 71/100 [00:08<00:03,  9.30it/s, distance=28.3] 73%|███████▎  | 73/100 [00:09<00:03,  6.92it/s, distance=27.9] 75%|███████▌  | 75/100 [00:09<00:03,  7.86it/s, distance=27.5] 77%|███████▋  | 77/100 [00:09<00:02,  8.65it/s, distance=27.1] 79%|███████▉  | 79/100 [00:09<00:02,  9.31it/s, distance=26.6] 81%|████████  | 81/100 [00:10<00:02,  6.93it/s, distance=26.1] 83%|████████▎ | 83/100 [00:10<00:02,  7.87it/s, distance=25.7] 85%|████████▌ | 85/100 [00:10<00:01,  8.66it/s, distance=25.3] 87%|████████▋ | 87/100 [00:10<00:01,  9.32it/s, distance=24.8] 89%|████████▉ | 89/100 [00:11<00:01,  6.94it/s, distance=24.3] 91%|█████████ | 91/100 [00:11<00:01,  7.87it/s, distance=23.7] 93%|█████████▎| 93/100 [00:11<00:00,  8.67it/s, distance=23.1] 95%|█████████▌| 95/100 [00:11<00:00,  9.32it/s, distance=22.3] 97%|█████████▋| 97/100 [00:11<00:00,  9.84it/s, distance=21.2] 99%|█████████▉| 99/100 [00:12<00:00, 10.24it/s, distance=19.1]100%|██████████| 100/100 [00:12<00:00,  8.20it/s, distance=15.9]
2025-06-18 20:33:27,784 [MPGD] >> Inference for image 15
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -2.0628e+00, -2.1167e+00,
        -5.1200e+08, -2.0843e+00, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8897, -1.9206, -1.7856, -1.9689, -1.9947, -1.7758, -1.9862, -1.9392],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04963731 0.02673682 0.39765366 0.01017898 0.00607032 0.4840813
 0.00719573 0.01844587]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5764, -1.6073, -1.6158, -1.4583, -1.5555, -1.4663, -1.4712, -1.4501],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02279037 0.01228778 0.01036341 0.24176465 0.03460959 0.20600394
 0.18699166 0.28518859]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1607, -1.0464, -1.1266, -1.0085, -1.1699, -1.0620, -1.0808, -1.1658],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02097652 0.20610013 0.04149772 0.44048147 0.01742938 0.15096018
 0.10363499 0.01891962]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8125, -0.8401, -0.8360, -1.0409, -0.9932, -0.8713, -0.8067, -0.9095],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.26209977 0.15110622 0.16386247 0.00272022 0.00706995 0.08089212
 0.2945799  0.03766935]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7036, -0.5975, -0.6800, -0.7905, -0.5993, -0.6649, -0.6714, -0.5730],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02714001 0.22649324 0.04349916 0.00477184 0.21837983 0.05878902
 0.05168288 0.36924401]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5161, -0.5358, -0.5391, -0.5383, -0.5122, -0.5606, -0.5670, -0.5708],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.19466561 0.13141636 0.1229191  0.12495853 0.2104546  0.07999956
 0.07031042 0.06527582]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4908, -0.4777, -0.4408, -0.4590, -0.4694, -0.4889, -0.5345, -0.5080],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0942869  0.12263777 0.25641472 0.17801851 0.14464893 0.09787587
 0.03933077 0.06678653]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5864, -0.4231, -0.4153, -0.4239, -0.4380, -0.4210, -0.4198, -0.3645],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00411177 0.10780637 0.1259432  0.10615141 0.08010752 0.11257173
 0.11523673 0.34807127]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3599, -0.3465, -0.3705, -0.3359, -0.3633, -0.3366, -0.3876, -0.3747],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11649225 0.15230222 0.09438771 0.18825114 0.10891271 0.18585853
 0.06702563 0.0867698 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3221, -0.3603, -0.3701, -0.3323, -0.3282, -0.3717, -0.3499, -0.3005],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16554803 0.07714126 0.0634782  0.13517172 0.14676307 0.06147019
 0.09501719 0.25541035]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3380, -0.2831, -0.3254, -0.3045, -0.3193, -0.3377, -0.3366, -0.3385],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08531006 0.25604086 0.10970328 0.16683336 0.12413667 0.08581583
 0.08772888 0.08443107]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.787
key: ssim
value: 0.840
key: lpips
value: 0.092
key: facenet_l2
value: 0.344
key: adaface_l2
value: 0.471
ref_face_img: tensor([[[[ 0.6471,  0.6157,  0.5922,  ...,  0.7176,  0.7255,  0.7020],
          [ 0.5765,  0.5765,  0.5686,  ...,  0.7098,  0.7098,  0.7255],
          [ 0.5686,  0.5686,  0.5686,  ...,  0.7020,  0.7255,  0.7176],
          ...,
          [ 0.9608,  0.9686,  0.9686,  ..., -0.7255, -0.6941, -0.6941],
          [ 0.9608,  0.9529,  0.9686,  ..., -0.7098, -0.6941, -0.7020],
          [ 0.9686,  0.9608,  0.9529,  ..., -0.7412, -0.7647, -0.7647]],

         [[ 0.8039,  0.7804,  0.7569,  ...,  0.9059,  0.9137,  0.8902],
          [ 0.7569,  0.7490,  0.7412,  ...,  0.8980,  0.8980,  0.9137],
          [ 0.7647,  0.7647,  0.7647,  ...,  0.8902,  0.9137,  0.9137],
          ...,
          [ 0.8667,  0.8745,  0.8745,  ..., -0.7412, -0.7020, -0.7176],
          [ 0.8667,  0.8588,  0.8745,  ..., -0.7255, -0.7098, -0.7176],
          [ 0.8824,  0.8667,  0.8588,  ..., -0.7569, -0.7804, -0.7804]],

         [[ 0.9686,  0.9686,  0.9608,  ...,  1.0000,  1.0000,  0.9843],
          [ 0.9843,  0.9922,  0.9843,  ...,  0.9922,  0.9922,  1.0000],
          [ 0.9922,  1.0000,  0.9843,  ...,  0.9843,  1.0000,  1.0000],
          ...,
          [ 0.9765,  0.9843,  0.9843,  ..., -0.7569, -0.7333, -0.7804],
          [ 0.9765,  0.9686,  0.9843,  ..., -0.7098, -0.7098, -0.7647],
          [ 0.9922,  0.9765,  0.9686,  ..., -0.7490, -0.7725, -0.7882]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.90it/s, distance=295]  3%|▎         | 3/100 [00:00<00:14,  6.49it/s, distance=160]  5%|▌         | 5/100 [00:00<00:11,  8.32it/s, distance=134]  7%|▋         | 7/100 [00:00<00:09,  9.37it/s, distance=126]  9%|▉         | 9/100 [00:01<00:13,  6.50it/s, distance=123] 11%|█         | 11/100 [00:01<00:11,  7.67it/s, distance=102] 13%|█▎        | 13/100 [00:01<00:10,  8.59it/s, distance=92.9] 15%|█▌        | 15/100 [00:01<00:09,  9.32it/s, distance=85.1] 17%|█▋        | 17/100 [00:02<00:12,  6.88it/s, distance=74.6] 19%|█▉        | 19/100 [00:02<00:10,  7.87it/s, distance=71.5] 21%|██        | 21/100 [00:02<00:09,  8.68it/s, distance=66.8] 23%|██▎       | 23/100 [00:02<00:08,  9.35it/s, distance=63.5] 25%|██▌       | 25/100 [00:03<00:10,  6.97it/s, distance=56.1] 27%|██▋       | 27/100 [00:03<00:09,  7.91it/s, distance=51.4] 29%|██▉       | 29/100 [00:03<00:08,  8.70it/s, distance=48.1] 31%|███       | 31/100 [00:03<00:07,  9.35it/s, distance=45.1] 33%|███▎      | 33/100 [00:04<00:09,  7.01it/s, distance=42.8] 35%|███▌      | 35/100 [00:04<00:08,  7.94it/s, distance=42]   37%|███▋      | 37/100 [00:04<00:07,  8.72it/s, distance=40.1] 39%|███▉      | 39/100 [00:04<00:06,  9.37it/s, distance=38.3] 41%|████      | 41/100 [00:05<00:08,  6.99it/s, distance=37]   43%|████▎     | 43/100 [00:05<00:07,  7.92it/s, distance=36.3] 45%|████▌     | 45/100 [00:05<00:06,  8.70it/s, distance=35.3] 47%|████▋     | 47/100 [00:05<00:05,  9.35it/s, distance=34.2] 49%|████▉     | 49/100 [00:06<00:07,  6.97it/s, distance=33.2] 51%|█████     | 51/100 [00:06<00:06,  7.90it/s, distance=32.6] 53%|█████▎    | 53/100 [00:06<00:05,  8.68it/s, distance=32]   55%|█████▌    | 55/100 [00:06<00:04,  9.33it/s, distance=31.3] 57%|█████▋    | 57/100 [00:07<00:06,  6.97it/s, distance=30.6] 59%|█████▉    | 59/100 [00:07<00:05,  7.91it/s, distance=30.2] 61%|██████    | 61/100 [00:07<00:04,  8.70it/s, distance=29.8] 63%|██████▎   | 63/100 [00:07<00:03,  9.35it/s, distance=29.3] 65%|██████▌   | 65/100 [00:08<00:05,  6.98it/s, distance=28.8] 67%|██████▋   | 67/100 [00:08<00:04,  7.90it/s, distance=28.4] 69%|██████▉   | 69/100 [00:08<00:03,  8.69it/s, distance=28]   71%|███████   | 71/100 [00:08<00:03,  9.34it/s, distance=27.6] 73%|███████▎  | 73/100 [00:09<00:03,  6.98it/s, distance=27.1] 75%|███████▌  | 75/100 [00:09<00:03,  7.91it/s, distance=26.8] 77%|███████▋  | 77/100 [00:09<00:02,  8.70it/s, distance=26.5] 79%|███████▉  | 79/100 [00:09<00:02,  9.36it/s, distance=26]   81%|████████  | 81/100 [00:10<00:02,  6.99it/s, distance=25.7] 83%|████████▎ | 83/100 [00:10<00:02,  7.92it/s, distance=25.3] 85%|████████▌ | 85/100 [00:10<00:01,  8.71it/s, distance=24.8] 87%|████████▋ | 87/100 [00:10<00:01,  9.35it/s, distance=24.4] 89%|████████▉ | 89/100 [00:11<00:01,  6.98it/s, distance=23.9] 91%|█████████ | 91/100 [00:11<00:01,  7.91it/s, distance=23.4] 93%|█████████▎| 93/100 [00:11<00:00,  8.69it/s, distance=22.8] 95%|█████████▌| 95/100 [00:11<00:00,  9.34it/s, distance=22]   97%|█████████▋| 97/100 [00:11<00:00,  9.86it/s, distance=20.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.25it/s, distance=18.8]100%|██████████| 100/100 [00:12<00:00,  8.24it/s, distance=15.6]
2025-06-18 20:33:41,007 [MPGD] >> Inference for image 16
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -1.9923e+00, -2.0305e+00, -1.9921e+00,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9003, -2.0103, -2.0041, -2.0120, -1.8153, -1.9347, -2.0801, -1.9716],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13186848 0.01460538 0.01651936 0.01411414 0.72136686 0.06622539
 0.00361738 0.03168301]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7628, -1.7233, -1.7109, -1.6977, -1.7497, -1.8614, -1.6509, -1.7565],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04619372 0.10162644 0.13046461 0.16989959 0.06003444 0.00641894
 0.43295695 0.05240531]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1986, -1.3721, -1.3734, -1.3523, -1.1806, -1.2411, -1.3413, -1.4112],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.32901433 0.0102214  0.00997198 0.01519573 0.47137689 0.14060313
 0.01893442 0.00468212]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0009, -1.0518, -1.0723, -1.0282, -1.0150, -0.9852, -1.0615, -0.9511],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13684776 0.04940476 0.03279463 0.07928227 0.10327539 0.18727003
 0.0407313  0.37039387]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8371, -0.9474, -0.8014, -0.9024, -0.8300, -0.9074, -0.8464, -0.8286],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1461285  0.01610579 0.29875048 0.03963002 0.16864344 0.03587801
 0.12139104 0.17347271]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7268, -0.7342, -0.6594, -0.7822, -0.8558, -0.8338, -0.6697, -0.7017],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0907948  0.07826892 0.34920524 0.02999082 0.00687724 0.01068397
 0.28431789 0.14986111]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5828, -0.6349, -0.6582, -0.6105, -0.5192, -0.5535, -0.4963, -0.5899],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0713792  0.02516294 0.01578238 0.04096513 0.25451915 0.12824504
 0.40207513 0.06187102]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6463, -0.7539, -0.4825, -0.5413, -0.5520, -0.6167, -0.5731, -0.4369],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0087411  0.00101631 0.23129658 0.0714401  0.05765383 0.01580561
 0.03780636 0.57624011]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4361, -0.4679, -0.4237, -0.4124, -0.3795, -0.3987, -0.4659, -0.5853],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09771954 0.05168303 0.12523055 0.15707449 0.30302399 0.20651017
 0.05381438 0.00494385]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3738, -0.4948, -0.3774, -0.4724, -0.3908, -0.4878, -0.4697, -0.6019],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.319362   0.02841993 0.29741419 0.04450672 0.22729765 0.03270478
 0.04695623 0.0033385 ]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3096, -0.4523, -0.3843, -0.4176, -0.4171, -0.3724, -0.4073, -0.4103],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.48235802 0.02778613 0.10823123 0.05559432 0.05615662 0.13723035
 0.06832534 0.06431799]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 31.009
key: ssim
value: 0.845
key: lpips
value: 0.097
key: facenet_l2
value: 0.232
key: adaface_l2
value: 0.415
ref_face_img: tensor([[[[-0.4196, -0.3961, -0.3804,  ..., -0.8824, -0.8745, -0.8745],
          [-0.4431, -0.4196, -0.4039,  ..., -0.8980, -0.8902, -0.8902],
          [-0.4588, -0.4431, -0.4275,  ..., -0.9059, -0.9059, -0.8980],
          ...,
          [-0.8902, -0.8902, -0.8745,  ..., -0.2392, -0.2392, -0.2471],
          [-0.8980, -0.8902, -0.8745,  ..., -0.2157, -0.2235, -0.2314],
          [-0.8980, -0.8902, -0.8745,  ..., -0.2000, -0.2078, -0.2157]],

         [[-0.6941, -0.6784, -0.6627,  ..., -0.9294, -0.9294, -0.9294],
          [-0.6941, -0.6863, -0.6706,  ..., -0.9373, -0.9294, -0.9294],
          [-0.7020, -0.6941, -0.6863,  ..., -0.9373, -0.9294, -0.9294],
          ...,
          [-0.7647, -0.7490, -0.7255,  ..., -0.3333, -0.3333, -0.3412],
          [-0.7647, -0.7490, -0.7333,  ..., -0.3098, -0.3176, -0.3255],
          [-0.7647, -0.7490, -0.7333,  ..., -0.3020, -0.3098, -0.3098]],

         [[-0.8353, -0.8353, -0.8275,  ..., -0.9529, -0.9529, -0.9529],
          [-0.8353, -0.8353, -0.8275,  ..., -0.9529, -0.9529, -0.9529],
          [-0.8353, -0.8275, -0.8275,  ..., -0.9529, -0.9529, -0.9451],
          ...,
          [-0.6078, -0.5843, -0.5686,  ..., -0.4745, -0.4745, -0.4745],
          [-0.6078, -0.5843, -0.5686,  ..., -0.4510, -0.4510, -0.4588],
          [-0.6078, -0.5843, -0.5686,  ..., -0.4431, -0.4431, -0.4510]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.99it/s, distance=282]  3%|▎         | 3/100 [00:00<00:14,  6.60it/s, distance=157]  5%|▌         | 5/100 [00:00<00:11,  8.42it/s, distance=127]  7%|▋         | 7/100 [00:00<00:09,  9.46it/s, distance=120]  9%|▉         | 9/100 [00:01<00:14,  6.49it/s, distance=102] 11%|█         | 11/100 [00:01<00:11,  7.66it/s, distance=98] 13%|█▎        | 13/100 [00:01<00:10,  8.59it/s, distance=89.1] 15%|█▌        | 15/100 [00:01<00:09,  9.31it/s, distance=83.1] 17%|█▋        | 17/100 [00:02<00:12,  6.79it/s, distance=76.4] 19%|█▉        | 19/100 [00:02<00:10,  7.77it/s, distance=67.6] 21%|██        | 21/100 [00:02<00:09,  8.60it/s, distance=62.3] 23%|██▎       | 23/100 [00:02<00:08,  9.28it/s, distance=58.3] 25%|██▌       | 25/100 [00:03<00:11,  6.82it/s, distance=53.9] 27%|██▋       | 27/100 [00:03<00:09,  7.77it/s, distance=52]   29%|██▉       | 29/100 [00:03<00:08,  8.58it/s, distance=48.1] 31%|███       | 31/100 [00:03<00:07,  9.26it/s, distance=46.4] 33%|███▎      | 33/100 [00:04<00:09,  6.84it/s, distance=42.5] 35%|███▌      | 35/100 [00:04<00:08,  7.78it/s, distance=41.6] 37%|███▋      | 37/100 [00:04<00:07,  8.59it/s, distance=40.5] 39%|███▉      | 39/100 [00:04<00:06,  9.26it/s, distance=38.8] 41%|████      | 41/100 [00:05<00:08,  6.83it/s, distance=37.5] 43%|████▎     | 43/100 [00:05<00:07,  7.78it/s, distance=36.5] 45%|████▌     | 45/100 [00:05<00:06,  8.58it/s, distance=35.7] 47%|████▋     | 47/100 [00:05<00:05,  9.26it/s, distance=34.8] 49%|████▉     | 49/100 [00:06<00:07,  6.86it/s, distance=33.9] 51%|█████     | 51/100 [00:06<00:06,  7.81it/s, distance=33.5] 53%|█████▎    | 53/100 [00:06<00:05,  8.62it/s, distance=32.7] 55%|█████▌    | 55/100 [00:06<00:04,  9.28it/s, distance=32.3] 57%|█████▋    | 57/100 [00:07<00:06,  6.89it/s, distance=32]   59%|█████▉    | 59/100 [00:07<00:05,  7.84it/s, distance=31.2] 61%|██████    | 61/100 [00:07<00:04,  8.63it/s, distance=30.7] 63%|██████▎   | 63/100 [00:08<00:05,  6.69it/s, distance=30.1] 65%|██████▌   | 65/100 [00:08<00:06,  5.69it/s, distance=29.6] 67%|██████▋   | 67/100 [00:08<00:04,  6.71it/s, distance=29.2] 69%|██████▉   | 69/100 [00:08<00:04,  7.64it/s, distance=28.8] 71%|███████   | 71/100 [00:09<00:03,  8.46it/s, distance=28.4] 73%|███████▎  | 73/100 [00:09<00:04,  6.49it/s, distance=28]   75%|███████▌  | 75/100 [00:09<00:03,  7.46it/s, distance=27.5] 77%|███████▋  | 77/100 [00:09<00:02,  8.31it/s, distance=27.1] 79%|███████▉  | 79/100 [00:10<00:02,  9.03it/s, distance=26.7] 81%|████████  | 81/100 [00:10<00:02,  6.77it/s, distance=26.2] 83%|████████▎ | 83/100 [00:10<00:02,  7.72it/s, distance=25.9] 85%|████████▌ | 85/100 [00:10<00:01,  8.53it/s, distance=25.4] 87%|████████▋ | 87/100 [00:11<00:01,  9.21it/s, distance=24.9] 89%|████████▉ | 89/100 [00:11<00:01,  6.84it/s, distance=24.5] 91%|█████████ | 91/100 [00:11<00:01,  7.79it/s, distance=23.9] 93%|█████████▎| 93/100 [00:11<00:00,  8.59it/s, distance=23.2] 95%|█████████▌| 95/100 [00:12<00:00,  9.26it/s, distance=22.4] 97%|█████████▋| 97/100 [00:12<00:00,  9.79it/s, distance=21.2] 99%|█████████▉| 99/100 [00:12<00:00, 10.21it/s, distance=19.1]100%|██████████| 100/100 [00:12<00:00,  7.97it/s, distance=15.9]
2025-06-18 20:33:54,685 [MPGD] >> Inference for image 17
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08, -1.9089e+00,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8893, -1.8798, -1.9871, -1.9016, -1.8498, -1.6987, -1.8448, -1.8934],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01856967 0.02245511 0.00262344 0.01451315 0.04091918 0.83864315
 0.04517505 0.01710125]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6834, -1.5062, -1.5687, -1.7388, -1.7267, -1.7235, -1.6612, -1.6235],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01938018 0.67053179 0.19233194 0.00640776 0.00814814 0.0086867
 0.03024225 0.06427125]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3411, -1.3994, -1.3599, -1.3069, -1.3510, -1.4353, -1.2470, -1.3735],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08311296 0.02586477 0.05703057 0.16442186 0.06818406 0.01262463
 0.54531247 0.04344868]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2804, -1.2722, -1.2992, -1.1410, -1.1386, -1.2359, -1.2227, -1.1109],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01399623 0.01650364 0.00960258 0.22756195 0.23866161 0.03409036
 0.04439291 0.41519072]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0198, -1.1341, -0.9597, -0.9383, -0.9989, -0.9476, -1.1898, -1.0389],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06248209 0.0063564  0.20780971 0.31919054 0.09482497 0.26462817
 0.00208439 0.04262374]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9185, -0.7376, -0.8649, -0.8756, -0.9349, -1.0071, -0.8919, -0.8378],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01954356 0.72856422 0.05708295 0.04605069 0.01407898 0.00331973
 0.03325154 0.09810832]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7296, -0.8522, -0.8153, -0.9175, -0.9283, -0.8504, -0.7390, -0.8409],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.42838942 0.03693453 0.07719841 0.01000077 0.00804906 0.03829191
 0.35481948 0.04631643]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7268, -0.6154, -0.7334, -0.7669, -0.7538, -0.6769, -0.7556, -0.6738],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05444652 0.50586118 0.04776594 0.02443944 0.03175684 0.14773892
 0.03065617 0.15733499]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6256, -0.6018, -0.6347, -0.5713, -0.5946, -0.5559, -0.6677, -0.5584],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.060375   0.09723385 0.05036461 0.1788682  0.11221918 0.24320744
 0.02601663 0.2317151 ]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6181, -0.5651, -0.5184, -0.5069, -0.5753, -0.5675, -0.5890, -0.5442],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03149991 0.09091267 0.23129536 0.29119373 0.07406119 0.08659229
 0.05635339 0.13809147]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4747, -0.5095, -0.4805, -0.5278, -0.4907, -0.4981, -0.5539, -0.4860],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.19644298 0.09795623 0.17491839 0.06796954 0.14275785 0.12296708
 0.04030646 0.15668147]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.616
key: ssim
value: 0.860
key: lpips
value: 0.085
key: facenet_l2
value: 0.295
key: adaface_l2
value: 0.482
ref_face_img: tensor([[[[ 0.2471,  0.2392,  0.2314,  ...,  0.3490,  0.3490,  0.3490],
          [ 0.2235,  0.2157,  0.2078,  ...,  0.3412,  0.3490,  0.3490],
          [ 0.1843,  0.1843,  0.1686,  ...,  0.3333,  0.3490,  0.3490],
          ...,
          [ 0.4510,  0.4510,  0.4510,  ..., -0.4588, -0.4275, -0.4118],
          [ 0.4431,  0.4431,  0.4431,  ..., -0.4588, -0.4275, -0.4118],
          [ 0.4353,  0.4353,  0.4353,  ..., -0.4510, -0.4275, -0.4118]],

         [[ 0.3255,  0.3255,  0.3098,  ...,  0.4353,  0.4353,  0.4353],
          [ 0.3020,  0.3020,  0.2863,  ...,  0.4275,  0.4353,  0.4353],
          [ 0.2706,  0.2627,  0.2471,  ...,  0.4196,  0.4275,  0.4353],
          ...,
          [ 0.5059,  0.5059,  0.5059,  ..., -0.4667, -0.4275, -0.4118],
          [ 0.4980,  0.4980,  0.4980,  ..., -0.4667, -0.4353, -0.4118],
          [ 0.4902,  0.4902,  0.4902,  ..., -0.4667, -0.4353, -0.4196]],

         [[ 0.4196,  0.4275,  0.4039,  ...,  0.5373,  0.5373,  0.5373],
          [ 0.3961,  0.3882,  0.3804,  ...,  0.5294,  0.5373,  0.5373],
          [ 0.3569,  0.3490,  0.3412,  ...,  0.5137,  0.5216,  0.5294],
          ...,
          [ 0.5922,  0.5922,  0.5922,  ..., -0.4588, -0.4196, -0.3961],
          [ 0.5843,  0.5843,  0.5843,  ..., -0.4588, -0.4275, -0.4039],
          [ 0.5686,  0.5686,  0.5686,  ..., -0.4588, -0.4275, -0.4039]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.91it/s, distance=286]  3%|▎         | 3/100 [00:00<00:14,  6.51it/s, distance=194]  5%|▌         | 5/100 [00:00<00:11,  8.34it/s, distance=152]  7%|▋         | 7/100 [00:00<00:09,  9.40it/s, distance=128]  9%|▉         | 9/100 [00:01<00:14,  6.42it/s, distance=110] 11%|█         | 11/100 [00:01<00:11,  7.59it/s, distance=97.3] 13%|█▎        | 13/100 [00:01<00:10,  8.52it/s, distance=89.2] 15%|█▌        | 15/100 [00:01<00:09,  9.26it/s, distance=84]   17%|█▋        | 17/100 [00:02<00:12,  6.76it/s, distance=78.6] 19%|█▉        | 19/100 [00:02<00:10,  7.75it/s, distance=75.6] 21%|██        | 21/100 [00:02<00:09,  8.58it/s, distance=71.4] 23%|██▎       | 23/100 [00:02<00:08,  9.26it/s, distance=68.8] 25%|██▌       | 25/100 [00:03<00:10,  6.84it/s, distance=63.9] 27%|██▋       | 27/100 [00:03<00:09,  7.79it/s, distance=61.5] 29%|██▉       | 29/100 [00:03<00:08,  8.61it/s, distance=59.1] 31%|███       | 31/100 [00:03<00:07,  9.28it/s, distance=56.1] 33%|███▎      | 33/100 [00:04<00:09,  6.86it/s, distance=53.4] 35%|███▌      | 35/100 [00:04<00:08,  7.80it/s, distance=51.5] 37%|███▋      | 37/100 [00:04<00:07,  8.61it/s, distance=49.5] 39%|███▉      | 39/100 [00:04<00:06,  9.28it/s, distance=47.9] 41%|████      | 41/100 [00:05<00:08,  6.89it/s, distance=46.5] 43%|████▎     | 43/100 [00:05<00:07,  7.83it/s, distance=44.8] 45%|████▌     | 45/100 [00:05<00:06,  8.62it/s, distance=43.2] 47%|████▋     | 47/100 [00:05<00:05,  9.29it/s, distance=41.9] 49%|████▉     | 49/100 [00:06<00:07,  6.84it/s, distance=41.2] 51%|█████     | 51/100 [00:06<00:06,  7.78it/s, distance=40]   53%|█████▎    | 53/100 [00:06<00:05,  8.58it/s, distance=38.8] 55%|█████▌    | 55/100 [00:06<00:04,  9.25it/s, distance=37.8] 57%|█████▋    | 57/100 [00:07<00:06,  6.85it/s, distance=36.7] 59%|█████▉    | 59/100 [00:07<00:05,  7.79it/s, distance=35.8] 61%|██████    | 61/100 [00:07<00:04,  8.60it/s, distance=34.9] 63%|██████▎   | 63/100 [00:07<00:03,  9.27it/s, distance=34]   65%|██████▌   | 65/100 [00:08<00:05,  6.83it/s, distance=33.3] 67%|██████▋   | 67/100 [00:08<00:04,  7.78it/s, distance=32.6] 69%|██████▉   | 69/100 [00:08<00:03,  8.58it/s, distance=31.8] 71%|███████   | 71/100 [00:08<00:03,  9.26it/s, distance=31.1] 73%|███████▎  | 73/100 [00:09<00:03,  6.83it/s, distance=30.5] 75%|███████▌  | 75/100 [00:09<00:03,  7.78it/s, distance=29.9] 77%|███████▋  | 77/100 [00:09<00:02,  8.58it/s, distance=29.4] 79%|███████▉  | 79/100 [00:09<00:02,  9.25it/s, distance=28.7] 81%|████████  | 81/100 [00:10<00:02,  6.83it/s, distance=28]   83%|████████▎ | 83/100 [00:10<00:02,  7.78it/s, distance=27.5] 85%|████████▌ | 85/100 [00:10<00:01,  8.59it/s, distance=26.9] 87%|████████▋ | 87/100 [00:10<00:01,  9.26it/s, distance=26.3] 89%|████████▉ | 89/100 [00:11<00:01,  6.81it/s, distance=25.6] 91%|█████████ | 91/100 [00:11<00:01,  7.76it/s, distance=24.9] 93%|█████████▎| 93/100 [00:11<00:00,  8.57it/s, distance=24.1] 95%|█████████▌| 95/100 [00:11<00:00,  9.25it/s, distance=23.2] 97%|█████████▋| 97/100 [00:12<00:00,  9.77it/s, distance=21.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.18it/s, distance=19.7]100%|██████████| 100/100 [00:12<00:00,  8.14it/s, distance=16.7]
2025-06-18 20:34:08,128 [MPGD] >> Inference for image 18
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -2.0240e+00, -5.1200e+08,
        -1.9653e+00, -5.1200e+08, -2.0317e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7641, -1.7745, -1.9552, -1.8781, -1.7191, -1.8646, -1.8875, -1.7193],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14143315 0.11496958 0.00309453 0.01446842 0.34808894 0.01895871
 0.01199315 0.34699352]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5138, -1.4969, -1.4966, -1.5928, -1.6523, -1.5876, -1.5182, -1.6717],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1899777  0.26600325 0.26767197 0.03913348 0.01188471 0.04335108
 0.1739065  0.00807131]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4252, -1.3645, -1.3510, -1.3794, -1.5041, -1.3969, -1.4645, -1.4183],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06742381 0.22666832 0.29705191 0.1682888  0.01391228 0.11855623
 0.03071316 0.07738549]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4137, -1.3159, -1.3339, -1.3053, -1.3167, -1.3721, -1.3095, -1.2947],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0200466  0.14196203 0.0989017  0.17532327 0.13968169 0.04607692
 0.16137233 0.21663547]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2369, -1.2607, -1.2214, -1.2932, -1.2511, -1.3295, -1.2474, -1.2318],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16304829 0.10131741 0.22225092 0.05288474 0.12265167 0.02558097
 0.13198125 0.18028475]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2025, -1.1697, -1.2118, -1.0908, -1.1783, -1.1303, -1.1430, -1.1566],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04041164 0.07791774 0.03355088 0.37715694 0.06554164 0.17143373
 0.13280843 0.101179  ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9401, -0.9025, -1.0582, -1.0114, -1.0436, -1.0222, -1.0356, -1.0445],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.24693896 0.52428907 0.02326532 0.05932699 0.03117326 0.04785178
 0.03657973 0.0305749 ]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8073, -0.8747, -0.8759, -0.8810, -0.8793, -0.9021, -0.8653, -0.8659],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.3633485  0.09434133 0.09214217 0.08313004 0.08612179 0.05455405
 0.11383137 0.11253074]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7798, -0.7351, -0.7779, -0.7091, -0.7418, -0.7892, -0.7444, -0.7978],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06991304 0.17116712 0.07271003 0.28796802 0.14947572 0.05795189
 0.14200836 0.04880581]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6895, -0.7523, -0.7193, -0.6511, -0.7097, -0.7122, -0.7241, -0.6999],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15132736 0.04310664 0.08339879 0.32631169 0.1010805  0.09604273
 0.07575528 0.122977  ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6402, -0.6914, -0.6329, -0.6832, -0.6585, -0.7179, -0.6779, -0.6407],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.18845856 0.06767748 0.21810336 0.07982948 0.13067988 0.03984006
 0.0887042  0.18670698]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.066
key: ssim
value: 0.873
key: lpips
value: 0.073
key: facenet_l2
value: 0.464
key: adaface_l2
value: 0.586
ref_face_img: tensor([[[[ 0.9216,  0.9294,  0.9216,  ...,  0.9059,  0.9137,  0.9137],
          [ 0.9216,  0.9294,  0.9294,  ...,  0.9059,  0.9137,  0.9059],
          [ 0.9294,  0.9216,  0.9216,  ...,  0.9059,  0.9059,  0.9059],
          ...,
          [-0.3098, -0.3255, -0.3333,  ...,  0.6235,  0.6314,  0.6314],
          [-0.3255, -0.3255, -0.3333,  ...,  0.6000,  0.6235,  0.6314],
          [-0.3255, -0.3255, -0.3333,  ...,  0.5843,  0.6157,  0.6235]],

         [[ 0.1294,  0.1294,  0.1294,  ...,  0.0510,  0.0510,  0.0510],
          [ 0.1294,  0.1294,  0.1294,  ...,  0.0510,  0.0510,  0.0510],
          [ 0.1294,  0.1294,  0.1294,  ...,  0.0588,  0.0588,  0.0510],
          ...,
          [-0.6784, -0.6863, -0.6784,  ..., -0.2784, -0.2706, -0.2706],
          [-0.6784, -0.6784, -0.6784,  ..., -0.2863, -0.2784, -0.2706],
          [-0.6784, -0.6784, -0.6784,  ..., -0.2941, -0.2863, -0.2784]],

         [[ 0.0980,  0.0980,  0.0980,  ...,  0.0275,  0.0275,  0.0275],
          [ 0.0980,  0.0980,  0.0980,  ...,  0.0275,  0.0275,  0.0275],
          [ 0.0980,  0.0902,  0.0980,  ...,  0.0275,  0.0275,  0.0275],
          ...,
          [-0.7333, -0.7412, -0.7333,  ..., -0.3804, -0.3804, -0.3804],
          [-0.7333, -0.7333, -0.7333,  ..., -0.3882, -0.3804, -0.3804],
          [-0.7333, -0.7333, -0.7333,  ..., -0.4039, -0.3882, -0.3804]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.87it/s, distance=255]  3%|▎         | 3/100 [00:00<00:15,  6.46it/s, distance=158]  5%|▌         | 5/100 [00:00<00:11,  8.30it/s, distance=144]  7%|▋         | 7/100 [00:00<00:09,  9.35it/s, distance=127]  9%|▉         | 9/100 [00:01<00:14,  6.48it/s, distance=107] 11%|█         | 11/100 [00:01<00:11,  7.65it/s, distance=94.2] 13%|█▎        | 13/100 [00:01<00:10,  8.58it/s, distance=85.5] 15%|█▌        | 15/100 [00:01<00:09,  9.31it/s, distance=76.1] 17%|█▋        | 17/100 [00:02<00:12,  6.77it/s, distance=69.7] 19%|█▉        | 19/100 [00:02<00:10,  7.77it/s, distance=69]   21%|██        | 21/100 [00:02<00:09,  8.59it/s, distance=64.6] 23%|██▎       | 23/100 [00:02<00:08,  9.28it/s, distance=60.7] 25%|██▌       | 25/100 [00:03<00:10,  6.83it/s, distance=54.4] 27%|██▋       | 27/100 [00:03<00:09,  7.78it/s, distance=52.1] 29%|██▉       | 29/100 [00:03<00:08,  8.58it/s, distance=50.1] 31%|███       | 31/100 [00:03<00:07,  9.23it/s, distance=47.3] 33%|███▎      | 33/100 [00:04<00:09,  6.80it/s, distance=54.7] 35%|███▌      | 35/100 [00:04<00:08,  7.75it/s, distance=47.3] 37%|███▋      | 37/100 [00:04<00:07,  8.55it/s, distance=43.6] 39%|███▉      | 39/100 [00:04<00:06,  9.22it/s, distance=41.8] 41%|████      | 41/100 [00:05<00:08,  6.85it/s, distance=41.7] 43%|████▎     | 43/100 [00:05<00:07,  7.79it/s, distance=39.4] 45%|████▌     | 45/100 [00:05<00:06,  8.60it/s, distance=38.5] 47%|████▋     | 47/100 [00:05<00:05,  9.26it/s, distance=37.3] 49%|████▉     | 49/100 [00:06<00:07,  6.84it/s, distance=36.2] 51%|█████     | 51/100 [00:06<00:06,  7.78it/s, distance=35.9] 53%|█████▎    | 53/100 [00:06<00:05,  8.59it/s, distance=34.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.26it/s, distance=34.4] 57%|█████▋    | 57/100 [00:07<00:06,  6.83it/s, distance=33.7] 59%|█████▉    | 59/100 [00:07<00:05,  7.77it/s, distance=32.9] 61%|██████    | 61/100 [00:07<00:04,  8.57it/s, distance=32.3] 63%|██████▎   | 63/100 [00:07<00:04,  9.24it/s, distance=31.7] 65%|██████▌   | 65/100 [00:08<00:05,  6.84it/s, distance=30.9] 67%|██████▋   | 67/100 [00:08<00:04,  7.79it/s, distance=30.5] 69%|██████▉   | 69/100 [00:08<00:03,  8.58it/s, distance=30]   71%|███████   | 71/100 [00:08<00:03,  9.24it/s, distance=29.5] 73%|███████▎  | 73/100 [00:09<00:03,  6.85it/s, distance=29]   75%|███████▌  | 75/100 [00:09<00:03,  7.79it/s, distance=28.5] 77%|███████▋  | 77/100 [00:09<00:02,  8.60it/s, distance=28]   79%|███████▉  | 79/100 [00:09<00:02,  9.25it/s, distance=27.5] 81%|████████  | 81/100 [00:10<00:02,  6.85it/s, distance=27]   83%|████████▎ | 83/100 [00:10<00:02,  7.78it/s, distance=26.5] 85%|████████▌ | 85/100 [00:10<00:01,  8.58it/s, distance=26]   87%|████████▋ | 87/100 [00:10<00:01,  9.25it/s, distance=25.5] 89%|████████▉ | 89/100 [00:11<00:01,  6.84it/s, distance=25]   91%|█████████ | 91/100 [00:11<00:01,  7.78it/s, distance=24.4] 93%|█████████▎| 93/100 [00:11<00:00,  8.57it/s, distance=23.7] 95%|█████████▌| 95/100 [00:11<00:00,  9.25it/s, distance=22.8] 97%|█████████▋| 97/100 [00:12<00:00,  9.77it/s, distance=21.5] 99%|█████████▉| 99/100 [00:12<00:00, 10.18it/s, distance=19.3]100%|██████████| 100/100 [00:12<00:00,  8.13it/s, distance=16.1]
2025-06-18 20:34:21,472 [MPGD] >> Inference for image 19
reward_name: adaface, curr_reward: tensor([-2.0206e+00, -5.1200e+08, -5.1200e+08, -2.1732e+00, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -2.0888e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9152, -2.0697, -2.0551, -1.9870, -2.0010, -2.1152, -1.9980, -1.9997],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.52126952 0.02371849 0.03175866 0.12400444 0.09388034 0.0095591
 0.09949851 0.09631093]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6530, -1.7820, -1.7027, -1.8530, -1.7031, -1.7196, -1.8000, -1.6229],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.25144137 0.01908465 0.09313353 0.00460936 0.09242392 0.06644845
 0.01329936 0.45955936]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2597, -1.5402, -1.2436, -1.4872, -1.2247, -1.4681, -1.1717, -1.3696],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [9.65601174e-02 3.53771747e-04 1.33307759e-01 1.02187829e-03
 1.94639637e-01 1.49663163e-03 5.61891665e-01 1.07285395e-02]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0952, -1.3536, -1.2813, -1.2834, -1.1843, -1.2380, -1.0671, -1.2259],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.32181825 0.00183145 0.00778417 0.007459   0.05421795 0.01849007
 0.56484145 0.02355765]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0305, -1.1498, -1.1361, -1.0549, -1.0616, -1.1207, -1.1046, -1.0372],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.2754524  0.02532833 0.03335384 0.16899578 0.14796903 0.0453146
 0.06260072 0.24098529]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0185, -1.0519, -1.0482, -1.0202, -1.0895, -1.0324, -0.9665, -1.0497],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13523577 0.06934374 0.07465612 0.13065418 0.03270765 0.10231811
 0.38259483 0.0724896 ]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8774, -1.0414, -0.9082, -0.9377, -0.9394, -0.9359, -0.9953, -0.8222],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17893076 0.00673682 0.09660492 0.0535379  0.05179211 0.05555645
 0.01693738 0.53990367]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8762, -0.7595, -0.8791, -0.8092, -0.8563, -0.8019, -0.9506, -0.8445],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04149163 0.42810663 0.03913014 0.15836966 0.06174485 0.18354252
 0.00937052 0.07824405]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7445, -0.7529, -0.8285, -0.7330, -0.8090, -0.8428, -0.7818, -0.7580],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.2023661  0.17087195 0.03771956 0.25465881 0.05565997 0.0283137
 0.09589201 0.15451792]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7218, -0.6865, -0.7415, -0.7677, -0.7671, -0.7606, -0.7505, -0.7372],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15978555 0.32346171 0.10758252 0.06378303 0.06456248 0.07351911
 0.08991243 0.11739318]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6721, -0.6851, -0.7540, -0.6956, -0.7152, -0.7061, -0.6963, -0.7252],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.22319315 0.17205689 0.04331648 0.13940672 0.09427379 0.11301716
 0.13759142 0.07714439]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.049
key: ssim
value: 0.884
key: lpips
value: 0.084
key: facenet_l2
value: 0.396
key: adaface_l2
value: 0.602
ref_face_img: tensor([[[[ 0.6784,  0.6784,  0.6784,  ...,  0.8196,  0.8196,  0.8196],
          [ 0.6784,  0.6784,  0.6784,  ...,  0.8196,  0.8196,  0.8196],
          [ 0.6784,  0.6784,  0.6784,  ...,  0.8196,  0.8196,  0.8196],
          ...,
          [-0.8431, -0.8431, -0.8431,  ..., -0.2392, -0.2314, -0.2392],
          [-0.8431, -0.8431, -0.8353,  ..., -0.2627, -0.2627, -0.2706],
          [-0.8510, -0.8510, -0.8353,  ..., -0.2784, -0.2706, -0.2784]],

         [[ 0.6784,  0.6784,  0.6784,  ...,  0.8196,  0.8196,  0.8196],
          [ 0.6784,  0.6784,  0.6784,  ...,  0.8196,  0.8196,  0.8196],
          [ 0.6784,  0.6784,  0.6784,  ...,  0.8196,  0.8196,  0.8196],
          ...,
          [-0.8510, -0.8431, -0.8510,  ..., -0.2863, -0.2863, -0.2863],
          [-0.8510, -0.8510, -0.8431,  ..., -0.3098, -0.3098, -0.3176],
          [-0.8510, -0.8510, -0.8353,  ..., -0.3255, -0.3255, -0.3255]],

         [[ 0.6941,  0.6941,  0.6941,  ...,  0.8353,  0.8353,  0.8353],
          [ 0.6941,  0.6941,  0.6941,  ...,  0.8353,  0.8353,  0.8353],
          [ 0.6941,  0.6941,  0.6941,  ...,  0.8353,  0.8353,  0.8353],
          ...,
          [-0.8431, -0.8431, -0.8510,  ..., -0.3333, -0.3255, -0.3255],
          [-0.8510, -0.8510, -0.8431,  ..., -0.3569, -0.3490, -0.3569],
          [-0.8510, -0.8510, -0.8353,  ..., -0.3725, -0.3725, -0.3725]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.97it/s, distance=289]  3%|▎         | 3/100 [00:00<00:14,  6.59it/s, distance=167]  5%|▌         | 5/100 [00:00<00:11,  8.38it/s, distance=135]  7%|▋         | 7/100 [00:00<00:09,  9.41it/s, distance=115]  9%|▉         | 9/100 [00:01<00:14,  6.40it/s, distance=111] 11%|█         | 11/100 [00:01<00:11,  7.56it/s, distance=92.6] 13%|█▎        | 13/100 [00:01<00:10,  8.49it/s, distance=83.6] 15%|█▌        | 15/100 [00:01<00:09,  9.21it/s, distance=79.8] 17%|█▋        | 17/100 [00:02<00:12,  6.65it/s, distance=74.9] 19%|█▉        | 19/100 [00:02<00:10,  7.63it/s, distance=65.2] 21%|██        | 21/100 [00:02<00:09,  8.47it/s, distance=59]   23%|██▎       | 23/100 [00:02<00:08,  9.17it/s, distance=52.2] 25%|██▌       | 25/100 [00:03<00:11,  6.67it/s, distance=48.7] 27%|██▋       | 27/100 [00:03<00:09,  7.63it/s, distance=46.2] 29%|██▉       | 29/100 [00:03<00:08,  8.44it/s, distance=44.3] 31%|███       | 31/100 [00:03<00:07,  9.13it/s, distance=42.9] 33%|███▎      | 33/100 [00:04<00:09,  6.77it/s, distance=40.7] 35%|███▌      | 35/100 [00:04<00:08,  7.71it/s, distance=39.9] 37%|███▋      | 37/100 [00:04<00:07,  8.53it/s, distance=39.3] 39%|███▉      | 39/100 [00:04<00:06,  9.20it/s, distance=38.1] 41%|████      | 41/100 [00:05<00:08,  6.79it/s, distance=37.8] 43%|████▎     | 43/100 [00:05<00:07,  7.73it/s, distance=36.6] 45%|████▌     | 45/100 [00:05<00:06,  8.53it/s, distance=36]   47%|████▋     | 47/100 [00:05<00:05,  9.21it/s, distance=35.1] 49%|████▉     | 49/100 [00:06<00:07,  6.81it/s, distance=34.5] 51%|█████     | 51/100 [00:06<00:06,  7.75it/s, distance=33.8] 53%|█████▎    | 53/100 [00:06<00:05,  8.57it/s, distance=32.8] 55%|█████▌    | 55/100 [00:06<00:04,  9.23it/s, distance=32.4] 57%|█████▋    | 57/100 [00:07<00:06,  6.82it/s, distance=32]   59%|█████▉    | 59/100 [00:07<00:05,  7.76it/s, distance=31.4] 61%|██████    | 61/100 [00:07<00:04,  8.57it/s, distance=30.7] 63%|██████▎   | 63/100 [00:07<00:04,  9.24it/s, distance=30.2] 65%|██████▌   | 65/100 [00:08<00:05,  6.81it/s, distance=29.7] 67%|██████▋   | 67/100 [00:08<00:04,  7.76it/s, distance=29.3] 69%|██████▉   | 69/100 [00:08<00:03,  8.57it/s, distance=28.9] 71%|███████   | 71/100 [00:08<00:03,  9.24it/s, distance=28.5] 73%|███████▎  | 73/100 [00:09<00:03,  6.84it/s, distance=28.2] 75%|███████▌  | 75/100 [00:09<00:03,  7.78it/s, distance=27.7] 77%|███████▋  | 77/100 [00:09<00:02,  8.58it/s, distance=27.3] 79%|███████▉  | 79/100 [00:09<00:02,  9.25it/s, distance=26.9] 81%|████████  | 81/100 [00:10<00:02,  6.85it/s, distance=26.6] 83%|████████▎ | 83/100 [00:10<00:02,  7.79it/s, distance=26.2] 85%|████████▌ | 85/100 [00:10<00:01,  8.60it/s, distance=25.7] 87%|████████▋ | 87/100 [00:10<00:01,  9.26it/s, distance=25.2] 89%|████████▉ | 89/100 [00:11<00:01,  6.85it/s, distance=24.7] 91%|█████████ | 91/100 [00:11<00:01,  7.80it/s, distance=24.1] 93%|█████████▎| 93/100 [00:11<00:00,  8.60it/s, distance=23.4] 95%|█████████▌| 95/100 [00:11<00:00,  9.26it/s, distance=22.6] 97%|█████████▋| 97/100 [00:12<00:00,  9.80it/s, distance=21.5] 99%|█████████▉| 99/100 [00:12<00:00, 10.19it/s, distance=19.2]100%|██████████| 100/100 [00:12<00:00,  8.10it/s, distance=16.1]
2025-06-18 20:34:34,992 [MPGD] >> Inference for image 20
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -2.0972e+00, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8988, -1.9108, -1.9313, -1.8829, -1.9838, -1.9100, -2.0023, -1.9937],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.20234924 0.15920974 0.10567028 0.27822548 0.03695933 0.16172132
 0.02554254 0.03032207]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7096, -1.6061, -1.6371, -1.6502, -1.7293, -1.7606, -1.6938, -1.7264],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05107486 0.40465902 0.21741429 0.16751933 0.03438713 0.0184147
 0.07004447 0.03648619]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3076, -1.3624, -1.2461, -1.3662, -1.2601, -1.2816, -1.2864, -1.2529],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07220194 0.02413882 0.24731795 0.02238664 0.18661185 0.12145962
 0.11037887 0.2155043 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0781, -1.4299, -1.1060, -0.9767, -1.0252, -0.9078, -0.9591, -1.0686],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [1.84470404e-02 1.62171087e-05 1.05479251e-02 1.40068524e-01
 5.31094424e-02 5.56306225e-01 1.99222575e-01 2.22820517e-02]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8908, -0.8815, -0.9437, -1.2560, -1.0502, -1.1663, -1.2882, -1.2733],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [3.84776596e-01 4.63675508e-01 1.33548987e-01 2.58982556e-04
 1.58642721e-02 1.55641518e-03 1.35933799e-04 1.83305009e-04]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2757, -1.0961, -1.2000, -0.8569, -1.1548, -0.9999, -1.3342, -1.3373],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [2.15463172e-04 7.82486229e-03 9.79318810e-04 9.34898660e-01
 2.41690775e-03 5.35349887e-02 6.69208740e-05 6.28780935e-05]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8290, -0.7833, -0.8224, -0.8195, -0.8594, -0.8504, -0.7570, -0.7527],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06303135 0.15717982 0.07200601 0.07620941 0.03433042 0.04109986
 0.26627076 0.28987238]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7295, -0.8995, -0.7111, -0.8089, -0.7480, -0.7596, -0.8239, -0.7281],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.19585408 0.0065397  0.28324962 0.04003584 0.13546993 0.10742262
 0.029653   0.2017752 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7560, -0.7744, -0.7187, -0.7358, -0.7206, -0.7317, -0.6879, -0.7271],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06823992 0.04730437 0.1438851  0.10221588 0.13860127 0.11114309
 0.26676238 0.12184798]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7223, -0.7146, -0.6817, -0.6973, -0.6845, -0.6627, -0.6382, -0.6809],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05222489 0.06091459 0.11755187 0.08597183 0.11111229 0.17190164
 0.2807545  0.11956839]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6829, -0.7184, -0.6466, -0.6149, -0.6658, -0.6533, -0.6357, -0.6560],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06682663 0.03290271 0.13807887 0.26079014 0.0940562  0.12085059
 0.17203977 0.1144551 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 24.699
key: ssim
value: 0.864
key: lpips
value: 0.077
key: facenet_l2
value: 0.364
key: adaface_l2
value: 0.579
ref_face_img: tensor([[[[ 0.7490,  0.7490,  0.7490,  ...,  0.6784,  0.6784,  0.6784],
          [ 0.7490,  0.7490,  0.7490,  ...,  0.6784,  0.6784,  0.6784],
          [ 0.7490,  0.7490,  0.7490,  ...,  0.6863,  0.6863,  0.6863],
          ...,
          [ 0.7176,  0.7176,  0.7176,  ..., -0.9608, -0.9608, -0.9608],
          [ 0.7098,  0.7098,  0.7098,  ..., -0.9373, -0.9373, -0.9373],
          [ 0.7098,  0.7098,  0.7098,  ..., -0.9216, -0.9216, -0.9216]],

         [[ 0.7725,  0.7725,  0.7725,  ...,  0.7098,  0.7098,  0.7098],
          [ 0.7725,  0.7725,  0.7725,  ...,  0.7098,  0.7098,  0.7098],
          [ 0.7725,  0.7725,  0.7725,  ...,  0.7098,  0.7098,  0.7098],
          ...,
          [ 0.7333,  0.7333,  0.7333,  ..., -0.0588, -0.0588, -0.0588],
          [ 0.7255,  0.7255,  0.7255,  ..., -0.0588, -0.0588, -0.0588],
          [ 0.7176,  0.7176,  0.7176,  ..., -0.0510, -0.0510, -0.0510]],

         [[ 0.8118,  0.8118,  0.8118,  ...,  0.7804,  0.7804,  0.7804],
          [ 0.8118,  0.8118,  0.8118,  ...,  0.7804,  0.7804,  0.7804],
          [ 0.8118,  0.8118,  0.8118,  ...,  0.7804,  0.7804,  0.7804],
          ...,
          [ 0.7725,  0.7725,  0.7804,  ...,  0.8510,  0.8510,  0.8510],
          [ 0.7647,  0.7647,  0.7647,  ...,  0.8353,  0.8431,  0.8431],
          [ 0.7569,  0.7569,  0.7569,  ...,  0.8275,  0.8275,  0.8275]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
  1%|          | 1/100 [00:00<00:35,  2.83it/s, distance=275]  3%|▎         | 3/100 [00:00<00:15,  6.41it/s, distance=160]  5%|▌         | 5/100 [00:00<00:11,  8.24it/s, distance=140]  7%|▋         | 7/100 [00:00<00:09,  9.31it/s, distance=121]  9%|▉         | 9/100 [00:01<00:14,  6.46it/s, distance=106] 11%|█         | 11/100 [00:01<00:11,  7.63it/s, distance=88.8] 13%|█▎        | 13/100 [00:01<00:10,  8.55it/s, distance=78.6] 15%|█▌        | 15/100 [00:01<00:09,  9.28it/s, distance=68]   17%|█▋        | 17/100 [00:02<00:12,  6.81it/s, distance=68.3] 19%|█▉        | 19/100 [00:02<00:10,  7.80it/s, distance=62.2] 21%|██        | 21/100 [00:02<00:09,  8.62it/s, distance=56.3] 23%|██▎       | 23/100 [00:02<00:08,  9.28it/s, distance=53.5] 25%|██▌       | 25/100 [00:03<00:10,  6.86it/s, distance=49.8] 27%|██▋       | 27/100 [00:03<00:09,  7.81it/s, distance=46]   29%|██▉       | 29/100 [00:03<00:08,  8.62it/s, distance=43.7] 31%|███       | 31/100 [00:03<00:07,  9.29it/s, distance=41.4] 33%|███▎      | 33/100 [00:04<00:09,  6.89it/s, distance=38.4] 35%|███▌      | 35/100 [00:04<00:08,  7.83it/s, distance=38.4] 37%|███▋      | 37/100 [00:04<00:07,  8.63it/s, distance=36.8] 39%|███▉      | 39/100 [00:04<00:06,  9.28it/s, distance=35.6] 41%|████      | 41/100 [00:05<00:08,  6.92it/s, distance=34.6] 43%|████▎     | 43/100 [00:05<00:07,  7.86it/s, distance=34.2] 45%|████▌     | 45/100 [00:05<00:06,  8.65it/s, distance=33.2] 47%|████▋     | 47/100 [00:05<00:05,  9.30it/s, distance=32.4] 49%|████▉     | 49/100 [00:06<00:07,  6.96it/s, distance=31.7] 51%|█████     | 51/100 [00:06<00:06,  7.89it/s, distance=31.1] 53%|█████▎    | 53/100 [00:06<00:05,  8.68it/s, distance=30.6] 55%|█████▌    | 55/100 [00:06<00:04,  9.33it/s, distance=30]   57%|█████▋    | 57/100 [00:07<00:06,  6.94it/s, distance=29.3] 59%|█████▉    | 59/100 [00:07<00:05,  7.87it/s, distance=29]   61%|██████    | 61/100 [00:07<00:04,  8.66it/s, distance=28.5] 63%|██████▎   | 63/100 [00:07<00:03,  9.31it/s, distance=28.1] 65%|██████▌   | 65/100 [00:08<00:05,  6.87it/s, distance=27.8] 67%|██████▋   | 67/100 [00:08<00:04,  7.81it/s, distance=27.4] 69%|██████▉   | 69/100 [00:08<00:03,  8.60it/s, distance=26.9] 71%|███████   | 71/100 [00:08<00:03,  9.27it/s, distance=26.6] 73%|███████▎  | 73/100 [00:09<00:03,  6.87it/s, distance=26.3] 75%|███████▌  | 75/100 [00:09<00:03,  7.82it/s, distance=26]   77%|███████▋  | 77/100 [00:09<00:02,  8.61it/s, distance=25.6] 79%|███████▉  | 79/100 [00:09<00:02,  9.27it/s, distance=25.2] 81%|████████  | 81/100 [00:10<00:02,  6.90it/s, distance=25]   83%|████████▎ | 83/100 [00:10<00:02,  7.85it/s, distance=24.6] 85%|████████▌ | 85/100 [00:10<00:01,  8.64it/s, distance=24.2] 87%|████████▋ | 87/100 [00:10<00:01,  9.30it/s, distance=23.7] 89%|████████▉ | 89/100 [00:11<00:01,  6.91it/s, distance=23.3] 91%|█████████ | 91/100 [00:11<00:01,  7.85it/s, distance=22.8] 93%|█████████▎| 93/100 [00:11<00:00,  8.64it/s, distance=22.2] 95%|█████████▌| 95/100 [00:11<00:00,  9.29it/s, distance=21.5] 97%|█████████▋| 97/100 [00:11<00:00,  9.81it/s, distance=20.4] 99%|█████████▉| 99/100 [00:12<00:00, 10.20it/s, distance=18.4]100%|██████████| 100/100 [00:12<00:00,  8.17it/s, distance=15.2]
2025-06-18 20:34:48,253 [MPGD] >> Inference for image 21
reward_name: adaface, curr_reward: tensor([-1.8280e+00, -5.1200e+08, -1.9337e+00, -1.9256e+00, -5.1200e+08,
        -1.8536e+00, -1.8793e+00, -1.9220e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9366, -1.9230, -1.9094, -1.9346, -2.0245, -1.9525, -1.8596, -1.8559],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06379948 0.08380848 0.11005469 0.06643419 0.01100883 0.04641624
 0.29794078 0.32053731]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6353, -1.7981, -1.6723, -1.9598, -1.8279, -1.7528, -1.8156, -1.8186],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.59262202 0.02284984 0.28316005 0.00090013 0.01259903 0.05658116
 0.01610837 0.0151794 ]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4741, -1.5744, -1.4520, -1.6017, -1.4660, -1.5728, -1.5245, -1.4570],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17082995 0.02297052 0.26549414 0.01331532 0.20082103 0.02371991
 0.06228596 0.24056317]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3906, -1.3251, -1.3469, -1.3307, -1.2441, -1.4794, -1.3604, -1.4582],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03184943 0.11805506 0.07636429 0.10552385 0.59625389 0.00539134
 0.05831595 0.00824619]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2579, -1.2419, -1.1798, -1.2535, -1.2800, -1.0198, -1.3378, -1.2971],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00791385 0.01088315 0.03773707 0.00863306 0.00508589 0.92453227
 0.0016002  0.00361449]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1727, -1.0094, -0.8482, -1.0513, -1.0316, -1.1583, -1.0564, -0.8976],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0010317  0.02698963 0.67837504 0.01168371 0.01732262 0.00137486
 0.01056106 0.25266138]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7952, -0.7869, -0.8310, -0.8636, -0.9334, -0.8943, -0.8081, -0.8352],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.23004205 0.2714449  0.11240517 0.0586174  0.01451476 0.03169941
 0.17791956 0.10335675]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7160, -0.7100, -0.7314, -0.7393, -0.7620, -0.7485, -0.6757, -0.7274],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13429502 0.15149895 0.09867842 0.08426409 0.05353481 0.07010903
 0.30076528 0.10685439]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7189, -0.6023, -0.7251, -0.5560, -0.6603, -0.6256, -0.6072, -0.6757],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01677554 0.17285807 0.01483465 0.43641032 0.0542061  0.10847774
 0.15662323 0.03981435]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5689, -0.5555, -0.5378, -0.5049, -0.5031, -0.5366, -0.5390, -0.5308],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0575717  0.0752656  0.10729058 0.20725237 0.21459163 0.10989045
 0.10477232 0.12336536]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5379, -0.5370, -0.5106, -0.5243, -0.5137, -0.4949, -0.5323, -0.5187],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08607834 0.08752157 0.14834758 0.11293669 0.13948127 0.2031174
 0.09628233 0.12623481]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.496
key: ssim
value: 0.845
key: lpips
value: 0.121
key: facenet_l2
value: 0.355
key: adaface_l2
value: 0.621
ref_face_img: tensor([[[[-0.8353, -0.8431, -0.8510,  ...,  0.0196,  0.0196,  0.0196],
          [-0.8353, -0.8431, -0.8510,  ...,  0.0118,  0.0196,  0.0196],
          [-0.8353, -0.8431, -0.8510,  ...,  0.0196,  0.0196,  0.0196],
          ...,
          [-0.8745, -0.8745, -0.8745,  ..., -0.5529, -0.5451, -0.5373],
          [-0.8588, -0.8588, -0.8588,  ..., -0.5529, -0.5451, -0.5373],
          [-0.8588, -0.8588, -0.8510,  ..., -0.5529, -0.5451, -0.5373]],

         [[-0.8431, -0.8510, -0.8510,  ...,  0.0118,  0.0196,  0.0196],
          [-0.8431, -0.8510, -0.8510,  ...,  0.0118,  0.0118,  0.0196],
          [-0.8431, -0.8431, -0.8510,  ...,  0.0118,  0.0118,  0.0196],
          ...,
          [-0.8824, -0.8824, -0.8824,  ..., -0.6000, -0.5922, -0.5922],
          [-0.8745, -0.8745, -0.8745,  ..., -0.6000, -0.5922, -0.5922],
          [-0.8667, -0.8667, -0.8667,  ..., -0.6000, -0.5922, -0.5922]],

         [[-0.8510, -0.8510, -0.8510,  ...,  0.0353,  0.0353,  0.0353],
          [-0.8510, -0.8510, -0.8510,  ...,  0.0353,  0.0353,  0.0353],
          [-0.8510, -0.8510, -0.8510,  ...,  0.0353,  0.0353,  0.0353],
          ...,
          [-0.8902, -0.8902, -0.8902,  ..., -0.6471, -0.6471, -0.6471],
          [-0.8824, -0.8824, -0.8824,  ..., -0.6471, -0.6471, -0.6471],
          [-0.8824, -0.8824, -0.8824,  ..., -0.6471, -0.6471, -0.6471]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.93it/s, distance=303]  3%|▎         | 3/100 [00:00<00:14,  6.55it/s, distance=162]  5%|▌         | 5/100 [00:00<00:11,  8.35it/s, distance=142]  7%|▋         | 7/100 [00:00<00:09,  9.39it/s, distance=125]  9%|▉         | 9/100 [00:01<00:13,  6.54it/s, distance=119] 11%|█         | 11/100 [00:01<00:11,  7.71it/s, distance=89.3] 13%|█▎        | 13/100 [00:01<00:10,  8.62it/s, distance=80.8] 15%|█▌        | 15/100 [00:01<00:09,  9.34it/s, distance=75.4] 17%|█▋        | 17/100 [00:02<00:12,  6.89it/s, distance=68.8] 19%|█▉        | 19/100 [00:02<00:10,  7.85it/s, distance=59.1] 21%|██        | 21/100 [00:02<00:09,  8.67it/s, distance=54.9] 23%|██▎       | 23/100 [00:02<00:08,  9.33it/s, distance=53.2] 25%|██▌       | 25/100 [00:03<00:10,  6.97it/s, distance=47.9] 27%|██▋       | 27/100 [00:03<00:09,  7.91it/s, distance=46.2] 29%|██▉       | 29/100 [00:03<00:08,  8.70it/s, distance=44.4] 31%|███       | 31/100 [00:03<00:07,  9.34it/s, distance=43.2] 33%|███▎      | 33/100 [00:04<00:09,  6.97it/s, distance=41.9] 35%|███▌      | 35/100 [00:04<00:08,  7.90it/s, distance=41.5] 37%|███▋      | 37/100 [00:04<00:07,  8.69it/s, distance=39.6] 39%|███▉      | 39/100 [00:04<00:06,  9.34it/s, distance=39.2] 41%|████      | 41/100 [00:05<00:08,  7.01it/s, distance=37.5] 43%|████▎     | 43/100 [00:05<00:07,  7.94it/s, distance=36.5] 45%|████▌     | 45/100 [00:05<00:06,  8.71it/s, distance=36.1] 47%|████▋     | 47/100 [00:05<00:05,  9.36it/s, distance=35.2] 49%|████▉     | 49/100 [00:06<00:07,  7.02it/s, distance=36.2] 51%|█████     | 51/100 [00:06<00:06,  7.95it/s, distance=34]   53%|█████▎    | 53/100 [00:06<00:05,  8.72it/s, distance=32.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.36it/s, distance=31.8] 57%|█████▋    | 57/100 [00:07<00:06,  7.03it/s, distance=30.9] 59%|█████▉    | 59/100 [00:07<00:05,  7.95it/s, distance=30.4] 61%|██████    | 61/100 [00:07<00:04,  8.73it/s, distance=29.8] 63%|██████▎   | 63/100 [00:07<00:03,  9.37it/s, distance=29.3] 65%|██████▌   | 65/100 [00:08<00:04,  7.00it/s, distance=28.9] 67%|██████▋   | 67/100 [00:08<00:04,  7.94it/s, distance=28.5] 69%|██████▉   | 69/100 [00:08<00:03,  8.71it/s, distance=28]   71%|███████   | 71/100 [00:08<00:03,  9.34it/s, distance=27.5] 73%|███████▎  | 73/100 [00:09<00:03,  7.02it/s, distance=27]   75%|███████▌  | 75/100 [00:09<00:03,  7.94it/s, distance=26.7] 77%|███████▋  | 77/100 [00:09<00:02,  8.72it/s, distance=26.3] 79%|███████▉  | 79/100 [00:09<00:02,  9.37it/s, distance=25.9] 81%|████████  | 81/100 [00:10<00:02,  7.03it/s, distance=25.6] 83%|████████▎ | 83/100 [00:10<00:02,  7.95it/s, distance=25.2] 85%|████████▌ | 85/100 [00:10<00:01,  8.73it/s, distance=24.8] 87%|████████▋ | 87/100 [00:10<00:01,  9.37it/s, distance=24.3] 89%|████████▉ | 89/100 [00:11<00:01,  7.03it/s, distance=23.8] 91%|█████████ | 91/100 [00:11<00:01,  7.96it/s, distance=23.3] 93%|█████████▎| 93/100 [00:11<00:00,  8.73it/s, distance=22.6] 95%|█████████▌| 95/100 [00:11<00:00,  9.36it/s, distance=21.8] 97%|█████████▋| 97/100 [00:11<00:00,  9.88it/s, distance=20.7] 99%|█████████▉| 99/100 [00:12<00:00, 10.26it/s, distance=18.6]100%|██████████| 100/100 [00:12<00:00,  8.26it/s, distance=15.5]
2025-06-18 20:35:03,878 [MPGD] >> Inference for image 22
reward_name: adaface, curr_reward: tensor([-1.7318e+00, -5.1200e+08, -5.1200e+08, -1.8233e+00, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9742, -1.8686, -2.1242, -1.8700, -1.8130, -1.9892, -1.8706, -1.9016],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01803241 0.149021   0.00089784 0.14500064 0.45338379 0.01336508
 0.14328817 0.07701106]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6820, -1.8367, -1.7750, -1.7891, -1.7379, -1.6812, -1.7299, -1.7905],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.31632357 0.01435266 0.04929972 0.03717861 0.10351978 0.32189565
 0.12131664 0.03611337]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8703, -1.8297, -1.8317, -1.6330, -1.7876, -1.7960, -1.8175, -1.8572],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00744123 0.01678783 0.01611374 0.85666276 0.03897248 0.03294486
 0.0214057  0.0096714 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7222, -1.5669, -1.5776, -1.6379, -1.5418, -1.5866, -1.6478, -1.5626],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00783597 0.17516717 0.14145976 0.04234977 0.28957185 0.11812064
 0.03473214 0.1907627 ]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4326, -1.4188, -1.3726, -1.4718, -1.4691, -1.4595, -1.4513, -1.3467],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07453324 0.09816803 0.24736737 0.03401358 0.03591431 0.04351355
 0.05123059 0.41525933]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1742, -1.2569, -1.2293, -1.2833, -1.2255, -1.3057, -1.2157, -1.2322],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.3549862  0.0679672  0.11795367 0.04005031 0.127332   0.0255921
 0.15472182 0.11139669]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1292, -1.0873, -1.0818, -1.1150, -1.1623, -1.1639, -1.0490, -1.1254],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06995184 0.16167659 0.18067781 0.09293802 0.03607042 0.03498526
 0.34812844 0.07557162]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0476, -1.1101, -1.0487, -1.0105, -1.0750, -1.0396, -1.0308, -1.0698],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12259911 0.03514491 0.11997898 0.25737643 0.07087934 0.1438049
 0.17152597 0.07869036]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0475, -1.0105, -0.9953, -0.9844, -1.0476, -1.0632, -1.0306, -1.0672],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07533325 0.15788929 0.214079   0.26600583 0.07517052 0.05502754
 0.10572568 0.0507689 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0061, -0.9673, -1.0706, -1.0283, -0.9577, -1.0653, -1.0086, -1.0127],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11290598 0.24512571 0.03107062 0.07250582 0.2973647  0.03455508
 0.10744752 0.09902457]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0126, -0.9962, -0.9668, -0.9947, -0.9577, -1.0269, -0.9764, -0.9630],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06753091 0.09371121 0.16849445 0.09648853 0.20218118 0.05064825
 0.13907723 0.18186825]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.051
key: ssim
value: 0.843
key: lpips
value: 0.107
key: facenet_l2
value: 0.658
key: adaface_l2
value: 0.898
ref_face_img: tensor([[[[-0.9765, -0.9765, -0.9765,  ..., -0.9843, -0.9843, -0.9843],
          [-0.9765, -0.9765, -0.9765,  ..., -0.9843, -0.9843, -0.9843],
          [-0.9765, -0.9608, -0.9686,  ..., -0.9843, -0.9843, -0.9843],
          ...,
          [-0.9686, -0.9686, -0.9686,  ..., -0.9686, -0.9765, -0.9843],
          [-0.9686, -0.9686, -0.9686,  ..., -1.0000, -1.0000, -0.9922],
          [-0.9686, -0.9686, -0.9686,  ..., -0.8588, -0.9373, -0.9843]],

         [[-0.9765, -0.9765, -0.9765,  ..., -0.9843, -0.9843, -0.9843],
          [-0.9765, -0.9765, -0.9765,  ..., -0.9843, -0.9843, -0.9843],
          [-0.9765, -0.9608, -0.9686,  ..., -0.9843, -0.9843, -0.9843],
          ...,
          [-0.9686, -0.9686, -0.9686,  ..., -0.9608, -0.9686, -0.9765],
          [-0.9686, -0.9686, -0.9686,  ..., -0.9922, -0.9922, -0.9843],
          [-0.9686, -0.9686, -0.9686,  ..., -0.8275, -0.9216, -0.9765]],

         [[-0.9765, -0.9765, -0.9765,  ..., -0.9843, -0.9843, -0.9843],
          [-0.9765, -0.9765, -0.9765,  ..., -0.9843, -0.9843, -0.9843],
          [-0.9765, -0.9608, -0.9686,  ..., -0.9843, -0.9843, -0.9843],
          ...,
          [-0.9686, -0.9686, -0.9686,  ..., -0.9608, -0.9843, -0.9765],
          [-0.9686, -0.9686, -0.9686,  ..., -0.9608, -0.9765, -0.9922],
          [-0.9686, -0.9686, -0.9686,  ..., -0.7725, -0.8824, -0.9765]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:38,  2.60it/s, distance=258]  3%|▎         | 3/100 [00:00<00:16,  6.06it/s, distance=159]  5%|▌         | 5/100 [00:00<00:11,  7.95it/s, distance=137]  7%|▋         | 7/100 [00:00<00:10,  9.09it/s, distance=125]  9%|▉         | 9/100 [00:01<00:14,  6.43it/s, distance=98]  11%|█         | 11/100 [00:01<00:11,  7.60it/s, distance=104] 13%|█▎        | 13/100 [00:01<00:10,  8.54it/s, distance=94.9] 15%|█▌        | 15/100 [00:01<00:09,  9.28it/s, distance=88.7] 17%|█▋        | 17/100 [00:02<00:12,  6.86it/s, distance=73.7] 19%|█▉        | 19/100 [00:02<00:10,  7.84it/s, distance=68.1] 21%|██        | 21/100 [00:02<00:09,  8.67it/s, distance=59.8] 23%|██▎       | 23/100 [00:02<00:08,  9.33it/s, distance=56.2] 25%|██▌       | 25/100 [00:03<00:10,  6.95it/s, distance=49]   27%|██▋       | 27/100 [00:03<00:09,  7.89it/s, distance=47.6] 29%|██▉       | 29/100 [00:03<00:08,  8.68it/s, distance=46.5] 31%|███       | 31/100 [00:03<00:07,  9.34it/s, distance=44.1] 33%|███▎      | 33/100 [00:04<00:09,  6.99it/s, distance=42.7] 35%|███▌      | 35/100 [00:04<00:08,  7.91it/s, distance=40]   37%|███▋      | 37/100 [00:04<00:07,  8.70it/s, distance=38.9] 39%|███▉      | 39/100 [00:04<00:06,  9.35it/s, distance=37.7] 41%|████      | 41/100 [00:05<00:08,  6.99it/s, distance=36.3] 43%|████▎     | 43/100 [00:05<00:07,  7.93it/s, distance=35]   45%|████▌     | 45/100 [00:05<00:06,  8.71it/s, distance=34.3] 47%|████▋     | 47/100 [00:05<00:05,  9.35it/s, distance=33.5] 49%|████▉     | 49/100 [00:06<00:07,  6.98it/s, distance=33]   51%|█████     | 51/100 [00:06<00:06,  7.90it/s, distance=32] 53%|█████▎    | 53/100 [00:06<00:05,  8.68it/s, distance=31.4] 55%|█████▌    | 55/100 [00:06<00:04,  9.34it/s, distance=30.7] 57%|█████▋    | 57/100 [00:07<00:06,  6.96it/s, distance=30.2] 59%|█████▉    | 59/100 [00:07<00:05,  7.90it/s, distance=29.7] 61%|██████    | 61/100 [00:07<00:04,  8.68it/s, distance=29.3] 63%|██████▎   | 63/100 [00:07<00:03,  9.33it/s, distance=28.8] 65%|██████▌   | 65/100 [00:08<00:05,  6.98it/s, distance=28.2] 67%|██████▋   | 67/100 [00:08<00:04,  7.91it/s, distance=27.9] 69%|██████▉   | 69/100 [00:08<00:03,  8.70it/s, distance=27.5] 71%|███████   | 71/100 [00:08<00:03,  9.34it/s, distance=27.1] 73%|███████▎  | 73/100 [00:09<00:03,  6.96it/s, distance=26.5] 75%|███████▌  | 75/100 [00:09<00:03,  7.89it/s, distance=26.3] 77%|███████▋  | 77/100 [00:09<00:02,  8.68it/s, distance=26]   79%|███████▉  | 79/100 [00:09<00:02,  9.32it/s, distance=25.6] 81%|████████  | 81/100 [00:10<00:02,  6.96it/s, distance=25.1] 83%|████████▎ | 83/100 [00:10<00:02,  7.90it/s, distance=24.8] 85%|████████▌ | 85/100 [00:10<00:01,  8.68it/s, distance=24.4] 87%|████████▋ | 87/100 [00:10<00:01,  9.33it/s, distance=24]   89%|████████▉ | 89/100 [00:11<00:01,  6.97it/s, distance=23.6] 91%|█████████ | 91/100 [00:11<00:01,  7.89it/s, distance=23]   93%|█████████▎| 93/100 [00:11<00:00,  8.69it/s, distance=22.4] 95%|█████████▌| 95/100 [00:11<00:00,  9.34it/s, distance=21.7] 97%|█████████▋| 97/100 [00:11<00:00,  9.84it/s, distance=20.6] 99%|█████████▉| 99/100 [00:12<00:00, 10.24it/s, distance=18.5]100%|██████████| 100/100 [00:12<00:00,  8.20it/s, distance=15.4]
2025-06-18 20:35:18,761 [MPGD] >> Inference for image 23
reward_name: adaface, curr_reward: tensor([-2.0068e+00, -1.9328e+00, -5.1200e+08, -5.1200e+08, -2.0943e+00,
        -2.0421e+00, -1.9086e+00, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0090, -2.0057, -1.8363, -1.8466, -1.7968, -1.8093, -1.6784, -1.9202],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00107124 0.00114491 0.03388642 0.0275659  0.07459351 0.05810756
 0.7973094  0.00632106]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4003, -1.4163, -1.5257, -1.5209, -1.4162, -1.4075, -1.2909, -1.3535],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06684998 0.04856409 0.0054523  0.00599662 0.04867084 0.05794616
 0.59597087 0.17054915]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0982, -1.1357, -0.9919, -1.1515, -1.1139, -1.0887, -1.0882, -1.1492],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07285    0.03444324 0.61097342 0.02509406 0.05325095 0.08802146
 0.08907152 0.02629535]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9141, -0.8151, -0.9502, -0.9064, -0.9180, -0.9817, -0.8760, -0.8312],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05417568 0.39205397 0.02629905 0.06319539 0.05010897 0.01402143
 0.11603618 0.28410933]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7362, -0.8023, -0.7773, -0.7174, -0.6965, -0.7725, -0.8327, -0.7277],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13919485 0.03707768 0.06114356 0.20248077 0.30768726 0.067256
 0.02020719 0.16495269]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6467, -0.7133, -0.7829, -0.6408, -0.6609, -0.7634, -0.7163, -0.7266],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.26610889 0.07031626 0.01747349 0.29962688 0.20060884 0.0258143
 0.06617485 0.05387649]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6612, -0.6522, -0.6656, -0.6725, -0.6425, -0.5782, -0.6708, -0.6754],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08193549 0.09808432 0.07510767 0.06538376 0.11915807 0.4311118
 0.06758657 0.06163233]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6472, -0.5674, -0.6419, -0.7613, -0.7217, -0.6319, -0.7105, -0.6256],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09478287 0.46744487 0.10539332 0.00967364 0.02135705 0.12871079
 0.02670353 0.14593391]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5001, -0.5543, -0.6157, -0.6111, -0.6038, -0.5928, -0.5630, -0.5324],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.37929945 0.12826698 0.03758483 0.04122721 0.04771982 0.05935679
 0.10787487 0.19867005]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5672, -0.5408, -0.5655, -0.4861, -0.5444, -0.5264, -0.5507, -0.5097],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05816516 0.09869926 0.06022003 0.29477276 0.09176239 0.13167572
 0.08098751 0.18371717]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4636, -0.5206, -0.5103, -0.5110, -0.5140, -0.4893, -0.5112, -0.5317],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.26966015 0.086265   0.10603601 0.104557   0.09859547 0.16148452
 0.10425865 0.06914321]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.253
key: ssim
value: 0.831
key: lpips
value: 0.136
key: facenet_l2
value: 0.409
key: adaface_l2
value: 0.545
ref_face_img: tensor([[[[-0.0824, -0.0824, -0.0824,  ...,  0.0824,  0.0824,  0.0824],
          [-0.0824, -0.0824, -0.0824,  ...,  0.0902,  0.0902,  0.0902],
          [-0.0745, -0.0745, -0.0745,  ...,  0.0980,  0.0980,  0.0980],
          ...,
          [-0.5922, -0.6157, -0.6157,  ...,  0.0353,  0.0824,  0.1216],
          [-0.6078, -0.6235, -0.6235,  ...,  0.0353,  0.0824,  0.1137],
          [-0.6157, -0.6314, -0.6392,  ...,  0.0353,  0.0824,  0.1216]],

         [[ 0.0118,  0.0118,  0.0118,  ...,  0.0902,  0.0980,  0.0980],
          [ 0.0118,  0.0118,  0.0118,  ...,  0.0980,  0.0980,  0.0980],
          [ 0.0196,  0.0196,  0.0196,  ...,  0.1059,  0.1059,  0.1059],
          ...,
          [-0.6235, -0.6392, -0.6471,  ..., -0.0431,  0.0039,  0.0431],
          [-0.6392, -0.6549, -0.6549,  ..., -0.0431,  0.0039,  0.0353],
          [-0.6392, -0.6549, -0.6627,  ..., -0.0431,  0.0039,  0.0353]],

         [[ 0.1451,  0.1451,  0.1451,  ...,  0.1922,  0.1922,  0.1922],
          [ 0.1451,  0.1451,  0.1529,  ...,  0.1922,  0.1922,  0.1922],
          [ 0.1529,  0.1529,  0.1529,  ...,  0.2000,  0.2000,  0.2000],
          ...,
          [-0.6471, -0.6627, -0.6706,  ..., -0.1059, -0.0667, -0.0275],
          [-0.6627, -0.6784, -0.6784,  ..., -0.1059, -0.0667, -0.0275],
          [-0.6706, -0.6863, -0.6941,  ..., -0.1059, -0.0667, -0.0353]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:36,  2.69it/s, distance=329]  3%|▎         | 3/100 [00:00<00:15,  6.18it/s, distance=152]  5%|▌         | 5/100 [00:00<00:11,  8.06it/s, distance=113]  7%|▋         | 7/100 [00:00<00:10,  9.17it/s, distance=94.7]  9%|▉         | 9/100 [00:01<00:14,  6.44it/s, distance=77.1] 11%|█         | 11/100 [00:01<00:11,  7.61it/s, distance=70.5] 13%|█▎        | 13/100 [00:01<00:10,  8.55it/s, distance=66.4] 15%|█▌        | 15/100 [00:01<00:09,  9.27it/s, distance=60.8] 17%|█▋        | 17/100 [00:02<00:12,  6.84it/s, distance=55.6] 19%|█▉        | 19/100 [00:02<00:10,  7.83it/s, distance=52.4] 21%|██        | 21/100 [00:02<00:09,  8.65it/s, distance=50.3] 23%|██▎       | 23/100 [00:02<00:08,  9.32it/s, distance=48.4] 25%|██▌       | 25/100 [00:03<00:10,  6.92it/s, distance=45.6] 27%|██▋       | 27/100 [00:03<00:09,  7.86it/s, distance=45.1] 29%|██▉       | 29/100 [00:03<00:08,  8.66it/s, distance=43.7] 31%|███       | 31/100 [00:03<00:07,  9.31it/s, distance=42.5] 33%|███▎      | 33/100 [00:04<00:09,  6.98it/s, distance=42.1] 35%|███▌      | 35/100 [00:04<00:08,  7.91it/s, distance=41.2] 37%|███▋      | 37/100 [00:04<00:07,  8.69it/s, distance=40.7] 39%|███▉      | 39/100 [00:04<00:06,  9.35it/s, distance=39.7] 41%|████      | 41/100 [00:05<00:08,  7.01it/s, distance=38.2] 43%|████▎     | 43/100 [00:05<00:07,  7.95it/s, distance=38]   45%|████▌     | 45/100 [00:05<00:06,  8.73it/s, distance=37.5] 47%|████▋     | 47/100 [00:05<00:05,  9.38it/s, distance=36.9] 49%|████▉     | 49/100 [00:06<00:07,  7.02it/s, distance=36.4] 51%|█████     | 51/100 [00:06<00:06,  7.95it/s, distance=35.8] 53%|█████▎    | 53/100 [00:06<00:05,  8.73it/s, distance=35.1] 55%|█████▌    | 55/100 [00:06<00:04,  9.35it/s, distance=34.5] 57%|█████▋    | 57/100 [00:07<00:06,  7.01it/s, distance=33.9] 59%|█████▉    | 59/100 [00:07<00:05,  7.93it/s, distance=33.4] 61%|██████    | 61/100 [00:07<00:04,  8.71it/s, distance=32.9] 63%|██████▎   | 63/100 [00:07<00:03,  9.36it/s, distance=32.4] 65%|██████▌   | 65/100 [00:08<00:04,  7.02it/s, distance=32.1] 67%|██████▋   | 67/100 [00:08<00:04,  7.94it/s, distance=31.5] 69%|██████▉   | 69/100 [00:08<00:03,  8.72it/s, distance=31]   71%|███████   | 71/100 [00:08<00:03,  9.36it/s, distance=30.5] 73%|███████▎  | 73/100 [00:09<00:03,  7.03it/s, distance=30]   75%|███████▌  | 75/100 [00:09<00:03,  7.96it/s, distance=29.5] 77%|███████▋  | 77/100 [00:09<00:02,  8.73it/s, distance=29]   79%|███████▉  | 79/100 [00:09<00:02,  9.38it/s, distance=28.5] 81%|████████  | 81/100 [00:10<00:02,  7.03it/s, distance=27.9] 83%|████████▎ | 83/100 [00:10<00:02,  7.96it/s, distance=27.5] 85%|████████▌ | 85/100 [00:10<00:01,  8.73it/s, distance=27.1] 87%|████████▋ | 87/100 [00:10<00:01,  9.37it/s, distance=26.6] 89%|████████▉ | 89/100 [00:11<00:01,  7.03it/s, distance=26]   91%|█████████ | 91/100 [00:11<00:01,  7.95it/s, distance=25.4] 93%|█████████▎| 93/100 [00:11<00:00,  8.74it/s, distance=24.6] 95%|█████████▌| 95/100 [00:11<00:00,  9.37it/s, distance=23.7] 97%|█████████▋| 97/100 [00:11<00:00,  9.87it/s, distance=22.4] 99%|█████████▉| 99/100 [00:12<00:00, 10.26it/s, distance=20.2]100%|██████████| 100/100 [00:12<00:00,  8.23it/s, distance=17.3]
2025-06-18 20:35:36,520 [MPGD] >> Inference for image 24
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -1.9204e+00, -5.1200e+08, -5.1200e+08,
        -1.9658e+00, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7179, -1.6259, -1.7721, -1.9232, -1.8585, -1.8724, -1.8903, -1.6377],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07832105 0.4935809  0.02647971 0.00129017 0.00470991 0.0035678
 0.00248939 0.38956106]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2309, -1.1672, -1.3254, -1.3736, -1.3501, -1.3342, -1.1352, -1.3112],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08352264 0.29844697 0.01259998 0.00480925 0.00769982 0.0105736
 0.56558429 0.01676346]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8758, -0.9262, -0.9721, -0.8357, -1.0677, -0.8314, -0.9761, -1.0079],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15617774 0.05707665 0.02278198 0.34835495 0.00336687 0.38010677
 0.02100788 0.01112717]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8177, -0.7681, -0.7741, -0.8354, -0.7779, -0.8080, -0.8358, -0.8663],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08859665 0.23864841 0.21186772 0.06216536 0.19613748 0.10740687
 0.06167752 0.03349999]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8396, -0.9413, -0.7847, -0.7054, -0.7603, -0.7530, -0.6683, -0.6059],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00598396 0.00078242 0.01794558 0.08764387 0.02920086 0.03377607
 0.18388761 0.64077962]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5880, -0.6595, -0.5997, -0.6350, -0.6122, -0.6073, -0.5506, -0.5752],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14030243 0.03360273 0.11112431 0.05486913 0.08658863 0.09549055
 0.29644804 0.18157418]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5314, -0.5252, -0.4943, -0.5844, -0.5057, -0.5514, -0.5635, -0.5602],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12491657 0.14143187 0.26192213 0.04321634 0.20888    0.08372653
 0.06569731 0.07020926]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5458, -0.4861, -0.4743, -0.4769, -0.5133, -0.5376, -0.4862, -0.5303],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04954982 0.16355821 0.20692487 0.19625947 0.0949263  0.0583097
 0.16296946 0.06750218]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5092, -0.5308, -0.5366, -0.5378, -0.5170, -0.5457, -0.4712, -0.4914],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12990767 0.08429626 0.07509361 0.07338773 0.11119715 0.0625764
 0.27802838 0.18551279]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4782, -0.4910, -0.4491, -0.4928, -0.4846, -0.5217, -0.4759, -0.4732],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12868729 0.09970599 0.23069297 0.0961843  0.11337907 0.05395919
 0.13498188 0.14240932]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4390, -0.4535, -0.4542, -0.4494, -0.4821, -0.4360, -0.4833, -0.4691],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17424087 0.13024119 0.12840656 0.14150692 0.07356271 0.18487342
 0.07184405 0.09532427]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.712
key: ssim
value: 0.845
key: lpips
value: 0.110
key: facenet_l2
value: 0.343
key: adaface_l2
value: 0.533
ref_face_img: tensor([[[[ 0.2941,  0.2941,  0.3333,  ..., -0.7569, -0.7647, -0.7647],
          [ 0.2941,  0.2941,  0.3255,  ..., -0.7725, -0.7804, -0.7804],
          [ 0.2863,  0.3020,  0.3255,  ..., -0.7725, -0.7804, -0.7804],
          ...,
          [-0.4353, -0.4431, -0.4275,  ...,  0.4902,  0.4902,  0.4902],
          [-0.4588, -0.4510, -0.4353,  ...,  0.4980,  0.4980,  0.4980],
          [-0.4510, -0.4353, -0.4275,  ...,  0.4980,  0.4980,  0.4980]],

         [[ 0.2078,  0.2157,  0.2471,  ..., -0.7647, -0.7725, -0.7725],
          [ 0.2078,  0.2235,  0.2471,  ..., -0.7804, -0.7882, -0.7882],
          [ 0.2157,  0.2314,  0.2471,  ..., -0.7804, -0.7882, -0.7882],
          ...,
          [-0.4824, -0.4824, -0.4667,  ...,  0.3569,  0.3569,  0.3569],
          [-0.4745, -0.4745, -0.4667,  ...,  0.3647,  0.3647,  0.3647],
          [-0.4588, -0.4588, -0.4588,  ...,  0.3647,  0.3647,  0.3647]],

         [[-0.0902, -0.0667, -0.0275,  ..., -0.9294, -0.9373, -0.9373],
          [-0.0902, -0.0667, -0.0275,  ..., -0.9451, -0.9529, -0.9529],
          [-0.0980, -0.0902, -0.0431,  ..., -0.9451, -0.9529, -0.9529],
          ...,
          [-0.7804, -0.8039, -0.8118,  ...,  0.1529,  0.1529,  0.1451],
          [-0.7725, -0.7882, -0.8039,  ...,  0.1608,  0.1608,  0.1529],
          [-0.7569, -0.7647, -0.7725,  ...,  0.1608,  0.1608,  0.1529]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:36,  2.70it/s, distance=295]  2%|▏         | 2/100 [00:00<00:21,  4.55it/s, distance=209]  4%|▍         | 4/100 [00:00<00:13,  7.08it/s, distance=147]  6%|▌         | 6/100 [00:00<00:10,  8.60it/s, distance=124]  8%|▊         | 8/100 [00:01<00:09,  9.53it/s, distance=112] 10%|█         | 10/100 [00:01<00:13,  6.61it/s, distance=96.5] 12%|█▏        | 12/100 [00:01<00:11,  7.71it/s, distance=84.9] 14%|█▍        | 14/100 [00:01<00:09,  8.61it/s, distance=77.7] 16%|█▌        | 16/100 [00:02<00:09,  9.33it/s, distance=72.5] 18%|█▊        | 18/100 [00:02<00:11,  6.85it/s, distance=65.7] 20%|██        | 20/100 [00:02<00:10,  7.80it/s, distance=65.2] 22%|██▏       | 22/100 [00:02<00:09,  8.62it/s, distance=61.1] 24%|██▍       | 24/100 [00:03<00:08,  9.30it/s, distance=56.9] 26%|██▌       | 26/100 [00:03<00:10,  6.98it/s, distance=55]   28%|██▊       | 28/100 [00:03<00:09,  7.89it/s, distance=53.7] 30%|███       | 30/100 [00:03<00:08,  8.68it/s, distance=49.2] 32%|███▏      | 32/100 [00:03<00:07,  9.33it/s, distance=52.1] 34%|███▍      | 34/100 [00:04<00:09,  6.96it/s, distance=50.3] 36%|███▌      | 36/100 [00:04<00:08,  7.88it/s, distance=43.3] 38%|███▊      | 38/100 [00:04<00:07,  8.66it/s, distance=41.1] 40%|████      | 40/100 [00:04<00:06,  9.31it/s, distance=40.5] 42%|████▏     | 42/100 [00:05<00:08,  6.95it/s, distance=37.9] 44%|████▍     | 44/100 [00:05<00:07,  7.86it/s, distance=37]   46%|████▌     | 46/100 [00:05<00:06,  8.65it/s, distance=35.6] 48%|████▊     | 48/100 [00:05<00:05,  9.31it/s, distance=34.8] 50%|█████     | 50/100 [00:06<00:07,  6.92it/s, distance=34.1] 52%|█████▏    | 52/100 [00:06<00:06,  7.83it/s, distance=33.2] 54%|█████▍    | 54/100 [00:06<00:05,  8.63it/s, distance=32.7] 56%|█████▌    | 56/100 [00:06<00:04,  9.30it/s, distance=32]   58%|█████▊    | 58/100 [00:07<00:06,  6.95it/s, distance=30.9] 60%|██████    | 60/100 [00:07<00:05,  7.86it/s, distance=30.3] 62%|██████▏   | 62/100 [00:07<00:04,  8.66it/s, distance=29.8] 64%|██████▍   | 64/100 [00:07<00:03,  9.32it/s, distance=29.2] 66%|██████▌   | 66/100 [00:08<00:04,  6.95it/s, distance=28.6] 68%|██████▊   | 68/100 [00:08<00:04,  7.87it/s, distance=28.2] 70%|███████   | 70/100 [00:08<00:03,  8.65it/s, distance=27.8] 72%|███████▏  | 72/100 [00:08<00:03,  9.31it/s, distance=27.4] 74%|███████▍  | 74/100 [00:09<00:03,  6.94it/s, distance=27]   76%|███████▌  | 76/100 [00:09<00:03,  7.86it/s, distance=26.6] 78%|███████▊  | 78/100 [00:09<00:02,  8.66it/s, distance=26.2] 80%|████████  | 80/100 [00:09<00:02,  9.31it/s, distance=25.8] 82%|████████▏ | 82/100 [00:10<00:02,  6.94it/s, distance=25.4] 84%|████████▍ | 84/100 [00:10<00:02,  7.85it/s, distance=24.9] 86%|████████▌ | 86/100 [00:10<00:01,  8.64it/s, distance=24.5] 88%|████████▊ | 88/100 [00:10<00:01,  9.30it/s, distance=24.1] 90%|█████████ | 90/100 [00:11<00:01,  6.95it/s, distance=23.6] 92%|█████████▏| 92/100 [00:11<00:01,  7.86it/s, distance=23]   94%|█████████▍| 94/100 [00:11<00:00,  8.65it/s, distance=22.3] 96%|█████████▌| 96/100 [00:11<00:00,  9.31it/s, distance=21.4] 98%|█████████▊| 98/100 [00:12<00:00,  9.84it/s, distance=20]  100%|██████████| 100/100 [00:12<00:00, 10.22it/s, distance=15.6]100%|██████████| 100/100 [00:12<00:00,  8.16it/s, distance=15.6]
2025-06-18 20:35:50,304 [MPGD] >> Inference for image 25
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -1.8790e+00, -1.9306e+00,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9239, -1.8646, -1.8009, -1.8018, -1.9547, -1.9274, -1.8266, -1.9271],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02710871 0.0887032  0.31711037 0.31183889 0.01465397 0.02529354
 0.18985876 0.02543256]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4959, -1.5521, -1.4601, -1.3661, -1.3769, -1.5314, -1.4544, -1.5274],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03235202 0.01051708 0.06620776 0.43383894 0.34974522 0.01588937
 0.07422813 0.01722147]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2529, -1.2753, -1.3218, -1.1783, -1.2344, -1.1774, -1.1974, -1.2537],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06121522 0.03909342 0.01542436 0.2721089  0.08869859 0.27746252
 0.18573218 0.06026481]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0515, -1.1418, -1.1333, -1.1402, -1.0906, -1.1455, -1.2071, -1.1670],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.43806819 0.07191165 0.08532991 0.07428691 0.20053498 0.06688651
 0.01948516 0.0434967 ]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9065, -0.9560, -0.8827, -1.0192, -0.9498, -0.8423, -0.8757, -0.8558],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08528974 0.03168614 0.13730122 0.00894415 0.0358986  0.30800825
 0.15772245 0.23514944]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7221, -0.7090, -0.6641, -0.7846, -0.7636, -0.6775, -0.6945, -0.6379],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06343022 0.08236211 0.20210564 0.01815838 0.02766324 0.1545783
 0.10998198 0.34172013]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5942, -0.5808, -0.7543, -0.6079, -0.5598, -0.6409, -0.5575, -0.5919],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11600979 0.15165336 0.00471714 0.08825453 0.23075489 0.04554325
 0.24166806 0.12139899]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5463, -0.5095, -0.5918, -0.5134, -0.5448, -0.6129, -0.5355, -0.5338],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10830834 0.22603813 0.04356375 0.20891757 0.11144995 0.02857265
 0.13422927 0.13892034]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5078, -0.5302, -0.5762, -0.4404, -0.5310, -0.4925, -0.5295, -0.5165],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10845624 0.06932705 0.02764139 0.41773466 0.06815095 0.14727492
 0.07022839 0.09118639]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4929, -0.5037, -0.4859, -0.4572, -0.4527, -0.4880, -0.4894, -0.4638],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08930925 0.07194845 0.10266482 0.18240248 0.19955455 0.09852934
 0.09573116 0.15985995]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4586, -0.4746, -0.4672, -0.4189, -0.4593, -0.4304, -0.4472, -0.4150],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08946521 0.06503411 0.07529666 0.19814593 0.08829723 0.15724697
 0.11236265 0.21415122]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.688
key: ssim
value: 0.850
key: lpips
value: 0.104
key: facenet_l2
value: 0.293
key: adaface_l2
value: 0.479
ref_face_img: tensor([[[[ 0.6863,  0.6863,  0.6863,  ...,  0.8275,  0.8353,  0.8353],
          [ 0.6863,  0.6863,  0.6863,  ...,  0.8275,  0.8353,  0.8353],
          [ 0.6863,  0.6863,  0.6863,  ...,  0.8275,  0.8275,  0.8353],
          ...,
          [ 0.6549,  0.6471,  0.6471,  ..., -0.7176, -0.7176, -0.7098],
          [ 0.6549,  0.6471,  0.6471,  ..., -0.7412, -0.7412, -0.7176],
          [ 0.6471,  0.6549,  0.6549,  ..., -0.7098, -0.7333, -0.7020]],

         [[ 0.7569,  0.7569,  0.7569,  ...,  0.9059,  0.9137,  0.9137],
          [ 0.7569,  0.7569,  0.7569,  ...,  0.9059,  0.9137,  0.9137],
          [ 0.7569,  0.7569,  0.7569,  ...,  0.9059,  0.9059,  0.9137],
          ...,
          [ 0.7098,  0.7020,  0.7020,  ..., -0.6941, -0.6941, -0.6863],
          [ 0.7098,  0.7020,  0.7020,  ..., -0.7176, -0.7176, -0.6941],
          [ 0.7020,  0.7098,  0.7098,  ..., -0.6863, -0.7098, -0.6784]],

         [[ 0.5451,  0.5294,  0.5137,  ...,  0.9765,  0.9765,  0.9765],
          [ 0.5294,  0.5137,  0.5059,  ...,  0.9765,  0.9843,  0.9843],
          [ 0.5294,  0.5137,  0.5059,  ...,  0.9765,  0.9765,  0.9843],
          ...,
          [ 0.7882,  0.7804,  0.7804,  ..., -0.6549, -0.6549, -0.6471],
          [ 0.7882,  0.7804,  0.7804,  ..., -0.6784, -0.6784, -0.6549],
          [ 0.7804,  0.7882,  0.7882,  ..., -0.6471, -0.6706, -0.6392]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:35,  2.83it/s, distance=250]  3%|▎         | 3/100 [00:00<00:15,  6.21it/s, distance=160]  5%|▌         | 5/100 [00:00<00:11,  8.10it/s, distance=137]  7%|▋         | 7/100 [00:00<00:10,  9.21it/s, distance=133]  9%|▉         | 9/100 [00:01<00:13,  6.53it/s, distance=104] 11%|█         | 11/100 [00:01<00:11,  7.69it/s, distance=94] 13%|█▎        | 13/100 [00:01<00:10,  8.61it/s, distance=84.6] 15%|█▌        | 15/100 [00:01<00:09,  9.32it/s, distance=75.5] 17%|█▋        | 17/100 [00:02<00:12,  6.89it/s, distance=74.3] 19%|█▉        | 19/100 [00:02<00:10,  7.87it/s, distance=64]   21%|██        | 21/100 [00:02<00:09,  8.69it/s, distance=57.7] 23%|██▎       | 23/100 [00:02<00:08,  9.35it/s, distance=53.7] 25%|██▌       | 25/100 [00:03<00:10,  7.00it/s, distance=48.6] 27%|██▋       | 27/100 [00:03<00:09,  7.94it/s, distance=47]   29%|██▉       | 29/100 [00:03<00:08,  8.72it/s, distance=44.3] 31%|███       | 31/100 [00:03<00:07,  9.36it/s, distance=42.6] 33%|███▎      | 33/100 [00:04<00:09,  6.95it/s, distance=40.7] 35%|███▌      | 35/100 [00:04<00:08,  7.90it/s, distance=39.8] 37%|███▋      | 37/100 [00:04<00:07,  8.68it/s, distance=38.8] 39%|███▉      | 39/100 [00:04<00:06,  9.34it/s, distance=37.1] 41%|████      | 41/100 [00:05<00:08,  6.99it/s, distance=36.1] 43%|████▎     | 43/100 [00:05<00:07,  7.91it/s, distance=35.4] 45%|████▌     | 45/100 [00:05<00:06,  8.70it/s, distance=34.4] 47%|████▋     | 47/100 [00:05<00:05,  9.35it/s, distance=33.5] 49%|████▉     | 49/100 [00:06<00:07,  6.95it/s, distance=33.1] 51%|█████     | 51/100 [00:06<00:06,  7.88it/s, distance=32.2] 53%|█████▎    | 53/100 [00:06<00:05,  8.67it/s, distance=31.6] 55%|█████▌    | 55/100 [00:06<00:04,  9.32it/s, distance=31.1] 57%|█████▋    | 57/100 [00:07<00:06,  6.97it/s, distance=30.5] 59%|█████▉    | 59/100 [00:07<00:05,  7.90it/s, distance=29.9] 61%|██████    | 61/100 [00:07<00:04,  8.68it/s, distance=29.4] 63%|██████▎   | 63/100 [00:07<00:03,  9.33it/s, distance=29]   65%|██████▌   | 65/100 [00:08<00:05,  6.99it/s, distance=28.5] 67%|██████▋   | 67/100 [00:08<00:04,  7.92it/s, distance=28.2] 69%|██████▉   | 69/100 [00:08<00:03,  8.71it/s, distance=27.8] 71%|███████   | 71/100 [00:08<00:03,  9.35it/s, distance=27.4] 73%|███████▎  | 73/100 [00:09<00:03,  7.00it/s, distance=26.9] 75%|███████▌  | 75/100 [00:09<00:03,  7.93it/s, distance=26.6] 77%|███████▋  | 77/100 [00:09<00:02,  8.71it/s, distance=26.3] 79%|███████▉  | 79/100 [00:09<00:02,  9.35it/s, distance=25.9] 81%|████████  | 81/100 [00:10<00:02,  7.00it/s, distance=25.5] 83%|████████▎ | 83/100 [00:10<00:02,  7.94it/s, distance=25.2] 85%|████████▌ | 85/100 [00:10<00:01,  8.71it/s, distance=24.8] 87%|████████▋ | 87/100 [00:10<00:01,  9.36it/s, distance=24.3] 89%|████████▉ | 89/100 [00:11<00:01,  7.01it/s, distance=23.8] 91%|█████████ | 91/100 [00:11<00:01,  7.94it/s, distance=23.3] 93%|█████████▎| 93/100 [00:11<00:00,  8.71it/s, distance=22.7] 95%|█████████▌| 95/100 [00:11<00:00,  9.36it/s, distance=21.9] 97%|█████████▋| 97/100 [00:11<00:00,  9.86it/s, distance=20.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.25it/s, distance=18.8]100%|██████████| 100/100 [00:12<00:00,  8.23it/s, distance=15.7]
2025-06-18 20:36:03,724 [MPGD] >> Inference for image 26
reward_name: adaface, curr_reward: tensor([-2.0644e+00, -1.9250e+00, -5.1200e+08, -1.9219e+00, -1.9915e+00,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9023, -1.9197, -2.0046, -1.9704, -2.0744, -1.8227, -1.8667, -2.0347],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.109355   0.07718982 0.01414258 0.02798264 0.00350227 0.53701671
 0.22307154 0.00773944]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6586, -1.5124, -1.5071, -1.4349, -1.4198, -1.4864, -1.5524, -1.4693],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00302869 0.05638079 0.06264586 0.2653154  0.35906503 0.09488294
 0.02534091 0.1333404 ]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2296, -1.3106, -1.2033, -1.2782, -1.2166, -1.1006, -1.3836, -1.1981],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05080007 0.01004187 0.08597624 0.01921188 0.06586279 0.67045323
 0.00233257 0.09532134]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9443, -1.0031, -0.9893, -0.9942, -1.0098, -0.9612, -0.9714, -1.0297],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.26117839 0.0805875  0.10620224 0.0962378  0.07039683 0.18629627
 0.1518415  0.04725947]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9901, -0.8415, -0.8638, -0.8846, -0.8657, -0.9388, -0.9519, -0.9895],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01688397 0.32952195 0.21110652 0.13903457 0.20309881 0.04707079
 0.03619053 0.01709286]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7550, -0.6741, -0.6889, -0.7386, -0.6895, -0.7531, -0.8118, -0.7751],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05907336 0.2979948  0.22196943 0.08207371 0.21899627 0.061385
 0.01898744 0.03951998]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6520, -0.6821, -0.6447, -0.5773, -0.5805, -0.6033, -0.5519, -0.5733],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03813139 0.02088315 0.04415867 0.16996837 0.15947909 0.10097354
 0.28224391 0.18416189]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4961, -0.5656, -0.4330, -0.4902, -0.5556, -0.5095, -0.5005, -0.4737],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10582842 0.02632858 0.37365009 0.11889506 0.03215519 0.08093361
 0.09684432 0.16536474]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3703, -0.4196, -0.3727, -0.3741, -0.3562, -0.4895, -0.4444, -0.4057],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.18545794 0.0692221  0.17687114 0.17180521 0.24601905 0.01710714
 0.04216468 0.09135275]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3590, -0.3244, -0.3340, -0.3134, -0.3377, -0.3264, -0.3301, -0.3198],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06867981 0.13717773 0.11331733 0.17086147 0.10521693 0.13183347
 0.12254101 0.15037225]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3225, -0.3420, -0.3122, -0.3129, -0.3239, -0.3071, -0.3301, -0.3419],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12512304 0.08477646 0.1537343  0.1517101  0.12180868 0.17041128
 0.10748222 0.08495391]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 31.788
key: ssim
value: 0.859
key: lpips
value: 0.069
key: facenet_l2
value: 0.245
key: adaface_l2
value: 0.407
ref_face_img: tensor([[[[-0.4353, -0.4588, -0.4824,  ..., -0.2235, -0.2392, -0.2471],
          [-0.4353, -0.4431, -0.4745,  ..., -0.2078, -0.2235, -0.2235],
          [-0.4275, -0.4431, -0.4588,  ..., -0.1922, -0.2078, -0.2078],
          ...,
          [ 0.1216,  0.1373,  0.1373,  ...,  0.5137,  0.5137,  0.5137],
          [ 0.1294,  0.1373,  0.1294,  ...,  0.4824,  0.4902,  0.4902],
          [ 0.1294,  0.1294,  0.1216,  ...,  0.4510,  0.4510,  0.4588]],

         [[-0.5686, -0.5843, -0.6078,  ..., -0.4902, -0.5059, -0.5059],
          [-0.5686, -0.5765, -0.6078,  ..., -0.4824, -0.4902, -0.4902],
          [-0.5686, -0.5765, -0.5922,  ..., -0.4667, -0.4745, -0.4745],
          ...,
          [-0.1608, -0.1529, -0.1529,  ...,  0.1451,  0.1451,  0.1451],
          [-0.1529, -0.1529, -0.1529,  ...,  0.1216,  0.1294,  0.1294],
          [-0.1529, -0.1529, -0.1608,  ...,  0.0980,  0.1059,  0.1059]],

         [[-0.8902, -0.8902, -0.9059,  ..., -0.6941, -0.7098, -0.7098],
          [-0.8902, -0.8902, -0.9059,  ..., -0.6863, -0.6941, -0.6941],
          [-0.8824, -0.8902, -0.8980,  ..., -0.6706, -0.6784, -0.6784],
          ...,
          [-0.4745, -0.4667, -0.4745,  ..., -0.0667, -0.0667, -0.0667],
          [-0.4745, -0.4745, -0.4745,  ..., -0.0745, -0.0745, -0.0667],
          [-0.4745, -0.4745, -0.4745,  ..., -0.0824, -0.0824, -0.0824]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.89it/s, distance=360]  3%|▎         | 3/100 [00:00<00:14,  6.49it/s, distance=161]  5%|▌         | 5/100 [00:00<00:11,  8.32it/s, distance=132]  7%|▋         | 7/100 [00:00<00:09,  9.37it/s, distance=117]  9%|▉         | 9/100 [00:01<00:14,  6.44it/s, distance=118] 11%|█         | 11/100 [00:01<00:11,  7.62it/s, distance=101] 13%|█▎        | 13/100 [00:01<00:10,  8.55it/s, distance=88.6] 15%|█▌        | 15/100 [00:01<00:09,  9.29it/s, distance=79]   17%|█▋        | 17/100 [00:02<00:12,  6.76it/s, distance=71.8] 19%|█▉        | 19/100 [00:02<00:10,  7.75it/s, distance=63.1] 21%|██        | 21/100 [00:02<00:09,  8.58it/s, distance=58.7] 23%|██▎       | 23/100 [00:02<00:08,  9.25it/s, distance=55.8] 25%|██▌       | 25/100 [00:03<00:10,  6.87it/s, distance=53.3] 27%|██▋       | 27/100 [00:03<00:09,  7.81it/s, distance=51.9] 29%|██▉       | 29/100 [00:03<00:08,  8.62it/s, distance=49.4] 31%|███       | 31/100 [00:03<00:07,  9.27it/s, distance=47.5] 33%|███▎      | 33/100 [00:04<00:09,  6.89it/s, distance=45.5] 35%|███▌      | 35/100 [00:04<00:08,  7.83it/s, distance=44.8] 37%|███▋      | 37/100 [00:04<00:07,  8.63it/s, distance=43.1] 39%|███▉      | 39/100 [00:04<00:06,  9.28it/s, distance=41.8] 41%|████      | 41/100 [00:05<00:08,  6.87it/s, distance=40.5] 43%|████▎     | 43/100 [00:05<00:07,  7.80it/s, distance=39.2] 45%|████▌     | 45/100 [00:05<00:06,  8.61it/s, distance=38.2] 47%|████▋     | 47/100 [00:05<00:05,  9.28it/s, distance=37.3] 49%|████▉     | 49/100 [00:06<00:07,  6.87it/s, distance=36.4] 51%|█████     | 51/100 [00:06<00:06,  7.82it/s, distance=35.5] 53%|█████▎    | 53/100 [00:06<00:05,  8.62it/s, distance=34.8] 55%|█████▌    | 55/100 [00:06<00:04,  9.29it/s, distance=34.2] 57%|█████▋    | 57/100 [00:07<00:06,  6.88it/s, distance=33.7] 59%|█████▉    | 59/100 [00:07<00:05,  7.82it/s, distance=32.9] 61%|██████    | 61/100 [00:07<00:04,  8.62it/s, distance=32.3] 63%|██████▎   | 63/100 [00:07<00:03,  9.27it/s, distance=31.6] 65%|██████▌   | 65/100 [00:08<00:05,  6.86it/s, distance=31.2] 67%|██████▋   | 67/100 [00:08<00:04,  7.81it/s, distance=30.6] 69%|██████▉   | 69/100 [00:08<00:03,  8.61it/s, distance=30.1] 71%|███████   | 71/100 [00:08<00:03,  9.28it/s, distance=29.6] 73%|███████▎  | 73/100 [00:09<00:03,  6.87it/s, distance=29.1] 75%|███████▌  | 75/100 [00:09<00:03,  7.81it/s, distance=28.7] 77%|███████▋  | 77/100 [00:09<00:02,  8.60it/s, distance=28.2] 79%|███████▉  | 79/100 [00:09<00:02,  9.26it/s, distance=27.8] 81%|████████  | 81/100 [00:10<00:02,  6.86it/s, distance=27.3] 83%|████████▎ | 83/100 [00:10<00:02,  7.80it/s, distance=26.9] 85%|████████▌ | 85/100 [00:10<00:01,  8.60it/s, distance=26.4] 87%|████████▋ | 87/100 [00:10<00:01,  9.26it/s, distance=25.9] 89%|████████▉ | 89/100 [00:11<00:01,  6.85it/s, distance=25.5] 91%|█████████ | 91/100 [00:11<00:01,  7.79it/s, distance=24.8] 93%|█████████▎| 93/100 [00:11<00:00,  8.59it/s, distance=24.1] 95%|█████████▌| 95/100 [00:11<00:00,  9.26it/s, distance=23.2] 97%|█████████▋| 97/100 [00:12<00:00,  9.78it/s, distance=22]   99%|█████████▉| 99/100 [00:12<00:00, 10.18it/s, distance=19.8]100%|██████████| 100/100 [00:12<00:00,  8.15it/s, distance=16.9]
2025-06-18 20:36:18,777 [MPGD] >> Inference for image 27
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08, -1.9472e+00,
        -1.9367e+00, -1.9467e+00, -2.0373e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9502, -2.0186, -1.9449, -2.0593, -2.0642, -2.0741, -1.9780, -2.1463],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.3068906  0.07816856 0.3410575  0.03464355 0.0314046  0.0257728
 0.1759817  0.00608069]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6721, -1.8333, -1.7043, -1.7261, -1.6651, -1.5208, -1.8110, -1.7382],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04167042 0.00165633 0.02186461 0.01413348 0.04795146 0.85902687
 0.00259186 0.01110498]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1631, -1.1794, -1.1831, -1.3827, -1.4521, -1.1793, -1.1797, -1.3493],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.25832748 0.18633692 0.17309156 0.00319701 0.00079759 0.18667396
 0.18534178 0.00623369]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2734, -1.2694, -1.1719, -1.1255, -1.2590, -1.1540, -1.1745, -1.1714],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01779878 0.01928246 0.13576798 0.34338212 0.0237648  0.19413824
 0.12883881 0.13702682]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1310, -1.1757, -1.0522, -1.1804, -1.1066, -1.0785, -1.0045, -1.0744],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03734064 0.0152821  0.18059259 0.01390273 0.0608182  0.10681039
 0.46938456 0.11586879]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0604, -0.9779, -1.0223, -1.0396, -0.9866, -1.0554, -1.0654, -1.1059],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05998394 0.31263829 0.12863981 0.09105441 0.26277468 0.06638344
 0.05435355 0.02417187]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9289, -1.0333, -0.9347, -0.9853, -1.0584, -1.0995, -1.0896, -1.0697],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.39297221 0.04865657 0.34942425 0.12721164 0.02946763 0.01295532
 0.01579468 0.0235177 ]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9722, -0.9358, -0.9838, -0.9503, -0.9460, -0.9793, -0.9157, -0.9553],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08024474 0.16620663 0.06357673 0.12418335 0.13557316 0.06963492
 0.24821042 0.11237005]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8873, -0.9015, -0.9388, -0.9263, -0.9244, -0.9682, -0.9101, -0.9173],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.22580575 0.17000425 0.08073055 0.10363868 0.1076112  0.04479918
 0.1433137  0.12409668]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9408, -0.8498, -0.8870, -0.9252, -0.9444, -0.8972, -0.9209, -0.8598],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04690637 0.28908746 0.13742281 0.06407162 0.04358486 0.11204238
 0.06983796 0.23704655]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8380, -0.8582, -0.8913, -0.8159, -0.8764, -0.8747, -0.9090, -0.9024],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.19871335 0.13267797 0.06853246 0.30939675 0.09234111 0.09538979
 0.04808269 0.05486588]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 31.214
key: ssim
value: 0.892
key: lpips
value: 0.081
key: facenet_l2
value: 0.316
key: adaface_l2
value: 0.602
ref_face_img: tensor([[[[0.8824, 0.8824, 0.8824,  ..., 0.7569, 0.7490, 0.7490],
          [0.8824, 0.8824, 0.8824,  ..., 0.7333, 0.7255, 0.7412],
          [0.8824, 0.8824, 0.8824,  ..., 0.7020, 0.7020, 0.7255],
          ...,
          [0.5137, 0.5137, 0.5137,  ..., 0.7961, 0.7961, 0.7961],
          [0.5137, 0.5137, 0.5137,  ..., 0.7961, 0.7961, 0.7961],
          [0.5137, 0.5137, 0.5137,  ..., 0.7961, 0.7961, 0.7961]],

         [[0.9922, 0.9922, 0.9922,  ..., 0.8118, 0.8039, 0.8039],
          [0.9922, 0.9922, 0.9922,  ..., 0.7882, 0.7804, 0.7882],
          [0.9922, 0.9922, 0.9922,  ..., 0.7569, 0.7569, 0.7725],
          ...,
          [0.3098, 0.3098, 0.3098,  ..., 0.7020, 0.7020, 0.7020],
          [0.3098, 0.3098, 0.3098,  ..., 0.7020, 0.7020, 0.7020],
          [0.3098, 0.3098, 0.3098,  ..., 0.7020, 0.7020, 0.6941]],

         [[0.9922, 0.9922, 0.9922,  ..., 0.8431, 0.8275, 0.8275],
          [0.9922, 0.9922, 0.9922,  ..., 0.8196, 0.8118, 0.8196],
          [0.9922, 0.9922, 0.9922,  ..., 0.7961, 0.7961, 0.8039],
          ...,
          [0.0118, 0.0039, 0.0118,  ..., 0.5059, 0.5059, 0.5059],
          [0.0118, 0.0039, 0.0118,  ..., 0.5059, 0.5059, 0.5059],
          [0.0118, 0.0118, 0.0118,  ..., 0.5059, 0.5059, 0.5059]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:36,  2.70it/s, distance=275]  2%|▏         | 2/100 [00:00<00:21,  4.58it/s, distance=208]  4%|▍         | 4/100 [00:00<00:13,  7.06it/s, distance=164]  6%|▌         | 6/100 [00:00<00:10,  8.59it/s, distance=133]  8%|▊         | 8/100 [00:01<00:09,  9.51it/s, distance=115] 10%|█         | 10/100 [00:01<00:13,  6.65it/s, distance=98.6] 12%|█▏        | 12/100 [00:01<00:11,  7.75it/s, distance=91.4] 14%|█▍        | 14/100 [00:01<00:09,  8.64it/s, distance=85.3] 16%|█▌        | 16/100 [00:02<00:08,  9.34it/s, distance=77.7] 18%|█▊        | 18/100 [00:02<00:11,  6.88it/s, distance=73.8] 20%|██        | 20/100 [00:02<00:10,  7.82it/s, distance=70.3] 22%|██▏       | 22/100 [00:02<00:09,  8.63it/s, distance=68]   24%|██▍       | 24/100 [00:03<00:08,  9.30it/s, distance=66.8] 26%|██▌       | 26/100 [00:03<00:10,  6.94it/s, distance=62.7] 28%|██▊       | 28/100 [00:03<00:09,  7.85it/s, distance=60.7] 30%|███       | 30/100 [00:03<00:08,  8.66it/s, distance=59.2] 32%|███▏      | 32/100 [00:03<00:07,  9.31it/s, distance=58.3] 34%|███▍      | 34/100 [00:04<00:09,  7.00it/s, distance=56.4] 36%|███▌      | 36/100 [00:04<00:08,  7.90it/s, distance=54.1] 38%|███▊      | 38/100 [00:04<00:07,  8.69it/s, distance=50.9] 40%|████      | 40/100 [00:04<00:06,  9.34it/s, distance=49.5] 42%|████▏     | 42/100 [00:05<00:08,  6.96it/s, distance=47.9] 44%|████▍     | 44/100 [00:05<00:07,  7.86it/s, distance=46.3] 46%|████▌     | 46/100 [00:05<00:06,  8.66it/s, distance=44.7] 48%|████▊     | 48/100 [00:05<00:05,  9.31it/s, distance=43.6] 50%|█████     | 50/100 [00:06<00:07,  6.96it/s, distance=42.9] 52%|█████▏    | 52/100 [00:06<00:06,  7.87it/s, distance=41.2] 54%|█████▍    | 54/100 [00:06<00:05,  8.66it/s, distance=40.3] 56%|█████▌    | 56/100 [00:06<00:04,  9.31it/s, distance=39.7] 58%|█████▊    | 58/100 [00:07<00:06,  6.92it/s, distance=38.5] 60%|██████    | 60/100 [00:07<00:05,  7.84it/s, distance=37.5] 62%|██████▏   | 62/100 [00:07<00:04,  8.63it/s, distance=36.8] 64%|██████▍   | 64/100 [00:07<00:03,  9.28it/s, distance=35.9] 66%|██████▌   | 66/100 [00:08<00:04,  6.92it/s, distance=35.3] 68%|██████▊   | 68/100 [00:08<00:04,  7.83it/s, distance=34.5] 70%|███████   | 70/100 [00:08<00:03,  8.64it/s, distance=33.8] 72%|███████▏  | 72/100 [00:08<00:03,  9.29it/s, distance=33]   74%|███████▍  | 74/100 [00:09<00:03,  6.92it/s, distance=32.5] 76%|███████▌  | 76/100 [00:09<00:03,  7.83it/s, distance=31.7] 78%|███████▊  | 78/100 [00:09<00:02,  8.62it/s, distance=31.1] 80%|████████  | 80/100 [00:09<00:02,  9.28it/s, distance=30.4] 82%|████████▏ | 82/100 [00:10<00:02,  6.91it/s, distance=29.8] 84%|████████▍ | 84/100 [00:10<00:02,  7.83it/s, distance=29.1] 86%|████████▌ | 86/100 [00:10<00:01,  8.61it/s, distance=28.4] 88%|████████▊ | 88/100 [00:10<00:01,  9.26it/s, distance=27.7] 90%|█████████ | 90/100 [00:11<00:01,  6.94it/s, distance=26.8] 92%|█████████▏| 92/100 [00:11<00:01,  7.84it/s, distance=26]   94%|█████████▍| 94/100 [00:11<00:00,  8.64it/s, distance=25] 96%|█████████▌| 96/100 [00:11<00:00,  9.30it/s, distance=23.8] 98%|█████████▊| 98/100 [00:12<00:00,  9.81it/s, distance=22.1]100%|██████████| 100/100 [00:12<00:00, 10.20it/s, distance=17.5]100%|██████████| 100/100 [00:12<00:00,  8.15it/s, distance=17.5]
2025-06-18 20:36:32,995 [MPGD] >> Inference for image 28
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.1378e+00, -5.1200e+08, -2.0617e+00, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9600, -2.0133, -2.0901, -2.0085, -1.8824, -1.9826, -2.0684, -1.9879],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12753225 0.04388333 0.00944607 0.04831149 0.60209175 0.08115733
 0.01460051 0.07297727]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4814, -1.6662, -1.6146, -1.6474, -1.6112, -1.6391, -1.4834, -1.5294],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.38577415 0.00957982 0.02686763 0.01395115 0.02878374 0.01644722
 0.37084061 0.14775568]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1808, -1.3089, -1.4321, -1.2602, -1.1685, -1.2109, -1.3922, -1.3040],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.31128204 0.02398784 0.00204018 0.06356582 0.39782533 0.17028634
 0.00453179 0.02648065]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1553, -1.1814, -1.2052, -1.1075, -1.1075, -1.1263, -1.1873, -1.2527],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10384906 0.06168578 0.03834706 0.27057364 0.27041306 0.18554625
 0.05475705 0.01482811]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0443, -0.9877, -1.0020, -1.0583, -1.0459, -1.2249, -1.0418, -0.9583],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06749635 0.20940914 0.15722343 0.05099009 0.06532654 0.00182104
 0.07088822 0.37684519]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9961, -0.9746, -1.0779, -0.9381, -1.0002, -0.9133, -0.9820, -0.9734],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06678288 0.10264569 0.013011   0.21294924 0.06148506 0.34947779
 0.08847371 0.10517464]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9533, -0.9204, -0.9231, -0.9110, -0.9785, -0.9471, -1.0053, -0.8865],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07698341 0.14859361 0.14092364 0.17939856 0.04655676 0.08721246
 0.02722845 0.29310311]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9133, -0.8547, -0.8768, -0.8911, -0.9723, -0.9358, -0.9390, -0.8830],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0889585  0.28733755 0.18452885 0.13875267 0.02734684 0.05670894
 0.0531844  0.16318225]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9063, -0.8736, -0.8748, -0.8360, -0.9334, -0.9199, -0.8784, -0.9084],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07735569 0.14877137 0.14525993 0.31558692 0.04491801 0.05890674
 0.1351342  0.07406714]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8466, -0.8598, -0.8155, -0.8209, -0.8570, -0.7975, -0.8401, -0.8799],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09590948 0.07356111 0.17846007 0.16027491 0.07788963 0.25562231
 0.10908014 0.04920235]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8148, -0.8234, -0.7995, -0.7727, -0.8511, -0.7987, -0.8049, -0.8223],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10562728 0.088917   0.14352235 0.24525643 0.0511507  0.14578644
 0.12885189 0.09088791]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 26.808
key: ssim
value: 0.879
key: lpips
value: 0.066
key: facenet_l2
value: 0.442
key: adaface_l2
value: 0.741
ref_face_img: tensor([[[[-0.6941, -0.7020, -0.7098,  ..., -0.6941, -0.6784, -0.6706],
          [-0.6941, -0.7020, -0.7098,  ..., -0.6941, -0.6784, -0.6706],
          [-0.6941, -0.7020, -0.7098,  ..., -0.6941, -0.6784, -0.6706],
          ...,
          [-0.6549, -0.6549, -0.6549,  ...,  0.4431,  0.4431,  0.4431],
          [-0.6471, -0.6471, -0.6471,  ...,  0.3961,  0.3961,  0.3961],
          [-0.6392, -0.6392, -0.6392,  ...,  0.3412,  0.3333,  0.3333]],

         [[-0.5059, -0.5059, -0.5137,  ..., -0.4980, -0.4980, -0.4980],
          [-0.5059, -0.5059, -0.5137,  ..., -0.4980, -0.4980, -0.4902],
          [-0.5059, -0.5137, -0.5137,  ..., -0.4980, -0.4980, -0.4902],
          ...,
          [-0.4902, -0.4902, -0.4902,  ...,  0.0353,  0.0353,  0.0353],
          [-0.4902, -0.4902, -0.4902,  ...,  0.0039,  0.0039, -0.0039],
          [-0.4824, -0.4824, -0.4824,  ..., -0.0275, -0.0353, -0.0353]],

         [[-0.2627, -0.2627, -0.2627,  ..., -0.2627, -0.2627, -0.2627],
          [-0.2627, -0.2627, -0.2627,  ..., -0.2627, -0.2627, -0.2627],
          [-0.2627, -0.2627, -0.2627,  ..., -0.2627, -0.2627, -0.2627],
          ...,
          [-0.2471, -0.2471, -0.2471,  ..., -0.0902, -0.0902, -0.0902],
          [-0.2471, -0.2471, -0.2471,  ..., -0.1137, -0.1137, -0.1216],
          [-0.2471, -0.2471, -0.2471,  ..., -0.1373, -0.1451, -0.1529]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
  1%|          | 1/100 [00:00<00:36,  2.72it/s, distance=282]  3%|▎         | 3/100 [00:00<00:16,  5.99it/s, distance=161]  5%|▌         | 5/100 [00:00<00:12,  7.81it/s, distance=133]  7%|▋         | 7/100 [00:00<00:10,  8.99it/s, distance=120]  9%|▉         | 9/100 [00:01<00:14,  6.35it/s, distance=104] 11%|█         | 11/100 [00:01<00:11,  7.52it/s, distance=93.9] 13%|█▎        | 13/100 [00:01<00:10,  8.47it/s, distance=85.2] 15%|█▌        | 15/100 [00:01<00:09,  9.22it/s, distance=77.2] 17%|█▋        | 17/100 [00:02<00:12,  6.75it/s, distance=82.7] 19%|█▉        | 19/100 [00:02<00:10,  7.74it/s, distance=67]   21%|██        | 21/100 [00:02<00:09,  8.58it/s, distance=61.5] 23%|██▎       | 23/100 [00:02<00:08,  9.27it/s, distance=57.5] 25%|██▌       | 25/100 [00:03<00:11,  6.79it/s, distance=58.3] 27%|██▋       | 27/100 [00:03<00:09,  7.76it/s, distance=52.1] 29%|██▉       | 29/100 [00:03<00:08,  8.57it/s, distance=50.5] 31%|███       | 31/100 [00:03<00:07,  9.25it/s, distance=48.1] 33%|███▎      | 33/100 [00:04<00:09,  6.79it/s, distance=46]   35%|███▌      | 35/100 [00:04<00:08,  7.75it/s, distance=45.1] 37%|███▋      | 37/100 [00:04<00:07,  8.55it/s, distance=42.7] 39%|███▉      | 39/100 [00:04<00:06,  9.22it/s, distance=41.2] 41%|████      | 41/100 [00:05<00:08,  6.76it/s, distance=39.1] 43%|████▎     | 43/100 [00:05<00:07,  7.72it/s, distance=38.7] 45%|████▌     | 45/100 [00:05<00:06,  8.54it/s, distance=37.5] 47%|████▋     | 47/100 [00:05<00:05,  9.21it/s, distance=36.4] 49%|████▉     | 49/100 [00:06<00:07,  6.75it/s, distance=34.9] 51%|█████     | 51/100 [00:06<00:06,  7.69it/s, distance=34.8] 53%|█████▎    | 53/100 [00:06<00:05,  8.51it/s, distance=33.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.19it/s, distance=33.4] 57%|█████▋    | 57/100 [00:07<00:06,  6.75it/s, distance=33.2] 59%|█████▉    | 59/100 [00:07<00:05,  7.69it/s, distance=32.2] 61%|██████    | 61/100 [00:07<00:04,  8.51it/s, distance=31.6] 63%|██████▎   | 63/100 [00:07<00:04,  9.19it/s, distance=30.9] 65%|██████▌   | 65/100 [00:08<00:05,  6.74it/s, distance=30.3] 67%|██████▋   | 67/100 [00:08<00:04,  7.69it/s, distance=29.8] 69%|██████▉   | 69/100 [00:08<00:03,  8.51it/s, distance=29.4] 71%|███████   | 71/100 [00:08<00:03,  9.17it/s, distance=28.8] 73%|███████▎  | 73/100 [00:09<00:03,  6.75it/s, distance=28.4] 75%|███████▌  | 75/100 [00:09<00:03,  7.70it/s, distance=28]   77%|███████▋  | 77/100 [00:09<00:02,  8.51it/s, distance=27.5] 79%|███████▉  | 79/100 [00:09<00:02,  9.18it/s, distance=27]   81%|████████  | 81/100 [00:10<00:02,  6.76it/s, distance=26.5] 83%|████████▎ | 83/100 [00:10<00:02,  7.70it/s, distance=26.1] 85%|████████▌ | 85/100 [00:10<00:01,  8.51it/s, distance=25.6] 87%|████████▋ | 87/100 [00:10<00:01,  9.19it/s, distance=25.1] 89%|████████▉ | 89/100 [00:11<00:01,  6.77it/s, distance=24.6] 91%|█████████ | 91/100 [00:11<00:01,  7.71it/s, distance=24]   93%|█████████▎| 93/100 [00:11<00:00,  8.52it/s, distance=23.3] 95%|█████████▌| 95/100 [00:11<00:00,  9.20it/s, distance=22.4] 97%|█████████▋| 97/100 [00:12<00:00,  9.73it/s, distance=21.2] 99%|█████████▉| 99/100 [00:12<00:00, 10.15it/s, distance=19]  100%|██████████| 100/100 [00:12<00:00,  8.05it/s, distance=15.9]
2025-06-18 20:36:48,108 [MPGD] >> Inference for image 29
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.0015e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -1.9276e+00, -2.0253e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.1034, -1.9036, -2.1280, -2.1025, -2.0857, -1.8319, -2.1347, -1.8559],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00233656 0.12699281 0.00142662 0.00237675 0.00332692 0.53278634
 0.00124869 0.32950532]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7891, -1.6112, -1.6483, -1.6266, -1.7020, -1.5746, -1.6627, -1.7480],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00581228 0.20398449 0.09715354 0.14980326 0.03319006 0.42403553
 0.072809   0.01321183]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3212, -1.5944, -1.5475, -1.2985, -1.4531, -1.3481, -1.4575, -1.7084],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [3.02007197e-01 1.27919772e-03 3.26659243e-03 4.75631268e-01
 2.15763047e-02 1.76319390e-01 1.97891401e-02 1.30910212e-04]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1175, -1.0863, -1.2139, -1.0044, -1.2758, -1.2135, -1.1680, -1.1558],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07334742 0.13695655 0.0106812  0.70428095 0.0030962  0.01075897
 0.02671941 0.03415931]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9294, -0.8918, -0.9612, -0.9164, -0.8539, -0.9305, -0.9251, -0.8483],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0602535  0.12759489 0.03189522 0.07814812 0.27267436 0.05885301
 0.06566832 0.30491258]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8866, -0.8374, -0.7561, -0.8711, -0.7231, -0.8190, -0.7685, -0.8362],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01606328 0.04300629 0.21882672 0.021902   0.42322576 0.06219505
 0.17071078 0.04407012]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7163, -0.6971, -0.7483, -0.6957, -0.7889, -0.7612, -0.7046, -0.6802],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11815786 0.17328059 0.06221749 0.17825071 0.02762888 0.04815514
 0.14912855 0.24318078]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7371, -0.6798, -0.6454, -0.6759, -0.6891, -0.6987, -0.7190, -0.6537],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03946218 0.1242607  0.24713934 0.13440526 0.1032612  0.08514238
 0.05677254 0.2095564 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6059, -0.6166, -0.6044, -0.6214, -0.6693, -0.6147, -0.7146, -0.6792],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.19863802 0.16031011 0.20469751 0.14560414 0.05585479 0.16643386
 0.02259674 0.04586484]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6617, -0.6765, -0.6106, -0.5808, -0.6277, -0.6540, -0.6348, -0.6183],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05950408 0.04428968 0.16537011 0.30014897 0.11744716 0.06944321
 0.10196919 0.1418276 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6052, -0.6488, -0.6282, -0.5991, -0.6304, -0.5813, -0.6287, -0.6073],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14328539 0.05988096 0.09037945 0.16185218 0.0865461  0.23113095
 0.08957254 0.13735244]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.406
key: ssim
value: 0.873
key: lpips
value: 0.093
key: facenet_l2
value: 0.358
key: adaface_l2
value: 0.609
ref_face_img: tensor([[[[0.7255, 0.7176, 0.7098,  ..., 0.2314, 0.2471, 0.2627],
          [0.7176, 0.7176, 0.7098,  ..., 0.2706, 0.2941, 0.3020],
          [0.7176, 0.7098, 0.7098,  ..., 0.3255, 0.3490, 0.3569],
          ...,
          [0.8039, 0.8039, 0.7961,  ..., 0.6706, 0.6706, 0.6706],
          [0.8039, 0.7961, 0.7961,  ..., 0.6706, 0.6706, 0.6706],
          [0.8039, 0.7961, 0.7882,  ..., 0.6706, 0.6627, 0.6627]],

         [[0.5608, 0.5529, 0.5451,  ..., 0.1373, 0.1529, 0.1686],
          [0.5529, 0.5451, 0.5373,  ..., 0.1765, 0.2000, 0.2078],
          [0.5529, 0.5373, 0.5373,  ..., 0.2314, 0.2627, 0.2706],
          ...,
          [0.7882, 0.7882, 0.7804,  ..., 0.3333, 0.3333, 0.3333],
          [0.7882, 0.7882, 0.7804,  ..., 0.3333, 0.3333, 0.3333],
          [0.7804, 0.7804, 0.7804,  ..., 0.3333, 0.3333, 0.3333]],

         [[0.1686, 0.1529, 0.1294,  ..., 0.0667, 0.0902, 0.0980],
          [0.1686, 0.1451, 0.1216,  ..., 0.1137, 0.1451, 0.1529],
          [0.1529, 0.1373, 0.1137,  ..., 0.1765, 0.2078, 0.2157],
          ...,
          [0.8431, 0.8353, 0.8353,  ..., 0.1059, 0.1059, 0.1059],
          [0.8353, 0.8353, 0.8353,  ..., 0.1059, 0.1059, 0.1059],
          [0.8275, 0.8275, 0.8275,  ..., 0.1059, 0.1059, 0.0980]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:38,  2.60it/s, distance=270]  2%|▏         | 2/100 [00:00<00:21,  4.59it/s, distance=187]  3%|▎         | 3/100 [00:00<00:16,  6.06it/s, distance=168]  5%|▌         | 5/100 [00:00<00:11,  8.06it/s, distance=150]  7%|▋         | 7/100 [00:00<00:10,  9.24it/s, distance=130]  9%|▉         | 9/100 [00:01<00:14,  6.35it/s, distance=128] 11%|█         | 11/100 [00:01<00:11,  7.56it/s, distance=98.2] 13%|█▎        | 13/100 [00:01<00:10,  8.51it/s, distance=86]   15%|█▌        | 15/100 [00:01<00:09,  9.25it/s, distance=76.9] 17%|█▋        | 17/100 [00:02<00:12,  6.63it/s, distance=70.1] 19%|█▉        | 19/100 [00:02<00:10,  7.65it/s, distance=67.4] 21%|██        | 21/100 [00:02<00:09,  8.49it/s, distance=63.7] 23%|██▎       | 23/100 [00:02<00:08,  9.19it/s, distance=61.4] 25%|██▌       | 25/100 [00:03<00:11,  6.69it/s, distance=62.4] 27%|██▋       | 27/100 [00:03<00:09,  7.66it/s, distance=56.5] 29%|██▉       | 29/100 [00:03<00:08,  8.49it/s, distance=52.2] 31%|███       | 31/100 [00:03<00:07,  9.17it/s, distance=49.8] 33%|███▎      | 33/100 [00:04<00:09,  6.72it/s, distance=48.1] 35%|███▌      | 35/100 [00:04<00:08,  7.69it/s, distance=46.3] 37%|███▋      | 37/100 [00:04<00:07,  8.50it/s, distance=45.2] 39%|███▉      | 39/100 [00:04<00:06,  9.18it/s, distance=43.3] 41%|████      | 41/100 [00:05<00:08,  6.69it/s, distance=43.1] 43%|████▎     | 43/100 [00:05<00:07,  7.64it/s, distance=41]   45%|████▌     | 45/100 [00:05<00:06,  8.47it/s, distance=40.1] 47%|████▋     | 47/100 [00:06<00:05,  9.15it/s, distance=38.8] 49%|████▉     | 49/100 [00:06<00:07,  6.68it/s, distance=38.2] 51%|█████     | 51/100 [00:06<00:06,  7.63it/s, distance=37.1] 53%|█████▎    | 53/100 [00:06<00:05,  8.45it/s, distance=36.2] 55%|█████▌    | 55/100 [00:07<00:04,  9.14it/s, distance=35.2] 57%|█████▋    | 57/100 [00:07<00:06,  6.63it/s, distance=34.3] 59%|█████▉    | 59/100 [00:07<00:05,  7.59it/s, distance=33.7] 61%|██████    | 61/100 [00:07<00:04,  8.41it/s, distance=33.1] 63%|██████▎   | 63/100 [00:08<00:04,  9.10it/s, distance=32.4] 65%|██████▌   | 65/100 [00:08<00:05,  6.64it/s, distance=32]   67%|██████▋   | 67/100 [00:08<00:04,  7.59it/s, distance=31.4] 69%|██████▉   | 69/100 [00:08<00:03,  8.42it/s, distance=30.8] 71%|███████   | 71/100 [00:09<00:03,  9.12it/s, distance=30.2] 73%|███████▎  | 73/100 [00:09<00:04,  6.63it/s, distance=29.7] 75%|███████▌  | 75/100 [00:09<00:03,  7.60it/s, distance=29.3] 77%|███████▋  | 77/100 [00:09<00:02,  8.42it/s, distance=28.8] 79%|███████▉  | 79/100 [00:10<00:02,  9.11it/s, distance=28.2] 81%|████████  | 81/100 [00:10<00:02,  6.62it/s, distance=27.7] 83%|████████▎ | 83/100 [00:10<00:02,  7.58it/s, distance=27.2] 85%|████████▌ | 85/100 [00:10<00:01,  8.41it/s, distance=26.6] 87%|████████▋ | 87/100 [00:11<00:01,  9.11it/s, distance=26.1] 89%|████████▉ | 89/100 [00:11<00:01,  6.65it/s, distance=25.5] 91%|█████████ | 91/100 [00:11<00:01,  7.61it/s, distance=24.8] 93%|█████████▎| 93/100 [00:11<00:00,  8.43it/s, distance=24.1] 95%|█████████▌| 95/100 [00:12<00:00,  9.13it/s, distance=23.1] 97%|█████████▋| 97/100 [00:12<00:00,  9.68it/s, distance=21.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.12it/s, distance=19.6]100%|██████████| 100/100 [00:12<00:00,  7.95it/s, distance=16.4]
2025-06-18 20:37:03,371 [MPGD] >> Inference for image 30
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -1.8925e+00, -1.9285e+00, -1.9685e+00,
        -1.9299e+00, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0005, -1.9523, -1.9674, -2.1321, -1.9402, -2.0759, -2.0017, -2.0273],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09303928 0.24379746 0.18004814 0.00668978 0.3107795  0.02058793
 0.09067029 0.05438763]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4366, -1.6321, -1.5500, -1.6743, -1.7041, -1.5813, -1.5085, -1.6449],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.69222858 0.0138572  0.07163407 0.00595703 0.00328436 0.03827756
 0.16403468 0.01072652]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3547, -1.2621, -1.1846, -1.3120, -1.2034, -1.2393, -1.1792, -1.2262],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00855164 0.05447055 0.25652188 0.0201071  0.17640078 0.08592161
 0.2863229  0.11170354]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0049, -0.9209, -0.9590, -0.9470, -0.8379, -1.0293, -1.0024, -1.2595],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [2.38343315e-02 1.27943419e-01 5.97345122e-02 7.59227282e-02
 6.72733093e-01 1.46435465e-02 2.50418006e-02 1.46568639e-04]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8268, -0.7476, -0.7672, -0.7594, -0.7276, -0.7484, -0.8377, -0.7854],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03552397 0.17294019 0.1168013  0.13668289 0.25810801 0.17016894
 0.02856459 0.08121011]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6551, -0.7175, -0.6648, -0.6547, -0.6921, -0.7530, -0.6772, -0.7320],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.21771656 0.06243315 0.1793804  0.21919521 0.10392836 0.03074298
 0.13987844 0.04672489]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5972, -0.6174, -0.5764, -0.5840, -0.6174, -0.6698, -0.6116, -0.6014],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14183062 0.09453241 0.21486551 0.18446267 0.0946788  0.03316207
 0.10629362 0.1301743 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5234, -0.6159, -0.5749, -0.5670, -0.5899, -0.5785, -0.5604, -0.5594],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.28650752 0.04501809 0.10215937 0.11965089 0.07575927 0.09502178
 0.13669151 0.13919158]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5444, -0.5020, -0.5039, -0.5385, -0.5578, -0.5484, -0.5564, -0.5234],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09343511 0.21824929 0.20991432 0.10511756 0.07145831 0.0862781
 0.07341902 0.14212828]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5140, -0.5308, -0.4963, -0.4834, -0.5319, -0.5372, -0.5418, -0.4997],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12163288 0.0869477  0.17334805 0.22452523 0.08515932 0.07658565
 0.06975575 0.16204543]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4963, -0.5237, -0.4923, -0.5497, -0.5063, -0.4968, -0.5291, -0.5254],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1698135  0.09810914 0.18392279 0.05831035 0.13898233 0.16793565
 0.08804257 0.09488368]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.870
key: ssim
value: 0.877
key: lpips
value: 0.090
key: facenet_l2
value: 0.397
key: adaface_l2
value: 0.465
ref_face_img: tensor([[[[ 0.0196,  0.0118,  0.0039,  ...,  0.1294,  0.1451,  0.1529],
          [ 0.0353,  0.0353,  0.0275,  ...,  0.1294,  0.1451,  0.1529],
          [ 0.0588,  0.0588,  0.0588,  ...,  0.1373,  0.1529,  0.1529],
          ...,
          [-0.9059, -0.8980, -0.8824,  ..., -0.1294, -0.1137, -0.1137],
          [-0.9059, -0.8902, -0.8824,  ..., -0.1373, -0.1137, -0.1137],
          [-0.9059, -0.8902, -0.8745,  ..., -0.1373, -0.1216, -0.1137]],

         [[-0.9373, -0.9373, -0.9373,  ...,  0.1216,  0.1373,  0.1451],
          [-0.9373, -0.9373, -0.9373,  ...,  0.1216,  0.1373,  0.1451],
          [-0.9294, -0.9294, -0.9294,  ...,  0.1216,  0.1373,  0.1451],
          ...,
          [-0.9137, -0.8980, -0.8902,  ..., -0.1294, -0.1059, -0.1059],
          [-0.9059, -0.8980, -0.8824,  ..., -0.1294, -0.1059, -0.1059],
          [-0.9059, -0.8980, -0.8824,  ..., -0.1294, -0.1137, -0.1059]],

         [[-0.9451, -0.9451, -0.9451,  ...,  0.1373,  0.1529,  0.1608],
          [-0.9451, -0.9451, -0.9451,  ...,  0.1373,  0.1608,  0.1608],
          [-0.9451, -0.9451, -0.9451,  ...,  0.1451,  0.1608,  0.1608],
          ...,
          [-0.9137, -0.9059, -0.8902,  ..., -0.0745, -0.0588, -0.0588],
          [-0.9137, -0.8980, -0.8824,  ..., -0.0824, -0.0588, -0.0588],
          [-0.9137, -0.8980, -0.8824,  ..., -0.0824, -0.0588, -0.0588]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:37,  2.66it/s, distance=284]  2%|▏         | 2/100 [00:00<00:21,  4.51it/s, distance=203]  4%|▍         | 4/100 [00:00<00:13,  7.00it/s, distance=144]  6%|▌         | 6/100 [00:00<00:11,  8.53it/s, distance=126]  8%|▊         | 8/100 [00:01<00:09,  9.46it/s, distance=119] 10%|█         | 10/100 [00:01<00:13,  6.56it/s, distance=104] 12%|█▏        | 12/100 [00:01<00:11,  7.66it/s, distance=92.6] 14%|█▍        | 14/100 [00:01<00:10,  8.57it/s, distance=74.9] 16%|█▌        | 16/100 [00:02<00:09,  9.30it/s, distance=67.9] 18%|█▊        | 18/100 [00:02<00:12,  6.80it/s, distance=61.1] 20%|██        | 20/100 [00:02<00:10,  7.75it/s, distance=63.3] 22%|██▏       | 22/100 [00:02<00:09,  8.58it/s, distance=69.7] 24%|██▍       | 24/100 [00:03<00:08,  9.26it/s, distance=63.7] 26%|██▌       | 26/100 [00:03<00:10,  6.87it/s, distance=60]   28%|██▊       | 28/100 [00:03<00:09,  7.80it/s, distance=53.2] 30%|███       | 30/100 [00:03<00:08,  8.60it/s, distance=50.7] 32%|███▏      | 32/100 [00:04<00:07,  9.26it/s, distance=47.4] 34%|███▍      | 34/100 [00:04<00:09,  6.93it/s, distance=44.4] 36%|███▌      | 36/100 [00:04<00:08,  7.83it/s, distance=40.1] 38%|███▊      | 38/100 [00:04<00:07,  8.63it/s, distance=37.7] 40%|████      | 40/100 [00:05<00:06,  9.29it/s, distance=35.9] 42%|████▏     | 42/100 [00:05<00:08,  6.94it/s, distance=34.5] 44%|████▍     | 44/100 [00:05<00:07,  7.86it/s, distance=33.8] 46%|████▌     | 46/100 [00:05<00:06,  8.65it/s, distance=33]   48%|████▊     | 48/100 [00:06<00:05,  9.31it/s, distance=32.4] 50%|█████     | 50/100 [00:06<00:07,  6.89it/s, distance=31.6] 52%|█████▏    | 52/100 [00:06<00:06,  7.79it/s, distance=30.9] 54%|█████▍    | 54/100 [00:06<00:05,  8.59it/s, distance=30.5] 56%|█████▌    | 56/100 [00:07<00:04,  9.26it/s, distance=30]   58%|█████▊    | 58/100 [00:07<00:06,  6.88it/s, distance=29.3] 60%|██████    | 60/100 [00:07<00:05,  7.80it/s, distance=28.8] 62%|██████▏   | 62/100 [00:07<00:04,  8.59it/s, distance=28.4] 64%|██████▍   | 64/100 [00:07<00:03,  9.25it/s, distance=28]   66%|██████▌   | 66/100 [00:08<00:04,  6.90it/s, distance=27.6] 68%|██████▊   | 68/100 [00:08<00:04,  7.81it/s, distance=27.1] 70%|███████   | 70/100 [00:08<00:03,  8.61it/s, distance=26.8] 72%|███████▏  | 72/100 [00:08<00:03,  9.27it/s, distance=26.5] 74%|███████▍  | 74/100 [00:09<00:03,  6.89it/s, distance=26.2] 76%|███████▌  | 76/100 [00:09<00:03,  7.80it/s, distance=25.8] 78%|███████▊  | 78/100 [00:09<00:02,  8.60it/s, distance=25.4] 80%|████████  | 80/100 [00:09<00:02,  9.26it/s, distance=25]   82%|████████▏ | 82/100 [00:10<00:02,  6.76it/s, distance=24.6] 84%|████████▍ | 84/100 [00:10<00:02,  7.68it/s, distance=24.3] 86%|████████▌ | 86/100 [00:10<00:01,  8.48it/s, distance=23.9] 88%|████████▊ | 88/100 [00:11<00:01,  9.16it/s, distance=23.5] 90%|█████████ | 90/100 [00:11<00:01,  6.75it/s, distance=23.1] 92%|█████████▏| 92/100 [00:11<00:01,  7.68it/s, distance=22.5] 94%|█████████▍| 94/100 [00:11<00:00,  8.49it/s, distance=21.9] 96%|█████████▌| 96/100 [00:12<00:00,  9.17it/s, distance=21]   98%|█████████▊| 98/100 [00:12<00:00,  9.72it/s, distance=19.7]100%|██████████| 100/100 [00:12<00:00, 10.14it/s, distance=15.3]100%|██████████| 100/100 [00:12<00:00,  8.09it/s, distance=15.3]
2025-06-18 20:37:17,783 [MPGD] >> Inference for image 31
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -1.8310e+00, -5.1200e+08, -5.1200e+08, -1.8819e+00,
        -1.9952e+00, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7650, -1.8739, -1.8211, -1.8697, -1.6343, -1.8820, -1.9491, -1.7709],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06166355 0.00698134 0.02009901 0.00759231 0.84130461 0.00594068
 0.00155117 0.05486733]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4503, -1.2862, -1.3633, -1.3694, -1.3613, -1.4087, -1.2852, -1.3558],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01242688 0.33134981 0.07078152 0.06273997 0.07375344 0.0285594
 0.33808011 0.08230886]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9968, -1.0935, -1.1505, -1.0269, -1.0243, -0.9452, -1.0120, -1.0477],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16072838 0.02324386 0.0074309  0.08803171 0.09271203 0.45116626
 0.11859288 0.05809397]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7385, -0.8555, -0.9660, -0.8873, -0.8272, -0.7631, -0.9537, -0.9440],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.50789072 0.0489241  0.00536621 0.02587597 0.08611303 0.31063388
 0.00686626 0.00832983]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6728, -0.6080, -0.6558, -0.6936, -0.7234, -0.7149, -0.7313, -0.6674],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1119322  0.40875572 0.15717477 0.07377867 0.04067969 0.04819448
 0.0347553  0.12472918]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5801, -0.6397, -0.6422, -0.5984, -0.5688, -0.6116, -0.5352, -0.6021],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13937927 0.04232832 0.04027162 0.09664713 0.17487132 0.07424122
 0.34240813 0.08985299]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5153, -0.5642, -0.5395, -0.5261, -0.4989, -0.5171, -0.4591, -0.5880],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11817619 0.04443633 0.07285513 0.09523415 0.16401287 0.11401803
 0.36367176 0.02759554]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4748, -0.4130, -0.4400, -0.5004, -0.4526, -0.4651, -0.5077, -0.4640],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08642827 0.29710242 0.17334777 0.05175535 0.13470143 0.10485872
 0.04469987 0.10710617]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3946, -0.4141, -0.3809, -0.3987, -0.4576, -0.3841, -0.4057, -0.3997],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14022355 0.09495513 0.18436665 0.12908499 0.03974415 0.17277058
 0.11220164 0.12665332]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3974, -0.3337, -0.3910, -0.3907, -0.3817, -0.3752, -0.3616, -0.3324],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06453566 0.23065188 0.07326172 0.0738279  0.08839447 0.10050955
 0.13199067 0.23682814]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3675, -0.3568, -0.3391, -0.3516, -0.3863, -0.3076, -0.3547, -0.3494],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08266456 0.10226897 0.14578641 0.11351423 0.05674754 0.27383165
 0.10664308 0.11854356]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.853
key: ssim
value: 0.829
key: lpips
value: 0.132
key: facenet_l2
value: 0.271
key: adaface_l2
value: 0.463
ref_face_img: tensor([[[[0.5373, 0.5373, 0.5373,  ..., 0.4431, 0.4431, 0.4431],
          [0.5373, 0.5373, 0.5373,  ..., 0.4431, 0.4431, 0.4431],
          [0.5373, 0.5451, 0.5451,  ..., 0.4510, 0.4510, 0.4510],
          ...,
          [0.6392, 0.6392, 0.6392,  ..., 0.4667, 0.4902, 0.5059],
          [0.6392, 0.6392, 0.6392,  ..., 0.4667, 0.4824, 0.4980],
          [0.6392, 0.6392, 0.6392,  ..., 0.4510, 0.4745, 0.4980]],

         [[0.5373, 0.5373, 0.5373,  ..., 0.4510, 0.4510, 0.4510],
          [0.5373, 0.5373, 0.5373,  ..., 0.4510, 0.4510, 0.4510],
          [0.5373, 0.5373, 0.5373,  ..., 0.4510, 0.4510, 0.4510],
          ...,
          [0.6314, 0.6314, 0.6314,  ..., 0.3098, 0.3255, 0.3333],
          [0.6314, 0.6314, 0.6314,  ..., 0.3020, 0.3176, 0.3333],
          [0.6314, 0.6314, 0.6314,  ..., 0.2941, 0.3098, 0.3255]],

         [[0.5608, 0.5608, 0.5608,  ..., 0.5529, 0.5608, 0.5608],
          [0.5608, 0.5608, 0.5608,  ..., 0.5529, 0.5529, 0.5608],
          [0.5608, 0.5608, 0.5608,  ..., 0.5608, 0.5608, 0.5608],
          ...,
          [0.6157, 0.6157, 0.6157,  ..., 0.1686, 0.1765, 0.1843],
          [0.6157, 0.6157, 0.6157,  ..., 0.1608, 0.1765, 0.1843],
          [0.6157, 0.6157, 0.6157,  ..., 0.1608, 0.1686, 0.1765]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:36,  2.70it/s, distance=340]  3%|▎         | 3/100 [00:00<00:15,  6.20it/s, distance=162]  5%|▌         | 5/100 [00:00<00:11,  8.08it/s, distance=129]  7%|▋         | 7/100 [00:00<00:10,  9.19it/s, distance=107]  9%|▉         | 9/100 [00:01<00:14,  6.47it/s, distance=84.8] 11%|█         | 11/100 [00:01<00:11,  7.64it/s, distance=82]  13%|█▎        | 13/100 [00:01<00:10,  8.56it/s, distance=84.4] 15%|█▌        | 15/100 [00:01<00:09,  9.29it/s, distance=82.6] 17%|█▋        | 17/100 [00:02<00:12,  6.70it/s, distance=70.3] 19%|█▉        | 19/100 [00:02<00:10,  7.68it/s, distance=70.6] 21%|██        | 21/100 [00:02<00:09,  8.51it/s, distance=62.2] 23%|██▎       | 23/100 [00:02<00:08,  9.21it/s, distance=57.1] 25%|██▌       | 25/100 [00:03<00:11,  6.78it/s, distance=55.9] 27%|██▋       | 27/100 [00:03<00:09,  7.74it/s, distance=45.8] 29%|██▉       | 29/100 [00:03<00:08,  8.56it/s, distance=43.6] 31%|███       | 31/100 [00:03<00:07,  9.23it/s, distance=42.1] 33%|███▎      | 33/100 [00:04<00:09,  6.82it/s, distance=39]   35%|███▌      | 35/100 [00:04<00:08,  7.77it/s, distance=38.1] 37%|███▋      | 37/100 [00:04<00:07,  8.58it/s, distance=37.1] 39%|███▉      | 39/100 [00:04<00:06,  9.25it/s, distance=36.1] 41%|████      | 41/100 [00:05<00:08,  6.84it/s, distance=35]   43%|████▎     | 43/100 [00:05<00:07,  7.79it/s, distance=34.2] 45%|████▌     | 45/100 [00:05<00:06,  8.59it/s, distance=33.3] 47%|████▋     | 47/100 [00:05<00:05,  9.26it/s, distance=32.8] 49%|████▉     | 49/100 [00:06<00:07,  6.83it/s, distance=32]   51%|█████     | 51/100 [00:06<00:06,  7.78it/s, distance=31.4] 53%|█████▎    | 53/100 [00:06<00:05,  8.59it/s, distance=30.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.25it/s, distance=30.4] 57%|█████▋    | 57/100 [00:07<00:06,  6.81it/s, distance=29.8] 59%|█████▉    | 59/100 [00:07<00:05,  7.75it/s, distance=29.4] 61%|██████    | 61/100 [00:07<00:04,  8.56it/s, distance=29.1] 63%|██████▎   | 63/100 [00:07<00:04,  9.23it/s, distance=28.5] 65%|██████▌   | 65/100 [00:08<00:05,  6.75it/s, distance=28.1] 67%|██████▋   | 67/100 [00:08<00:04,  7.70it/s, distance=27.8] 69%|██████▉   | 69/100 [00:08<00:03,  8.51it/s, distance=27.3] 71%|███████   | 71/100 [00:08<00:03,  9.20it/s, distance=26.9] 73%|███████▎  | 73/100 [00:09<00:03,  6.80it/s, distance=26.7] 75%|███████▌  | 75/100 [00:09<00:03,  7.75it/s, distance=26.3] 77%|███████▋  | 77/100 [00:09<00:02,  8.56it/s, distance=25.9] 79%|███████▉  | 79/100 [00:09<00:02,  9.22it/s, distance=25.6] 81%|████████  | 81/100 [00:10<00:02,  6.78it/s, distance=25.2] 83%|████████▎ | 83/100 [00:10<00:02,  7.73it/s, distance=24.9] 85%|████████▌ | 85/100 [00:10<00:01,  8.54it/s, distance=24.5] 87%|████████▋ | 87/100 [00:10<00:01,  9.22it/s, distance=24.1] 89%|████████▉ | 89/100 [00:11<00:01,  6.77it/s, distance=23.6] 91%|█████████ | 91/100 [00:11<00:01,  7.73it/s, distance=23.1] 93%|█████████▎| 93/100 [00:11<00:00,  8.53it/s, distance=22.5] 95%|█████████▌| 95/100 [00:11<00:00,  9.20it/s, distance=21.8] 97%|█████████▋| 97/100 [00:12<00:00,  9.75it/s, distance=20.7] 99%|█████████▉| 99/100 [00:12<00:00, 10.16it/s, distance=18.6]100%|██████████| 100/100 [00:12<00:00,  8.09it/s, distance=15.6]
2025-06-18 20:37:31,402 [MPGD] >> Inference for image 32
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -1.9375e+00, -5.1200e+08, -1.8203e+00, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7283, -1.6966, -1.8482, -1.7465, -1.6841, -1.8145, -1.7491, -1.7680],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13543273 0.25537133 0.01231971 0.09410915 0.32809828 0.02417604
 0.0892812  0.06121157]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2265, -1.3894, -1.3291, -1.2589, -1.3613, -1.4289, -1.2971, -1.3296],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.46596678 0.01793974 0.05992463 0.24359303 0.03146267 0.00813988
 0.11368996 0.0592833 ]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0179, -0.9623, -0.9181, -0.9881, -1.0896, -1.0435, -0.9727, -0.9490],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0487967  0.14828582 0.35938426 0.08848227 0.01162871 0.02925505
 0.12053589 0.19363129]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8297, -0.8677, -0.9465, -0.7892, -0.8300, -0.8405, -0.8389, -0.8873],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14805666 0.06920938 0.01430972 0.33246356 0.14707297 0.11908163
 0.12309458 0.04671149]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7160, -0.6302, -0.7408, -0.6633, -0.6726, -0.6787, -0.7650, -0.8244],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06663254 0.37029986 0.04058546 0.19102554 0.15845248 0.14042644
 0.02496405 0.00761363]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6596, -0.7378, -0.5666, -0.6562, -0.6772, -0.6430, -0.8005, -0.5237],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03846745 0.00803863 0.24715692 0.04117857 0.0270464  0.05354419
 0.00229366 0.58227418]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5223, -0.6984, -0.7469, -0.7132, -0.8241, -0.7566, -0.7239, -0.5003],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.37819981 0.01116728 0.0042283  0.00830245 0.00090387 0.00348832
 0.00669744 0.58701253]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6292, -0.6380, -0.7300, -0.6273, -0.6080, -0.7147, -0.4226, -0.4601],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01036583 0.00869862 0.00138244 0.01077209 0.01583625 0.00187443
 0.64604379 0.30502657]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3839, -0.4107, -0.4307, -0.4121, -0.4216, -0.3762, -0.4329, -0.5047],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.21508113 0.1258798  0.08448463 0.12241969 0.10127085 0.25092501
 0.08073134 0.01920755]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3817, -0.3995, -0.3915, -0.3620, -0.3839, -0.3690, -0.3929, -0.3790],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12340348 0.08641597 0.10134185 0.18307088 0.11797606 0.15909868
 0.09862437 0.1300687 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3337, -0.3752, -0.3408, -0.3588, -0.3913, -0.3635, -0.3843, -0.3764],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.21891904 0.09546148 0.19010445 0.13256301 0.06920569 0.12081229
 0.07968567 0.09324837]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.931
key: ssim
value: 0.837
key: lpips
value: 0.095
key: facenet_l2
value: 0.281
key: adaface_l2
value: 0.451
ref_face_img: tensor([[[[0.7255, 0.7333, 0.7333,  ..., 0.8745, 0.8667, 0.8588],
          [0.7333, 0.7333, 0.7333,  ..., 0.8745, 0.8667, 0.8588],
          [0.7333, 0.7333, 0.7412,  ..., 0.8745, 0.8667, 0.8588],
          ...,
          [0.4745, 0.5059, 0.5373,  ..., 0.6157, 0.6157, 0.6078],
          [0.4667, 0.5059, 0.5373,  ..., 0.6078, 0.6078, 0.6078],
          [0.4745, 0.5059, 0.5373,  ..., 0.6078, 0.6078, 0.6078]],

         [[0.7647, 0.7647, 0.7647,  ..., 0.8510, 0.8431, 0.8275],
          [0.7725, 0.7725, 0.7725,  ..., 0.8510, 0.8353, 0.8275],
          [0.7804, 0.7804, 0.7882,  ..., 0.8510, 0.8353, 0.8275],
          ...,
          [0.3569, 0.3961, 0.4275,  ..., 0.5451, 0.5529, 0.5451],
          [0.3490, 0.3961, 0.4275,  ..., 0.5451, 0.5451, 0.5373],
          [0.3490, 0.3882, 0.4275,  ..., 0.5373, 0.5451, 0.5373]],

         [[0.8353, 0.8275, 0.8353,  ..., 0.9137, 0.9059, 0.8902],
          [0.8431, 0.8431, 0.8431,  ..., 0.9137, 0.9059, 0.8902],
          [0.8510, 0.8510, 0.8588,  ..., 0.9137, 0.8980, 0.8902],
          ...,
          [0.2941, 0.3412, 0.3882,  ..., 0.5137, 0.5216, 0.5059],
          [0.2863, 0.3412, 0.3804,  ..., 0.5059, 0.5137, 0.5059],
          [0.2941, 0.3412, 0.3804,  ..., 0.5059, 0.5137, 0.4980]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.95it/s, distance=273]  3%|▎         | 3/100 [00:00<00:14,  6.56it/s, distance=160]  5%|▌         | 5/100 [00:00<00:11,  8.37it/s, distance=137]  7%|▋         | 7/100 [00:00<00:09,  9.40it/s, distance=130]  9%|▉         | 9/100 [00:01<00:14,  6.40it/s, distance=97.4] 11%|█         | 11/100 [00:01<00:11,  7.58it/s, distance=91.3] 13%|█▎        | 13/100 [00:01<00:10,  8.50it/s, distance=79.7] 15%|█▌        | 15/100 [00:01<00:09,  9.24it/s, distance=70.4] 17%|█▋        | 17/100 [00:02<00:12,  6.67it/s, distance=67.3] 19%|█▉        | 19/100 [00:02<00:10,  7.67it/s, distance=61.4] 21%|██        | 21/100 [00:02<00:09,  8.51it/s, distance=56.6] 23%|██▎       | 23/100 [00:02<00:08,  9.20it/s, distance=51.5] 25%|██▌       | 25/100 [00:03<00:11,  6.75it/s, distance=45]   27%|██▋       | 27/100 [00:03<00:09,  7.71it/s, distance=42.2] 29%|██▉       | 29/100 [00:03<00:08,  8.53it/s, distance=41]   31%|███       | 31/100 [00:03<00:07,  9.20it/s, distance=39.2] 33%|███▎      | 33/100 [00:04<00:09,  6.75it/s, distance=38.6] 35%|███▌      | 35/100 [00:04<00:08,  7.70it/s, distance=35.8] 37%|███▋      | 37/100 [00:04<00:07,  8.52it/s, distance=34.8] 39%|███▉      | 39/100 [00:04<00:06,  9.19it/s, distance=33.8] 41%|████      | 41/100 [00:05<00:08,  6.72it/s, distance=32.4] 43%|████▎     | 43/100 [00:05<00:07,  7.68it/s, distance=31.8] 45%|████▌     | 45/100 [00:05<00:06,  8.48it/s, distance=31.2] 47%|████▋     | 47/100 [00:05<00:05,  9.17it/s, distance=30.7] 49%|████▉     | 49/100 [00:06<00:07,  6.73it/s, distance=30]   51%|█████     | 51/100 [00:06<00:06,  7.68it/s, distance=29.5] 53%|█████▎    | 53/100 [00:06<00:05,  8.49it/s, distance=29.1] 55%|█████▌    | 55/100 [00:06<00:04,  9.18it/s, distance=28.6] 57%|█████▋    | 57/100 [00:07<00:06,  6.68it/s, distance=28.3] 59%|█████▉    | 59/100 [00:07<00:05,  7.63it/s, distance=27.8] 61%|██████    | 61/100 [00:07<00:04,  8.45it/s, distance=27.5] 63%|██████▎   | 63/100 [00:07<00:04,  9.15it/s, distance=27]   65%|██████▌   | 65/100 [00:08<00:05,  6.65it/s, distance=26.8] 67%|██████▋   | 67/100 [00:08<00:04,  7.61it/s, distance=26.6] 69%|██████▉   | 69/100 [00:08<00:03,  8.42it/s, distance=26.2] 71%|███████   | 71/100 [00:08<00:03,  9.11it/s, distance=25.9] 73%|███████▎  | 73/100 [00:09<00:04,  6.61it/s, distance=25.5] 75%|███████▌  | 75/100 [00:09<00:03,  7.57it/s, distance=25.2] 77%|███████▋  | 77/100 [00:09<00:02,  8.41it/s, distance=24.9] 79%|███████▉  | 79/100 [00:09<00:02,  9.11it/s, distance=24.6] 81%|████████  | 81/100 [00:10<00:02,  6.61it/s, distance=24.2] 83%|████████▎ | 83/100 [00:10<00:02,  7.58it/s, distance=23.9] 85%|████████▌ | 85/100 [00:10<00:01,  8.41it/s, distance=23.5] 87%|████████▋ | 87/100 [00:11<00:01,  9.10it/s, distance=23.2] 89%|████████▉ | 89/100 [00:11<00:01,  6.62it/s, distance=22.8] 91%|█████████ | 91/100 [00:11<00:01,  7.59it/s, distance=22.3] 93%|█████████▎| 93/100 [00:11<00:00,  8.42it/s, distance=21.8] 95%|█████████▌| 95/100 [00:12<00:00,  9.11it/s, distance=21.1] 97%|█████████▋| 97/100 [00:12<00:00,  9.66it/s, distance=20.1] 99%|█████████▉| 99/100 [00:12<00:00, 10.10it/s, distance=18.1]100%|██████████| 100/100 [00:12<00:00,  8.01it/s, distance=14.9]
2025-06-18 20:37:45,153 [MPGD] >> Inference for image 33
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -2.0263e+00, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -2.0888e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6702, -1.7720, -1.9820, -2.0252, -2.0558, -1.9345, -1.7802, -1.7769],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [7.30760160e-01 9.55131348e-02 1.43123572e-03 6.02911838e-04
 3.27329237e-04 3.70035534e-03 8.10605155e-02 8.66043578e-02]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5970, -1.6609, -1.6187, -1.5259, -1.6015, -1.6324, -1.7242, -1.5383],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09267769 0.0257845  0.05998975 0.38417901 0.08466847 0.04568035
 0.00727753 0.2997427 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4229, -1.4951, -1.3806, -1.3335, -1.3430, -1.4642, -1.4658, -1.3421],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04904164 0.01157461 0.11435836 0.293232   0.24258732 0.02149187
 0.02080895 0.24690524]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1600, -1.2073, -1.1729, -1.2539, -1.2163, -1.1369, -1.1997, -1.1655],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17938903 0.06965602 0.13853104 0.02743063 0.05822302 0.28502114
 0.08101629 0.16073285]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1305, -1.0742, -1.3250, -1.2248, -1.1642, -1.1043, -1.0260, -1.2819],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06859544 0.21149032 0.00140176 0.0104101  0.03497118 0.11575392
 0.55405369 0.00332359]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2582, -1.0416, -1.1113, -1.0559, -1.1266, -1.0110, -1.0593, -1.0855],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00254942 0.19408238 0.0481315  0.14563245 0.03541085 0.35740693
 0.13620478 0.08058169]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9681, -0.9963, -0.9901, -1.0208, -0.9660, -1.0164, -1.0161, -1.0184],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.21105381 0.12016202 0.13606038 0.07364802 0.2204009  0.080455
 0.0809464  0.07727346]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9402, -0.9682, -0.9932, -0.9811, -0.9474, -0.9737, -0.9882, -0.9647],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.21133157 0.1207184  0.07328887 0.09324146 0.1829109  0.10814892
 0.08092086 0.12943902]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9323, -0.8821, -0.9444, -0.9652, -0.9348, -0.9629, -0.9227, -0.9559],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11952615 0.32637282 0.09394334 0.06192568 0.11386445 0.06482352
 0.14494009 0.07460395]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9466, -0.9347, -0.9103, -0.9312, -0.9195, -0.9527, -0.9152, -0.9307],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08653755 0.10983053 0.17910943 0.11774552 0.14885759 0.07664022
 0.16226967 0.1190095 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9211, -0.8962, -0.8823, -0.9129, -0.8919, -0.8987, -0.9484, -0.8990],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0870794  0.14310209 0.18912111 0.10253483 0.15606644 0.13619612
 0.05046616 0.13543386]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 27.636
key: ssim
value: 0.835
key: lpips
value: 0.103
key: facenet_l2
value: 0.642
key: adaface_l2
value: 0.841
ref_face_img: tensor([[[[ 0.3882,  0.3882,  0.3882,  ...,  0.7882,  0.7804,  0.7725],
          [ 0.3882,  0.3882,  0.3882,  ...,  0.7961,  0.7882,  0.7882],
          [ 0.3804,  0.3882,  0.3882,  ...,  0.8039,  0.8039,  0.7882],
          ...,
          [ 0.7020,  0.7020,  0.7020,  ..., -0.5451, -0.5765, -0.5765],
          [ 0.7020,  0.7020,  0.7020,  ..., -0.5529, -0.5608, -0.5765],
          [ 0.7020,  0.7020,  0.7020,  ..., -0.5529, -0.5608, -0.5765]],

         [[ 0.3490,  0.3490,  0.3490,  ...,  0.4353,  0.4431,  0.4431],
          [ 0.3412,  0.3412,  0.3490,  ...,  0.4431,  0.4431,  0.4431],
          [ 0.3412,  0.3412,  0.3412,  ...,  0.4510,  0.4510,  0.4431],
          ...,
          [ 0.6863,  0.6863,  0.6863,  ..., -0.6627, -0.6941, -0.7020],
          [ 0.6863,  0.6863,  0.6863,  ..., -0.6784, -0.6863, -0.6941],
          [ 0.6863,  0.6863,  0.6863,  ..., -0.6863, -0.6863, -0.7020]],

         [[ 0.2784,  0.2784,  0.2863,  ...,  0.2627,  0.2627,  0.2706],
          [ 0.2784,  0.2784,  0.2784,  ...,  0.2706,  0.2706,  0.2706],
          [ 0.2784,  0.2784,  0.2784,  ...,  0.2784,  0.2784,  0.2706],
          ...,
          [ 0.6549,  0.6549,  0.6549,  ..., -0.6863, -0.7255, -0.7255],
          [ 0.6549,  0.6549,  0.6549,  ..., -0.7020, -0.7098, -0.7255],
          [ 0.6549,  0.6549,  0.6549,  ..., -0.7098, -0.7098, -0.7333]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:32,  3.01it/s, distance=354]  3%|▎         | 3/100 [00:00<00:14,  6.64it/s, distance=160]  5%|▌         | 5/100 [00:00<00:11,  8.44it/s, distance=110]  7%|▋         | 7/100 [00:00<00:09,  9.46it/s, distance=102]  9%|▉         | 9/100 [00:01<00:14,  6.41it/s, distance=88.1] 11%|█         | 11/100 [00:01<00:11,  7.58it/s, distance=77.8] 13%|█▎        | 13/100 [00:01<00:10,  8.51it/s, distance=76.7] 15%|█▌        | 15/100 [00:01<00:09,  9.24it/s, distance=72.3] 17%|█▋        | 17/100 [00:02<00:12,  6.71it/s, distance=61.2] 19%|█▉        | 19/100 [00:02<00:10,  7.70it/s, distance=56.4] 21%|██        | 21/100 [00:02<00:09,  8.53it/s, distance=53.3] 23%|██▎       | 23/100 [00:02<00:08,  9.22it/s, distance=49.3] 25%|██▌       | 25/100 [00:03<00:11,  6.79it/s, distance=43]   27%|██▋       | 27/100 [00:03<00:09,  7.75it/s, distance=41.6] 29%|██▉       | 29/100 [00:03<00:08,  8.56it/s, distance=39]   31%|███       | 31/100 [00:03<00:07,  9.23it/s, distance=37.8] 33%|███▎      | 33/100 [00:04<00:09,  6.80it/s, distance=35.6] 35%|███▌      | 35/100 [00:04<00:08,  7.74it/s, distance=35.3] 37%|███▋      | 37/100 [00:04<00:07,  8.56it/s, distance=34.7] 39%|███▉      | 39/100 [00:04<00:06,  9.23it/s, distance=33.6] 41%|████      | 41/100 [00:05<00:08,  6.72it/s, distance=32.9] 43%|████▎     | 43/100 [00:05<00:07,  7.66it/s, distance=32.1] 45%|████▌     | 45/100 [00:05<00:06,  8.48it/s, distance=31.3] 47%|████▋     | 47/100 [00:05<00:05,  9.17it/s, distance=30.9] 49%|████▉     | 49/100 [00:06<00:07,  6.72it/s, distance=30.8] 51%|█████     | 51/100 [00:06<00:06,  7.67it/s, distance=29.8] 53%|█████▎    | 53/100 [00:06<00:05,  8.49it/s, distance=29.4] 55%|█████▌    | 55/100 [00:06<00:04,  9.17it/s, distance=28.8] 57%|█████▋    | 57/100 [00:07<00:06,  6.71it/s, distance=28.3] 59%|█████▉    | 59/100 [00:07<00:05,  7.66it/s, distance=28]   61%|██████    | 61/100 [00:07<00:04,  8.48it/s, distance=27.7] 63%|██████▎   | 63/100 [00:07<00:04,  9.17it/s, distance=27.4] 65%|██████▌   | 65/100 [00:08<00:05,  6.68it/s, distance=26.9] 67%|██████▋   | 67/100 [00:08<00:04,  7.64it/s, distance=26.6] 69%|██████▉   | 69/100 [00:08<00:03,  8.46it/s, distance=26.4] 71%|███████   | 71/100 [00:08<00:03,  9.16it/s, distance=26]   73%|███████▎  | 73/100 [00:09<00:04,  6.66it/s, distance=25.8] 75%|███████▌  | 75/100 [00:09<00:03,  7.62it/s, distance=25.4] 77%|███████▋  | 77/100 [00:09<00:02,  8.45it/s, distance=25.1] 79%|███████▉  | 79/100 [00:09<00:02,  9.14it/s, distance=24.8] 81%|████████  | 81/100 [00:10<00:02,  6.66it/s, distance=24.4] 83%|████████▎ | 83/100 [00:10<00:02,  7.61it/s, distance=24.1] 85%|████████▌ | 85/100 [00:10<00:01,  8.44it/s, distance=23.7] 87%|████████▋ | 87/100 [00:10<00:01,  9.14it/s, distance=23.3] 89%|████████▉ | 89/100 [00:11<00:01,  6.66it/s, distance=22.9] 91%|█████████ | 91/100 [00:11<00:01,  7.62it/s, distance=22.4] 93%|█████████▎| 93/100 [00:11<00:00,  8.45it/s, distance=21.9] 95%|█████████▌| 95/100 [00:11<00:00,  9.15it/s, distance=21.2] 97%|█████████▋| 97/100 [00:12<00:00,  9.71it/s, distance=20.2] 99%|█████████▉| 99/100 [00:12<00:00, 10.12it/s, distance=18.2]100%|██████████| 100/100 [00:12<00:00,  8.04it/s, distance=15.1]
2025-06-18 20:37:58,891 [MPGD] >> Inference for image 34
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.0051e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9168, -1.7457, -1.8409, -1.9331, -2.0713, -1.8736, -1.8782, -1.8046],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01963465 0.60133985 0.0896307  0.014165   0.00089329 0.04658048
 0.04245214 0.18530389]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6263, -1.6313, -1.6701, -1.6141, -1.7137, -1.6981, -1.6063, -1.6096],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14480557 0.1311005  0.06035741 0.18512605 0.02522929 0.03450729
 0.21632905 0.20254486]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3786, -1.5677, -1.4224, -1.4759, -1.4907, -1.5643, -1.3328, -1.4994],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.23227288 0.00529364 0.0969014  0.03319774 0.02471446 0.0056703
 0.58119858 0.020751  ]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1463, -1.2509, -1.2296, -1.3687, -1.2838, -1.2221, -1.1440, -1.1512],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.28104863 0.03463656 0.05308635 0.0032884  0.01794024 0.06165188
 0.29382258 0.25452536]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0248, -0.9243, -0.9693, -0.9735, -1.1754, -1.0695, -1.0268, -0.9571],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05111009 0.38120476 0.15502209 0.14236849 0.0025143  0.02090211
 0.04908007 0.1977981 ]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8870, -0.8532, -0.8430, -0.9555, -0.8339, -0.9331, -0.8680, -1.0178],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09565738 0.1879372  0.23055533 0.02429137 0.27678339 0.03803713
 0.13975246 0.00698574]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7936, -0.8555, -0.7873, -0.8015, -0.8635, -0.7710, -0.7960, -0.8426],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15561769 0.04509129 0.1766709  0.13276457 0.03842444 0.24467577
 0.14839688 0.05835847]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7481, -0.7089, -0.8123, -0.7672, -0.7594, -0.7838, -0.7579, -0.8026],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15159179 0.33211574 0.04203206 0.10340083 0.12102262 0.07426043
 0.12458382 0.05099271]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7426, -0.7318, -0.7246, -0.7214, -0.7110, -0.6892, -0.8178, -0.7294],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08688504 0.10780239 0.12442464 0.13258113 0.16332574 0.25254605
 0.01930294 0.11313206]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7077, -0.7185, -0.6627, -0.7301, -0.6989, -0.7065, -0.7087, -0.6614],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09411532 0.07591199 0.23142597 0.06013973 0.11224012 0.09636629
 0.09226174 0.23753884]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7064, -0.6479, -0.6764, -0.6703, -0.6728, -0.7246, -0.6848, -0.7304],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07746165 0.2493914  0.14109027 0.15935379 0.15157117 0.05379114
 0.11938252 0.04795806]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 23.240
key: ssim
value: 0.826
key: lpips
value: 0.166
key: facenet_l2
value: 0.389
key: adaface_l2
value: 0.526
ref_face_img: tensor([[[[-0.9451, -0.9451, -0.9451,  ..., -0.6784, -0.6784, -0.6863],
          [-0.9451, -0.9451, -0.9451,  ..., -0.6863, -0.6863, -0.6863],
          [-0.9451, -0.9451, -0.9451,  ..., -0.6863, -0.6863, -0.6863],
          ...,
          [-0.9451, -0.9451, -0.9451,  ..., -0.8039, -0.8039, -0.8039],
          [-0.9451, -0.9451, -0.9451,  ..., -0.7961, -0.7961, -0.7961],
          [-0.9451, -0.9451, -0.9451,  ..., -0.7961, -0.7961, -0.7961]],

         [[-0.9529, -0.9529, -0.9529,  ..., -0.7020, -0.7020, -0.7098],
          [-0.9529, -0.9529, -0.9529,  ..., -0.7098, -0.7098, -0.7098],
          [-0.9529, -0.9529, -0.9529,  ..., -0.7098, -0.7098, -0.7098],
          ...,
          [-0.9451, -0.9451, -0.9451,  ..., -0.9294, -0.9294, -0.9294],
          [-0.9451, -0.9451, -0.9451,  ..., -0.9216, -0.9216, -0.9216],
          [-0.9451, -0.9451, -0.9451,  ..., -0.9216, -0.9216, -0.9216]],

         [[-0.9137, -0.9137, -0.9137,  ..., -0.7412, -0.7412, -0.7490],
          [-0.9137, -0.9137, -0.9137,  ..., -0.7490, -0.7490, -0.7490],
          [-0.9137, -0.9137, -0.9137,  ..., -0.7490, -0.7490, -0.7490],
          ...,
          [-0.9451, -0.9451, -0.9451,  ..., -0.9294, -0.9294, -0.9294],
          [-0.9451, -0.9451, -0.9451,  ..., -0.9216, -0.9216, -0.9216],
          [-0.9451, -0.9451, -0.9451,  ..., -0.9216, -0.9216, -0.9216]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.85it/s, distance=255]  3%|▎         | 3/100 [00:00<00:15,  6.44it/s, distance=168]  5%|▌         | 5/100 [00:00<00:11,  8.26it/s, distance=145]  7%|▋         | 7/100 [00:00<00:09,  9.33it/s, distance=125]  9%|▉         | 9/100 [00:01<00:14,  6.48it/s, distance=122] 11%|█         | 11/100 [00:01<00:11,  7.65it/s, distance=102] 13%|█▎        | 13/100 [00:01<00:10,  8.57it/s, distance=85.3] 15%|█▌        | 15/100 [00:01<00:09,  9.29it/s, distance=81.6] 17%|█▋        | 17/100 [00:02<00:12,  6.86it/s, distance=69.6] 19%|█▉        | 19/100 [00:02<00:10,  7.83it/s, distance=64.3] 21%|██        | 21/100 [00:02<00:09,  8.64it/s, distance=58.1] 23%|██▎       | 23/100 [00:02<00:08,  9.32it/s, distance=55.4] 25%|██▌       | 25/100 [00:03<00:10,  6.90it/s, distance=55]   27%|██▋       | 27/100 [00:03<00:09,  7.84it/s, distance=51.3] 29%|██▉       | 29/100 [00:03<00:08,  8.64it/s, distance=48.3] 31%|███       | 31/100 [00:03<00:07,  9.30it/s, distance=47.2] 33%|███▎      | 33/100 [00:04<00:09,  6.94it/s, distance=44.5] 35%|███▌      | 35/100 [00:04<00:08,  7.88it/s, distance=41.7] 37%|███▋      | 37/100 [00:04<00:07,  8.67it/s, distance=39.8] 39%|███▉      | 39/100 [00:04<00:06,  9.31it/s, distance=37.7] 41%|████      | 41/100 [00:05<00:08,  6.93it/s, distance=36]   43%|████▎     | 43/100 [00:05<00:07,  7.87it/s, distance=35.3] 45%|████▌     | 45/100 [00:05<00:06,  8.66it/s, distance=34.6] 47%|████▋     | 47/100 [00:05<00:05,  9.31it/s, distance=33.6] 49%|████▉     | 49/100 [00:06<00:07,  6.94it/s, distance=32.6] 51%|█████     | 51/100 [00:06<00:06,  7.87it/s, distance=32.3] 53%|█████▎    | 53/100 [00:06<00:05,  8.65it/s, distance=31.6] 55%|█████▌    | 55/100 [00:06<00:04,  9.29it/s, distance=30.9] 57%|█████▋    | 57/100 [00:07<00:06,  6.93it/s, distance=30.2] 59%|█████▉    | 59/100 [00:07<00:05,  7.86it/s, distance=29.8] 61%|██████    | 61/100 [00:07<00:04,  8.65it/s, distance=29.5] 63%|██████▎   | 63/100 [00:07<00:03,  9.30it/s, distance=29]   65%|██████▌   | 65/100 [00:08<00:05,  6.96it/s, distance=28.5] 67%|██████▋   | 67/100 [00:08<00:04,  7.89it/s, distance=28.2] 69%|██████▉   | 69/100 [00:08<00:03,  8.68it/s, distance=27.9] 71%|███████   | 71/100 [00:08<00:03,  9.32it/s, distance=27.4] 73%|███████▎  | 73/100 [00:09<00:03,  6.97it/s, distance=27]   75%|███████▌  | 75/100 [00:09<00:03,  7.91it/s, distance=26.6] 77%|███████▋  | 77/100 [00:09<00:02,  8.69it/s, distance=26.2] 79%|███████▉  | 79/100 [00:09<00:02,  9.33it/s, distance=25.8] 81%|████████  | 81/100 [00:10<00:02,  6.94it/s, distance=25.4] 83%|████████▎ | 83/100 [00:10<00:02,  7.87it/s, distance=25]   85%|████████▌ | 85/100 [00:10<00:01,  8.66it/s, distance=24.6] 87%|████████▋ | 87/100 [00:10<00:01,  9.30it/s, distance=24.2] 89%|████████▉ | 89/100 [00:11<00:01,  6.95it/s, distance=23.7] 91%|█████████ | 91/100 [00:11<00:01,  7.87it/s, distance=23.2] 93%|█████████▎| 93/100 [00:11<00:00,  8.66it/s, distance=22.6] 95%|█████████▌| 95/100 [00:11<00:00,  9.32it/s, distance=21.8] 97%|█████████▋| 97/100 [00:11<00:00,  9.82it/s, distance=20.7] 99%|█████████▉| 99/100 [00:12<00:00, 10.21it/s, distance=18.6]100%|██████████| 100/100 [00:12<00:00,  8.20it/s, distance=15.5]
2025-06-18 20:38:12,151 [MPGD] >> Inference for image 35
reward_name: adaface, curr_reward: tensor([-2.0453e+00, -5.1200e+08, -2.0653e+00, -2.1487e+00, -2.0440e+00,
        -2.1043e+00, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0124, -1.9393, -1.7980, -1.9824, -2.0189, -2.0252, -1.9242, -1.7374],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00301288 0.01298345 0.21915398 0.00548481 0.00264625 0.0023306
 0.0175651  0.73682294]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1451, -1.3122, -1.3007, -1.1400, -1.3193, -1.2067, -1.2913, -1.0929],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.18495259 0.00654939 0.00823457 0.20492533 0.00568042 0.05400287
 0.00995116 0.52570367]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1189, -1.0308, -1.1093, -1.0463, -1.1494, -1.0174, -1.0394, -1.0271],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03160923 0.18412283 0.03830173 0.13504092 0.01716497 0.24056079
 0.15498769 0.19821184]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0261, -0.9546, -0.9473, -0.8792, -1.1116, -1.0804, -1.0809, -0.9860],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03127987 0.13070234 0.15137239 0.59028984 0.00565124 0.01055915
 0.01046175 0.06968342]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9220, -0.7843, -0.9359, -0.9146, -0.9224, -0.9535, -0.7837, -0.7617],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0164702  0.25849494 0.01248314 0.01911524 0.0163513  0.0087749
 0.26179953 0.40651075]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7207, -0.6439, -0.6085, -0.7115, -0.6215, -0.6653, -0.7190, -0.6942],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03409085 0.15861135 0.32170694 0.04096957 0.24798014 0.10333693
 0.03530313 0.05800109]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5536, -0.6023, -0.6054, -0.5745, -0.5817, -0.7122, -0.6080, -0.6677],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.29072327 0.10969    0.10302873 0.1913738  0.1655104  0.01218891
 0.0978585  0.02962638]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5217, -0.6462, -0.6426, -0.5737, -0.6341, -0.5779, -0.6643, -0.5844],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.43508719 0.03608775 0.03875282 0.15360977 0.04591905 0.14137855
 0.02511348 0.12405138]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4812, -0.5618, -0.5174, -0.5848, -0.5875, -0.5894, -0.5292, -0.5391],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.36477964 0.07272226 0.17680396 0.04595744 0.04350536 0.04192482
 0.13968948 0.11461705]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5231, -0.5204, -0.5047, -0.4868, -0.5883, -0.5383, -0.5132, -0.4958],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10509336 0.11086025 0.15165341 0.21721494 0.028517   0.07748658
 0.12804632 0.18112813]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4659, -0.4982, -0.4708, -0.4756, -0.4915, -0.4673, -0.4921, -0.4628],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15427392 0.08078378 0.13975001 0.1271453  0.09243    0.15001704
 0.09136001 0.16423993]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.209
key: ssim
value: 0.838
key: lpips
value: 0.139
key: facenet_l2
value: 0.369
key: adaface_l2
value: 0.516
ref_face_img: tensor([[[[ 0.0039,  0.0039,  0.0039,  ...,  0.0118,  0.0118,  0.0118],
          [ 0.0039,  0.0039,  0.0039,  ...,  0.0118,  0.0118,  0.0118],
          [ 0.0039,  0.0039,  0.0039,  ...,  0.0196,  0.0196,  0.0196],
          ...,
          [-0.5294, -0.5373, -0.5373,  ..., -0.4118, -0.4196, -0.4118],
          [-0.5294, -0.5373, -0.5373,  ..., -0.4196, -0.4196, -0.4196],
          [-0.5373, -0.5373, -0.5373,  ..., -0.4196, -0.4196, -0.4196]],

         [[ 0.1294,  0.1294,  0.1294,  ...,  0.0667,  0.0667,  0.0588],
          [ 0.1294,  0.1294,  0.1294,  ...,  0.0667,  0.0667,  0.0667],
          [ 0.1294,  0.1294,  0.1294,  ...,  0.0745,  0.0667,  0.0667],
          ...,
          [-0.5529, -0.5529, -0.5529,  ..., -0.4431, -0.4431, -0.4431],
          [-0.5529, -0.5529, -0.5529,  ..., -0.4431, -0.4431, -0.4431],
          [-0.5529, -0.5529, -0.5529,  ..., -0.4431, -0.4431, -0.4431]],

         [[ 0.2941,  0.2941,  0.2941,  ...,  0.1608,  0.1608,  0.1608],
          [ 0.2941,  0.2941,  0.2941,  ...,  0.1686,  0.1608,  0.1608],
          [ 0.2941,  0.3020,  0.3020,  ...,  0.1686,  0.1686,  0.1608],
          ...,
          [-0.5686, -0.5608, -0.5608,  ..., -0.4667, -0.4667, -0.4667],
          [-0.5686, -0.5686, -0.5608,  ..., -0.4667, -0.4667, -0.4667],
          [-0.5686, -0.5686, -0.5686,  ..., -0.4667, -0.4667, -0.4667]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.98it/s, distance=292]  3%|▎         | 3/100 [00:00<00:14,  6.61it/s, distance=153]  5%|▌         | 5/100 [00:00<00:11,  8.40it/s, distance=137]  7%|▋         | 7/100 [00:00<00:09,  9.43it/s, distance=118]  9%|▉         | 9/100 [00:01<00:13,  6.52it/s, distance=93.8] 11%|█         | 11/100 [00:01<00:11,  7.68it/s, distance=84]  13%|█▎        | 13/100 [00:01<00:10,  8.60it/s, distance=75.2] 15%|█▌        | 15/100 [00:01<00:09,  9.32it/s, distance=70.9] 17%|█▋        | 17/100 [00:02<00:12,  6.84it/s, distance=63.7] 19%|█▉        | 19/100 [00:02<00:10,  7.82it/s, distance=59.5] 21%|██        | 21/100 [00:02<00:09,  8.64it/s, distance=53.1] 23%|██▎       | 23/100 [00:02<00:08,  9.31it/s, distance=51]   25%|██▌       | 25/100 [00:03<00:10,  6.96it/s, distance=48.7] 27%|██▋       | 27/100 [00:03<00:09,  7.91it/s, distance=45.4] 29%|██▉       | 29/100 [00:03<00:08,  8.69it/s, distance=43.7] 31%|███       | 31/100 [00:03<00:07,  9.34it/s, distance=41.8] 33%|███▎      | 33/100 [00:04<00:09,  6.96it/s, distance=40.3] 35%|███▌      | 35/100 [00:04<00:08,  7.90it/s, distance=39.9] 37%|███▋      | 37/100 [00:04<00:07,  8.69it/s, distance=38.6] 39%|███▉      | 39/100 [00:04<00:06,  9.34it/s, distance=37.5] 41%|████      | 41/100 [00:05<00:08,  6.96it/s, distance=36.5] 43%|████▎     | 43/100 [00:05<00:07,  7.89it/s, distance=35.7] 45%|████▌     | 45/100 [00:05<00:06,  8.68it/s, distance=35.2] 47%|████▋     | 47/100 [00:05<00:05,  9.32it/s, distance=34.6] 49%|████▉     | 49/100 [00:06<00:07,  6.99it/s, distance=33.7] 51%|█████     | 51/100 [00:06<00:06,  7.92it/s, distance=33.3] 53%|█████▎    | 53/100 [00:06<00:05,  8.70it/s, distance=32.7] 55%|█████▌    | 55/100 [00:06<00:04,  9.35it/s, distance=32.1] 57%|█████▋    | 57/100 [00:07<00:06,  6.99it/s, distance=32]   59%|█████▉    | 59/100 [00:07<00:05,  7.92it/s, distance=31.3] 61%|██████    | 61/100 [00:07<00:04,  8.71it/s, distance=30.8] 63%|██████▎   | 63/100 [00:07<00:03,  9.34it/s, distance=30.3] 65%|██████▌   | 65/100 [00:08<00:05,  6.96it/s, distance=29.8] 67%|██████▋   | 67/100 [00:08<00:04,  7.89it/s, distance=29.5] 69%|██████▉   | 69/100 [00:08<00:03,  8.67it/s, distance=29.2] 71%|███████   | 71/100 [00:08<00:03,  9.32it/s, distance=28.8] 73%|███████▎  | 73/100 [00:09<00:03,  6.96it/s, distance=28.3] 75%|███████▌  | 75/100 [00:09<00:03,  7.89it/s, distance=27.9] 77%|███████▋  | 77/100 [00:09<00:02,  8.66it/s, distance=27.6] 79%|███████▉  | 79/100 [00:09<00:02,  9.31it/s, distance=27.2] 81%|████████  | 81/100 [00:10<00:02,  6.96it/s, distance=26.8] 83%|████████▎ | 83/100 [00:10<00:02,  7.88it/s, distance=26.4] 85%|████████▌ | 85/100 [00:10<00:01,  8.67it/s, distance=25.9] 87%|████████▋ | 87/100 [00:10<00:01,  9.32it/s, distance=25.5] 89%|████████▉ | 89/100 [00:11<00:01,  6.96it/s, distance=24.9] 91%|█████████ | 91/100 [00:11<00:01,  7.90it/s, distance=24.3] 93%|█████████▎| 93/100 [00:11<00:00,  8.68it/s, distance=23.6] 95%|█████████▌| 95/100 [00:11<00:00,  9.32it/s, distance=22.8] 97%|█████████▋| 97/100 [00:11<00:00,  9.85it/s, distance=21.6] 99%|█████████▉| 99/100 [00:12<00:00, 10.24it/s, distance=19.4]100%|██████████| 100/100 [00:12<00:00,  8.23it/s, distance=16.3]
2025-06-18 20:38:25,418 [MPGD] >> Inference for image 36
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.0181e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -1.9955e+00, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9600, -1.7665, -1.9438, -1.9071, -1.9279, -1.9151, -1.8926, -2.1390],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [1.62623046e-02 7.80452157e-01 2.24861321e-02 4.69022123e-02
 3.08852655e-02 3.99161837e-02 6.26419926e-02 4.53752206e-04]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3056, -1.3264, -1.1997, -1.3246, -1.3435, -1.2948, -1.3542, -1.2695],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06761153 0.04460232 0.56143817 0.04623676 0.03165805 0.08380588
 0.02556859 0.13907871]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9858, -0.9630, -0.9656, -0.9968, -1.0741, -0.9612, -0.9871, -0.8789],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06200831 0.09774404 0.0928284  0.049729   0.0106037  0.10128877
 0.06043376 0.52536402]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7526, -0.7322, -0.7206, -0.7171, -0.6055, -0.7232, -0.7128, -0.6988],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03092694 0.04656    0.05862949 0.0629881  0.58587336 0.05571056
 0.0685825  0.09072905]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5513, -0.5553, -0.5550, -0.6055, -0.5630, -0.5936, -0.5940, -0.5921],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.18936236 0.17487934 0.17582521 0.06404952 0.15004459 0.08138034
 0.08070917 0.08374946]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4806, -0.5705, -0.5755, -0.5518, -0.5216, -0.5457, -0.5002, -0.5806],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.32507468 0.05374707 0.04862952 0.07811284 0.14293697 0.08828472
 0.21930278 0.04391143]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5532, -0.4781, -0.5042, -0.5227, -0.4830, -0.4792, -0.4781, -0.5393],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04121157 0.18512637 0.10974694 0.07582419 0.16779546 0.18102067
 0.18488994 0.05438486]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5265, -0.4813, -0.5292, -0.4814, -0.4549, -0.4577, -0.4878, -0.5409],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05574373 0.13760583 0.05281475 0.13736753 0.23332815 0.22055073
 0.12079411 0.04179515]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4354, -0.4845, -0.4966, -0.4152, -0.4856, -0.5213, -0.4761, -0.4405],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.19758138 0.07408301 0.05808774 0.29607517 0.07238019 0.03546705
 0.08763878 0.17868668]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4364, -0.4071, -0.4666, -0.4136, -0.4482, -0.4645, -0.3870, -0.4636],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1046543  0.18804465 0.05729487 0.16513679 0.0827977  0.05972501
 0.28159569 0.06075099]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4452, -0.4245, -0.3983, -0.4143, -0.4353, -0.3988, -0.4007, -0.4044],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06511222 0.09850586 0.16627574 0.12070339 0.0793414  0.16467164
 0.15834221 0.14704754]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.437
key: ssim
value: 0.842
key: lpips
value: 0.104
key: facenet_l2
value: 0.292
key: adaface_l2
value: 0.495
ref_face_img: tensor([[[[ 0.6157,  0.6157,  0.6157,  ..., -0.1922, -0.1373, -0.1137],
          [ 0.6157,  0.6157,  0.6157,  ..., -0.1843, -0.1373, -0.1137],
          [ 0.6157,  0.6157,  0.6157,  ..., -0.1843, -0.1294, -0.1059],
          ...,
          [ 0.6000,  0.6000,  0.6000,  ..., -0.7725, -0.7725, -0.7725],
          [ 0.6000,  0.6000,  0.6000,  ..., -0.7725, -0.7725, -0.7725],
          [ 0.5922,  0.5922,  0.5922,  ..., -0.7725, -0.7725, -0.7725]],

         [[ 0.6471,  0.6471,  0.6471,  ..., -0.0824, -0.0353, -0.0118],
          [ 0.6471,  0.6471,  0.6471,  ..., -0.0824, -0.0353, -0.0118],
          [ 0.6471,  0.6471,  0.6471,  ..., -0.0824, -0.0353, -0.0118],
          ...,
          [ 0.6235,  0.6235,  0.6235,  ..., -0.7647, -0.7647, -0.7647],
          [ 0.6235,  0.6235,  0.6235,  ..., -0.7647, -0.7647, -0.7647],
          [ 0.6157,  0.6157,  0.6157,  ..., -0.7647, -0.7647, -0.7647]],

         [[ 0.7020,  0.7020,  0.7020,  ...,  0.1216,  0.1608,  0.1686],
          [ 0.7020,  0.7020,  0.7020,  ...,  0.1216,  0.1608,  0.1765],
          [ 0.7020,  0.7020,  0.7098,  ...,  0.1216,  0.1608,  0.1765],
          ...,
          [ 0.6627,  0.6627,  0.6627,  ..., -0.7333, -0.7333, -0.7333],
          [ 0.6627,  0.6627,  0.6627,  ..., -0.7255, -0.7255, -0.7255],
          [ 0.6549,  0.6549,  0.6549,  ..., -0.7255, -0.7255, -0.7255]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.87it/s, distance=254]  3%|▎         | 3/100 [00:00<00:14,  6.47it/s, distance=166]  5%|▌         | 5/100 [00:00<00:11,  8.29it/s, distance=136]  7%|▋         | 7/100 [00:00<00:09,  9.35it/s, distance=119]  9%|▉         | 9/100 [00:01<00:14,  6.50it/s, distance=112] 11%|█         | 11/100 [00:01<00:11,  7.66it/s, distance=91.8] 13%|█▎        | 13/100 [00:01<00:10,  8.58it/s, distance=80.2] 15%|█▌        | 15/100 [00:01<00:09,  9.31it/s, distance=74.4] 17%|█▋        | 17/100 [00:02<00:12,  6.78it/s, distance=67.8] 19%|█▉        | 19/100 [00:02<00:10,  7.78it/s, distance=65.2] 21%|██        | 21/100 [00:02<00:09,  8.60it/s, distance=62]   23%|██▎       | 23/100 [00:02<00:08,  9.27it/s, distance=55.5] 25%|██▌       | 25/100 [00:03<00:10,  6.86it/s, distance=52.2] 27%|██▋       | 27/100 [00:03<00:09,  7.81it/s, distance=50.9] 29%|██▉       | 29/100 [00:03<00:08,  8.61it/s, distance=49]   31%|███       | 31/100 [00:03<00:07,  9.27it/s, distance=42.8] 33%|███▎      | 33/100 [00:04<00:09,  6.84it/s, distance=39.2] 35%|███▌      | 35/100 [00:04<00:08,  7.78it/s, distance=38.2] 37%|███▋      | 37/100 [00:04<00:07,  8.58it/s, distance=37.6] 39%|███▉      | 39/100 [00:04<00:06,  9.25it/s, distance=35.7] 41%|████      | 41/100 [00:05<00:08,  6.84it/s, distance=34.3] 43%|████▎     | 43/100 [00:05<00:07,  7.78it/s, distance=33.3] 45%|████▌     | 45/100 [00:05<00:06,  8.58it/s, distance=32.4] 47%|████▋     | 47/100 [00:05<00:05,  9.24it/s, distance=31.5] 49%|████▉     | 49/100 [00:06<00:07,  6.85it/s, distance=30.6] 51%|█████     | 51/100 [00:06<00:06,  7.80it/s, distance=30.2] 53%|█████▎    | 53/100 [00:06<00:05,  8.60it/s, distance=29.5] 55%|█████▌    | 55/100 [00:06<00:04,  9.26it/s, distance=29.1] 57%|█████▋    | 57/100 [00:07<00:06,  6.86it/s, distance=28.3] 59%|█████▉    | 59/100 [00:07<00:05,  7.80it/s, distance=28]   61%|██████    | 61/100 [00:07<00:04,  8.60it/s, distance=27.7] 63%|██████▎   | 63/100 [00:07<00:03,  9.26it/s, distance=27.3] 65%|██████▌   | 65/100 [00:08<00:05,  6.86it/s, distance=27.1] 67%|██████▋   | 67/100 [00:08<00:04,  7.80it/s, distance=26.6] 69%|██████▉   | 69/100 [00:08<00:03,  8.60it/s, distance=26.3] 71%|███████   | 71/100 [00:08<00:03,  9.26it/s, distance=25.9] 73%|███████▎  | 73/100 [00:09<00:03,  6.86it/s, distance=25.6] 75%|███████▌  | 75/100 [00:09<00:03,  7.79it/s, distance=25.3] 77%|███████▋  | 77/100 [00:09<00:02,  8.60it/s, distance=24.9] 79%|███████▉  | 79/100 [00:09<00:02,  9.26it/s, distance=24.6] 81%|████████  | 81/100 [00:10<00:02,  6.84it/s, distance=24.2] 83%|████████▎ | 83/100 [00:10<00:02,  7.78it/s, distance=23.9] 85%|████████▌ | 85/100 [00:10<00:01,  8.57it/s, distance=23.5] 87%|████████▋ | 87/100 [00:10<00:01,  9.24it/s, distance=23.1] 89%|████████▉ | 89/100 [00:11<00:01,  6.85it/s, distance=22.7] 91%|█████████ | 91/100 [00:11<00:01,  7.79it/s, distance=22.2] 93%|█████████▎| 93/100 [00:11<00:00,  8.58it/s, distance=21.7] 95%|█████████▌| 95/100 [00:11<00:00,  9.25it/s, distance=21]   97%|█████████▋| 97/100 [00:12<00:00,  9.78it/s, distance=20] 99%|█████████▉| 99/100 [00:12<00:00, 10.18it/s, distance=18.1]100%|██████████| 100/100 [00:12<00:00,  8.14it/s, distance=15] 
2025-06-18 20:38:38,974 [MPGD] >> Inference for image 37
reward_name: adaface, curr_reward: tensor([-2.0345e+00, -2.0125e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -2.0049e+00, -5.1200e+08, -2.1362e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8420, -1.8553, -1.9374, -1.9376, -2.0743, -1.9826, -2.1869, -2.0222],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.46299622 0.35470316 0.06861283 0.06834508 0.004447   0.02782352
 0.00046709 0.01260509]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8438, -1.8122, -1.7438, -1.8082, -1.7146, -1.5950, -1.7224, -1.7397],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00527147 0.00992053 0.0389108  0.01074114 0.06981577 0.76329106
 0.05978298 0.04226625]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5631, -1.3583, -1.4493, -1.4443, -1.2697, -1.4734, -1.3138, -1.4047],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00163725 0.09838298 0.01593911 0.01760926 0.57823716 0.00984276
 0.23946906 0.03888242]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2489, -1.2339, -1.1811, -1.0197, -1.2087, -1.1478, -1.3183, -0.9747],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00281517 0.00379924 0.01092462 0.27555564 0.00629698 0.02127343
 0.00070323 0.67863168]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9868, -0.7904, -0.8829, -0.8954, -0.9059, -1.1581, -0.8998, -0.8891],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [1.19215634e-02 6.05930076e-01 9.52814854e-02 7.41824868e-02
 6.01635502e-02 3.87757289e-04 6.79381818e-02 8.41948991e-02]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8012, -0.7418, -0.7007, -0.7372, -0.8069, -0.7922, -0.7103, -0.8245],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04130182 0.13545022 0.30833156 0.14844264 0.03687895 0.04942045
 0.2542681  0.02590626]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6789, -0.8916, -0.6867, -0.7470, -0.7330, -0.7168, -0.8458, -0.7450],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.3090198  0.00439019 0.2645784  0.07919495 0.10466847 0.14487268
 0.01098017 0.08229534]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6607, -0.6349, -0.6940, -0.6447, -0.6065, -0.7525, -0.7056, -0.6766],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1134189  0.18995548 0.05824533 0.15609487 0.335502   0.01807385
 0.04617092 0.08253864]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7062, -0.6982, -0.7069, -0.5551, -0.5717, -0.5748, -0.5262, -0.6088],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01043635 0.01224642 0.01028497 0.21402794 0.15365165 0.14444528
 0.38175745 0.07314994]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5166, -0.5452, -0.5093, -0.5204, -0.5371, -0.5037, -0.5437, -0.4930],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12841583 0.07250432 0.14843595 0.11906548 0.08514551 0.16614425
 0.07465944 0.20562923]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4638, -0.4783, -0.5122, -0.4913, -0.4871, -0.5254, -0.4884, -0.4950],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.20950542 0.1567566  0.07970462 0.12092563 0.131522   0.06117634
 0.12808447 0.11232493]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 31.209
key: ssim
value: 0.825
key: lpips
value: 0.152
key: facenet_l2
value: 0.357
key: adaface_l2
value: 0.553
ref_face_img: tensor([[[[-0.6784, -0.6784, -0.6784,  ...,  0.4824,  0.4745,  0.4588],
          [-0.6784, -0.6784, -0.6784,  ...,  0.4588,  0.4431,  0.4353],
          [-0.6784, -0.6784, -0.6784,  ...,  0.4275,  0.4118,  0.4039],
          ...,
          [ 0.0588,  0.0588,  0.0510,  ..., -0.7333, -0.7412, -0.7412],
          [ 0.0588,  0.0588,  0.0510,  ..., -0.7333, -0.7333, -0.7333],
          [ 0.0431,  0.0431,  0.0431,  ..., -0.7333, -0.7333, -0.7333]],

         [[-0.6471, -0.6471, -0.6471,  ...,  0.5137,  0.4980,  0.4902],
          [-0.6471, -0.6471, -0.6471,  ...,  0.4824,  0.4745,  0.4667],
          [-0.6471, -0.6471, -0.6471,  ...,  0.4588,  0.4431,  0.4353],
          ...,
          [ 0.1294,  0.1294,  0.1216,  ..., -0.7020, -0.7098, -0.7098],
          [ 0.1294,  0.1294,  0.1216,  ..., -0.7020, -0.7020, -0.7020],
          [ 0.1137,  0.1137,  0.1137,  ..., -0.7020, -0.7020, -0.7020]],

         [[-0.6314, -0.6314, -0.6392,  ...,  0.5373,  0.5216,  0.5137],
          [-0.6314, -0.6314, -0.6314,  ...,  0.5059,  0.4980,  0.4902],
          [-0.6314, -0.6314, -0.6314,  ...,  0.4745,  0.4745,  0.4510],
          ...,
          [ 0.1529,  0.1451,  0.1451,  ..., -0.7020, -0.7020, -0.7020],
          [ 0.1529,  0.1451,  0.1451,  ..., -0.7020, -0.7020, -0.7020],
          [ 0.1373,  0.1373,  0.1294,  ..., -0.7020, -0.7020, -0.7020]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.96it/s, distance=295]  3%|▎         | 3/100 [00:00<00:14,  6.56it/s, distance=172]  5%|▌         | 5/100 [00:00<00:11,  8.37it/s, distance=139]  7%|▋         | 7/100 [00:00<00:09,  9.39it/s, distance=116]  9%|▉         | 9/100 [00:01<00:13,  6.50it/s, distance=115] 11%|█         | 11/100 [00:01<00:11,  7.66it/s, distance=102] 13%|█▎        | 13/100 [00:01<00:10,  8.59it/s, distance=86.7] 15%|█▌        | 15/100 [00:01<00:09,  9.30it/s, distance=76.6] 17%|█▋        | 17/100 [00:02<00:12,  6.75it/s, distance=60.7] 19%|█▉        | 19/100 [00:02<00:10,  7.74it/s, distance=57.7] 21%|██        | 21/100 [00:02<00:09,  8.57it/s, distance=55.2] 23%|██▎       | 23/100 [00:02<00:08,  9.26it/s, distance=52]   25%|██▌       | 25/100 [00:03<00:11,  6.80it/s, distance=51.2] 27%|██▋       | 27/100 [00:03<00:09,  7.75it/s, distance=49.4] 29%|██▉       | 29/100 [00:03<00:08,  8.56it/s, distance=45.7] 31%|███       | 31/100 [00:03<00:07,  9.22it/s, distance=41.9] 33%|███▎      | 33/100 [00:04<00:09,  6.83it/s, distance=37.6] 35%|███▌      | 35/100 [00:04<00:08,  7.77it/s, distance=37.1] 37%|███▋      | 37/100 [00:04<00:07,  8.57it/s, distance=35.4] 39%|███▉      | 39/100 [00:04<00:06,  9.23it/s, distance=34.5] 41%|████      | 41/100 [00:05<00:08,  6.78it/s, distance=33.2] 43%|████▎     | 43/100 [00:05<00:07,  7.73it/s, distance=32.6] 45%|████▌     | 45/100 [00:05<00:06,  8.54it/s, distance=31.6] 47%|████▋     | 47/100 [00:05<00:05,  9.21it/s, distance=30.9] 49%|████▉     | 49/100 [00:06<00:07,  6.77it/s, distance=30.3] 51%|█████     | 51/100 [00:06<00:06,  7.72it/s, distance=29.7] 53%|█████▎    | 53/100 [00:06<00:05,  8.52it/s, distance=29.1] 55%|█████▌    | 55/100 [00:06<00:04,  9.20it/s, distance=28.7] 57%|█████▋    | 57/100 [00:07<00:06,  6.77it/s, distance=28]   59%|█████▉    | 59/100 [00:07<00:05,  7.73it/s, distance=27.6] 61%|██████    | 61/100 [00:07<00:04,  8.54it/s, distance=27.3] 63%|██████▎   | 63/100 [00:07<00:04,  9.21it/s, distance=26.9] 65%|██████▌   | 65/100 [00:08<00:05,  6.76it/s, distance=26.6] 67%|██████▋   | 67/100 [00:08<00:04,  7.71it/s, distance=26.2] 69%|██████▉   | 69/100 [00:08<00:03,  8.53it/s, distance=25.9] 71%|███████   | 71/100 [00:08<00:03,  9.20it/s, distance=25.5] 73%|███████▎  | 73/100 [00:09<00:03,  6.76it/s, distance=25.3] 75%|███████▌  | 75/100 [00:09<00:03,  7.72it/s, distance=25]   77%|███████▋  | 77/100 [00:09<00:02,  8.53it/s, distance=24.7] 79%|███████▉  | 79/100 [00:09<00:02,  9.19it/s, distance=24.3] 81%|████████  | 81/100 [00:10<00:02,  6.78it/s, distance=24]   83%|████████▎ | 83/100 [00:10<00:02,  7.73it/s, distance=23.6] 85%|████████▌ | 85/100 [00:10<00:01,  8.54it/s, distance=23.3] 87%|████████▋ | 87/100 [00:10<00:01,  9.21it/s, distance=22.9] 89%|████████▉ | 89/100 [00:11<00:01,  6.77it/s, distance=22.6] 91%|█████████ | 91/100 [00:11<00:01,  7.72it/s, distance=22.1] 93%|█████████▎| 93/100 [00:11<00:00,  8.53it/s, distance=21.5] 95%|█████████▌| 95/100 [00:11<00:00,  9.20it/s, distance=20.8] 97%|█████████▋| 97/100 [00:12<00:00,  9.75it/s, distance=19.8] 99%|█████████▉| 99/100 [00:12<00:00, 10.16it/s, distance=17.9]100%|██████████| 100/100 [00:12<00:00,  8.10it/s, distance=14.8]
2025-06-18 20:38:52,547 [MPGD] >> Inference for image 38
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08, -2.0941e+00,
        -5.1200e+08, -5.1200e+08, -2.0170e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9679, -2.0551, -1.9126, -1.9264, -2.0244, -1.8977, -1.7654, -1.9647],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01442652 0.0025195  0.04360369 0.03306148 0.00465958 0.05869584
 0.82767214 0.01536125]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6350, -1.4949, -1.5306, -1.4894, -1.4672, -1.7742, -1.5407, -1.4970],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01052247 0.17325254 0.08496961 0.19355146 0.30153902 0.00065067
 0.0694153  0.16609893]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3199, -1.2175, -1.2526, -1.3825, -1.2946, -1.2731, -1.3002, -1.1950],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03253299 0.25246053 0.12512045 0.00930443 0.05401485 0.08300166
 0.04828432 0.39528078]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3376, -1.1478, -1.1575, -1.3631, -1.2136, -1.1935, -1.1812, -1.1959],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00656105 0.29223949 0.24075099 0.00393643 0.07831003 0.11700906
 0.14963504 0.1115579 ]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0430, -1.0519, -0.9548, -1.0855, -1.0036, -1.0351, -0.9738, -1.0590],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0617518  0.05171026 0.36070982 0.02639143 0.13583226 0.07236025
 0.24640107 0.04484311]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8599, -0.8508, -0.8354, -0.8939, -0.9217, -0.9165, -0.8674, -0.9433],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16678866 0.20002273 0.27185913 0.08445309 0.04845413 0.05367069
 0.14334925 0.03140232]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8559, -0.7451, -0.7555, -0.7526, -0.8723, -0.8036, -0.7328, -0.8377],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02368492 0.21694258 0.1762233  0.18690283 0.01706571 0.06736457
 0.27774965 0.03406643]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7302, -0.7768, -0.7451, -0.6932, -0.6546, -0.7116, -0.6643, -0.6958],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06276138 0.02468636 0.04661411 0.13141122 0.28444318 0.09093015
 0.23422691 0.1249267 ]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6700, -0.6133, -0.6276, -0.6075, -0.6719, -0.6364, -0.6693, -0.6796],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0681206  0.21143536 0.15892136 0.23756791 0.06550001 0.13322483
 0.06899597 0.05623396]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6353, -0.5628, -0.5696, -0.5298, -0.6022, -0.6595, -0.5773, -0.5925],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03944233 0.16812727 0.14701429 0.32572941 0.07654822 0.0243352
 0.12594    0.09286327]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5155, -0.5238, -0.5154, -0.5140, -0.5276, -0.5237, -0.5240, -0.4998],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12951228 0.10959688 0.12978229 0.13345495 0.10154255 0.1098247
 0.10919196 0.17709439]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.566
key: ssim
value: 0.825
key: lpips
value: 0.155
key: facenet_l2
value: 0.473
key: adaface_l2
value: 0.624
ref_face_img: tensor([[[[0.5216, 0.5216, 0.5216,  ..., 0.4824, 0.4824, 0.4902],
          [0.5216, 0.5216, 0.5216,  ..., 0.4824, 0.4902, 0.4902],
          [0.5216, 0.5137, 0.5137,  ..., 0.4824, 0.4902, 0.4902],
          ...,
          [0.3569, 0.3725, 0.3804,  ..., 0.4902, 0.4902, 0.4902],
          [0.3490, 0.3647, 0.3804,  ..., 0.4902, 0.4902, 0.4902],
          [0.3569, 0.3647, 0.3804,  ..., 0.4902, 0.4902, 0.4902]],

         [[0.4745, 0.4745, 0.4745,  ..., 0.3804, 0.3882, 0.3882],
          [0.4745, 0.4745, 0.4745,  ..., 0.3804, 0.3882, 0.3882],
          [0.4745, 0.4745, 0.4745,  ..., 0.3804, 0.3882, 0.3961],
          ...,
          [0.1451, 0.1686, 0.1843,  ..., 0.3961, 0.3961, 0.3961],
          [0.1373, 0.1608, 0.1765,  ..., 0.3961, 0.3961, 0.3961],
          [0.1373, 0.1529, 0.1765,  ..., 0.3961, 0.3961, 0.3961]],

         [[0.4824, 0.4824, 0.4824,  ..., 0.3725, 0.3804, 0.3882],
          [0.4824, 0.4824, 0.4824,  ..., 0.3725, 0.3804, 0.3882],
          [0.4824, 0.4824, 0.4824,  ..., 0.3725, 0.3804, 0.3882],
          ...,
          [0.1294, 0.1529, 0.1686,  ..., 0.3961, 0.3961, 0.3961],
          [0.1294, 0.1451, 0.1608,  ..., 0.3961, 0.3961, 0.3961],
          [0.1294, 0.1373, 0.1608,  ..., 0.3961, 0.3961, 0.3961]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.87it/s, distance=302]  3%|▎         | 3/100 [00:00<00:15,  6.44it/s, distance=143]  5%|▌         | 5/100 [00:00<00:11,  8.26it/s, distance=125]  7%|▋         | 7/100 [00:00<00:09,  9.32it/s, distance=114]  9%|▉         | 9/100 [00:01<00:13,  6.55it/s, distance=105] 11%|█         | 11/100 [00:01<00:11,  7.71it/s, distance=88.9] 13%|█▎        | 13/100 [00:01<00:10,  8.62it/s, distance=73.2] 15%|█▌        | 15/100 [00:01<00:09,  9.34it/s, distance=67.2] 17%|█▋        | 17/100 [00:02<00:12,  6.88it/s, distance=61.3] 19%|█▉        | 19/100 [00:02<00:10,  7.85it/s, distance=54.2] 21%|██        | 21/100 [00:02<00:09,  8.67it/s, distance=50.6] 23%|██▎       | 23/100 [00:02<00:08,  9.33it/s, distance=47.6] 25%|██▌       | 25/100 [00:03<00:10,  6.93it/s, distance=46.1] 27%|██▋       | 27/100 [00:03<00:09,  7.88it/s, distance=45.2] 29%|██▉       | 29/100 [00:03<00:08,  8.66it/s, distance=44]   31%|███       | 31/100 [00:03<00:07,  9.30it/s, distance=41.5] 33%|███▎      | 33/100 [00:04<00:09,  6.95it/s, distance=45.1] 35%|███▌      | 35/100 [00:04<00:08,  7.89it/s, distance=41.1] 37%|███▋      | 37/100 [00:04<00:07,  8.66it/s, distance=39]   39%|███▉      | 39/100 [00:04<00:06,  9.31it/s, distance=38] 41%|████      | 41/100 [00:05<00:08,  6.95it/s, distance=36.5] 43%|████▎     | 43/100 [00:05<00:07,  7.88it/s, distance=36]   45%|████▌     | 45/100 [00:05<00:06,  8.66it/s, distance=35.3] 47%|████▋     | 47/100 [00:05<00:05,  9.32it/s, distance=34.4] 49%|████▉     | 49/100 [00:06<00:07,  6.98it/s, distance=33.9] 51%|█████     | 51/100 [00:06<00:06,  7.91it/s, distance=33.2] 53%|█████▎    | 53/100 [00:06<00:05,  8.68it/s, distance=32.7] 55%|█████▌    | 55/100 [00:06<00:04,  9.33it/s, distance=32.1] 57%|█████▋    | 57/100 [00:07<00:06,  6.95it/s, distance=31.2] 59%|█████▉    | 59/100 [00:07<00:05,  7.88it/s, distance=30.9] 61%|██████    | 61/100 [00:07<00:04,  8.67it/s, distance=30.5] 63%|██████▎   | 63/100 [00:07<00:03,  9.32it/s, distance=30.1] 65%|██████▌   | 65/100 [00:08<00:05,  6.96it/s, distance=29.7] 67%|██████▋   | 67/100 [00:08<00:04,  7.89it/s, distance=29.3] 69%|██████▉   | 69/100 [00:08<00:03,  8.68it/s, distance=28.9] 71%|███████   | 71/100 [00:08<00:03,  9.32it/s, distance=28.5] 73%|███████▎  | 73/100 [00:09<00:03,  6.96it/s, distance=28.3] 75%|███████▌  | 75/100 [00:09<00:03,  7.89it/s, distance=27.8] 77%|███████▋  | 77/100 [00:09<00:02,  8.67it/s, distance=27.4] 79%|███████▉  | 79/100 [00:09<00:02,  9.32it/s, distance=27]   81%|████████  | 81/100 [00:10<00:02,  6.98it/s, distance=26.5] 83%|████████▎ | 83/100 [00:10<00:02,  7.91it/s, distance=26.2] 85%|████████▌ | 85/100 [00:10<00:01,  8.69it/s, distance=25.8] 87%|████████▋ | 87/100 [00:10<00:01,  9.33it/s, distance=25.3] 89%|████████▉ | 89/100 [00:11<00:01,  7.00it/s, distance=24.8] 91%|█████████ | 91/100 [00:11<00:01,  7.92it/s, distance=24.3] 93%|█████████▎| 93/100 [00:11<00:00,  8.70it/s, distance=23.6] 95%|█████████▌| 95/100 [00:11<00:00,  9.34it/s, distance=22.7] 97%|█████████▋| 97/100 [00:11<00:00,  9.84it/s, distance=21.6] 99%|█████████▉| 99/100 [00:12<00:00, 10.23it/s, distance=19.4]100%|██████████| 100/100 [00:12<00:00,  8.22it/s, distance=16.4]
2025-06-18 20:39:05,980 [MPGD] >> Inference for image 39
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -2.0578e+00, -5.1200e+08, -5.1200e+08,
        -2.0138e+00, -2.0420e+00, -2.0736e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9250, -1.8101, -1.9562, -2.0178, -1.7531, -1.9289, -1.9901, -1.8538],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0207964  0.20699283 0.01114638 0.00325017 0.64663925 0.01922408
 0.00566064 0.08629025]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4760, -1.5371, -1.4097, -1.5290, -1.4944, -1.4468, -1.5229, -1.5199],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11501901 0.0338378  0.43271329 0.03985596 0.07960879 0.20616554
 0.04499219 0.04780741]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2086, -1.2552, -1.2523, -1.1652, -1.2617, -1.2842, -1.1656, -1.1656],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1055349  0.04149363 0.04397551 0.25099626 0.03648117 0.02324144
 0.24899597 0.24928111]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0946, -1.1389, -1.1715, -1.1259, -1.2363, -1.0497, -1.0714, -1.1609],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1530146  0.06318939 0.03287389 0.08192176 0.00900131 0.37589306
 0.24344053 0.04066546]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0019, -0.9589, -0.9854, -0.9877, -0.7754, -0.8879, -0.7788, -0.9585],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00505527 0.01194933 0.00704289 0.00671536 0.46958329 0.04946899
 0.4381421  0.01204278]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7165, -0.7924, -0.6671, -0.8267, -0.6271, -0.8073, -0.5126, -0.8162],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01442648 0.0031601  0.03868602 0.00159173 0.08612579 0.00234499
 0.85170104 0.00196385]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4530, -0.5079, -0.4931, -0.4634, -0.4843, -0.4621, -0.5289, -0.5545],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.23193221 0.07739362 0.10393982 0.18834127 0.12397562 0.19318089
 0.05079044 0.03044614]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4160, -0.4398, -0.5503, -0.3770, -0.4870, -0.4114, -0.4305, -0.4502],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15471831 0.09621677 0.01054912 0.33755639 0.03740792 0.16959178
 0.11588236 0.07807735]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3692, -0.3354, -0.4094, -0.3736, -0.4173, -0.4007, -0.3727, -0.3507],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13122327 0.25797057 0.05869464 0.120067   0.0501015  0.0698203
 0.12226512 0.1898576 ]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3216, -0.3418, -0.3265, -0.3367, -0.3315, -0.3503, -0.3532, -0.3492],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17233692 0.11494899 0.1561351  0.12741904 0.14126114 0.09697106
 0.09163368 0.09929406]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.3522, -0.3094, -0.3720, -0.3958, -0.3431, -0.3841, -0.3856, -0.3418],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12618289 0.29750345 0.08506243 0.05275138 0.15141532 0.06678618
 0.06478793 0.15551041]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.749
key: ssim
value: 0.844
key: lpips
value: 0.076
key: facenet_l2
value: 0.365
key: adaface_l2
value: 0.417
ref_face_img: tensor([[[[-0.9059, -0.9059, -0.9059,  ..., -0.8275, -0.8431, -0.8824],
          [-0.9137, -0.9059, -0.9059,  ..., -0.8510, -0.8667, -0.8902],
          [-0.9059, -0.9059, -0.9059,  ..., -0.8824, -0.8902, -0.9059],
          ...,
          [-0.8745, -0.8980, -0.9059,  ..., -0.7333, -0.7490, -0.7725],
          [-0.8902, -0.8980, -0.8980,  ..., -0.7098, -0.7098, -0.7176],
          [-0.9294, -0.9294, -0.9137,  ..., -0.6863, -0.6549, -0.6235]],

         [[-0.8902, -0.8902, -0.8902,  ..., -0.8196, -0.8353, -0.8588],
          [-0.8980, -0.8902, -0.8902,  ..., -0.8431, -0.8588, -0.8745],
          [-0.8902, -0.8902, -0.8902,  ..., -0.8510, -0.8588, -0.8745],
          ...,
          [-0.8588, -0.8824, -0.8902,  ..., -0.7647, -0.7961, -0.8039],
          [-0.8745, -0.8824, -0.8824,  ..., -0.7647, -0.7804, -0.7725],
          [-0.9137, -0.9137, -0.8980,  ..., -0.7569, -0.7333, -0.6941]],

         [[-0.9294, -0.9294, -0.9294,  ..., -0.8667, -0.8824, -0.9137],
          [-0.9373, -0.9294, -0.9294,  ..., -0.8902, -0.9059, -0.9216],
          [-0.9294, -0.9294, -0.9373,  ..., -0.9216, -0.9216, -0.9373],
          ...,
          [-0.8980, -0.9216, -0.9294,  ..., -0.8431, -0.8667, -0.8275],
          [-0.9137, -0.9216, -0.9216,  ..., -0.8353, -0.8588, -0.8275],
          [-0.9529, -0.9529, -0.9373,  ..., -0.8196, -0.8196, -0.7882]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.92it/s, distance=246]  3%|▎         | 3/100 [00:00<00:14,  6.51it/s, distance=155]  5%|▌         | 5/100 [00:00<00:11,  8.32it/s, distance=139]  7%|▋         | 7/100 [00:00<00:09,  9.36it/s, distance=119]  9%|▉         | 9/100 [00:01<00:13,  6.53it/s, distance=112] 11%|█         | 11/100 [00:01<00:11,  7.69it/s, distance=92.1] 13%|█▎        | 13/100 [00:01<00:10,  8.61it/s, distance=86]   15%|█▌        | 15/100 [00:01<00:09,  9.32it/s, distance=78.9] 17%|█▋        | 17/100 [00:02<00:12,  6.86it/s, distance=67.8] 19%|█▉        | 19/100 [00:02<00:10,  7.83it/s, distance=60.8] 21%|██        | 21/100 [00:02<00:09,  8.65it/s, distance=57.2] 23%|██▎       | 23/100 [00:02<00:08,  9.31it/s, distance=53.1] 25%|██▌       | 25/100 [00:03<00:10,  6.89it/s, distance=51.6] 27%|██▋       | 27/100 [00:03<00:09,  7.83it/s, distance=49.3] 29%|██▉       | 29/100 [00:03<00:08,  8.63it/s, distance=49.3] 31%|███       | 31/100 [00:03<00:07,  9.29it/s, distance=47]   33%|███▎      | 33/100 [00:04<00:09,  6.94it/s, distance=44.1] 35%|███▌      | 35/100 [00:04<00:08,  7.88it/s, distance=43.5] 37%|███▋      | 37/100 [00:04<00:07,  8.66it/s, distance=43.6] 39%|███▉      | 39/100 [00:04<00:06,  9.30it/s, distance=41.9] 41%|████      | 41/100 [00:05<00:08,  6.96it/s, distance=43.9] 43%|████▎     | 43/100 [00:05<00:07,  7.89it/s, distance=42.8] 45%|████▌     | 45/100 [00:05<00:06,  8.67it/s, distance=38.7] 47%|████▋     | 47/100 [00:05<00:05,  9.32it/s, distance=38.3] 49%|████▉     | 49/100 [00:06<00:07,  6.96it/s, distance=36.8] 51%|█████     | 51/100 [00:06<00:06,  7.88it/s, distance=34.9] 53%|█████▎    | 53/100 [00:06<00:05,  8.67it/s, distance=33.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.31it/s, distance=33.3] 57%|█████▋    | 57/100 [00:07<00:06,  6.95it/s, distance=32.8] 59%|█████▉    | 59/100 [00:07<00:05,  7.87it/s, distance=32.1] 61%|██████    | 61/100 [00:07<00:04,  8.66it/s, distance=31.6] 63%|██████▎   | 63/100 [00:07<00:03,  9.31it/s, distance=30.9] 65%|██████▌   | 65/100 [00:08<00:05,  6.92it/s, distance=30.3] 67%|██████▋   | 67/100 [00:08<00:04,  7.85it/s, distance=29.9] 69%|██████▉   | 69/100 [00:08<00:03,  8.64it/s, distance=29.3] 71%|███████   | 71/100 [00:08<00:03,  9.28it/s, distance=28.8] 73%|███████▎  | 73/100 [00:09<00:03,  6.91it/s, distance=28.5] 75%|███████▌  | 75/100 [00:09<00:03,  7.84it/s, distance=28.1] 77%|███████▋  | 77/100 [00:09<00:02,  8.63it/s, distance=27.6] 79%|███████▉  | 79/100 [00:09<00:02,  9.28it/s, distance=27.2] 81%|████████  | 81/100 [00:10<00:02,  6.92it/s, distance=26.7] 83%|████████▎ | 83/100 [00:10<00:02,  7.86it/s, distance=26.3] 85%|████████▌ | 85/100 [00:10<00:01,  8.64it/s, distance=25.8] 87%|████████▋ | 87/100 [00:10<00:01,  9.29it/s, distance=25.3] 89%|████████▉ | 89/100 [00:11<00:01,  6.89it/s, distance=24.8] 91%|█████████ | 91/100 [00:11<00:01,  7.82it/s, distance=24.2] 93%|█████████▎| 93/100 [00:11<00:00,  8.62it/s, distance=23.5] 95%|█████████▌| 95/100 [00:11<00:00,  9.26it/s, distance=22.6] 97%|█████████▋| 97/100 [00:11<00:00,  9.78it/s, distance=21.4] 99%|█████████▉| 99/100 [00:12<00:00, 10.19it/s, distance=19.2]100%|██████████| 100/100 [00:12<00:00,  8.20it/s, distance=16.1]
2025-06-18 20:39:19,245 [MPGD] >> Inference for image 40
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -1.9927e+00, -5.1200e+08, -2.0991e+00, -5.1200e+08,
        -2.1811e+00, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8527, -1.9393, -1.9356, -1.9053, -1.8926, -1.8710, -1.8996, -1.9250],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.28691174 0.05069519 0.05456709 0.10016024 0.12904209 0.19889369
 0.11220365 0.06752632]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5718, -1.3627, -1.3774, -1.5513, -1.4253, -1.5955, -1.5275, -1.4707],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0068454  0.44825642 0.33397901 0.01030948 0.12806314 0.00426283
 0.0166     0.05168372]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3825, -1.4455, -1.3212, -1.3254, -1.2167, -1.2630, -1.2508, -1.3196],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0157037  0.00445156 0.05347327 0.04918729 0.43212641 0.17133092
 0.21847193 0.05525492]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2613, -1.1756, -1.0909, -1.1283, -1.1225, -1.1605, -1.1304, -1.2471],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01115707 0.06195703 0.33716809 0.15941502 0.17898148 0.08365177
 0.1528477  0.01482183]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9011, -0.9307, -0.8836, -0.8946, -0.9188, -0.9093, -0.9166, -0.8452],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10571184 0.05852369 0.15019042 0.12041392 0.07420461 0.08980364
 0.07754382 0.32360805]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7388, -0.7756, -0.7569, -0.8200, -0.7674, -0.7405, -0.7038, -0.7866],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15854052 0.07600778 0.11058027 0.03125585 0.0895227  0.15350534
 0.31963244 0.0609551 ]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7516, -0.7905, -0.7306, -0.6848, -0.7819, -0.7266, -0.7537, -0.7715],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09428031 0.04327921 0.14348511 0.35832028 0.05147369 0.1555394
 0.09031661 0.06330538]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6353, -0.5804, -0.5681, -0.6768, -0.6507, -0.6843, -0.6138, -0.6145],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08044778 0.24107082 0.30863528 0.03506295 0.05911977 0.03019005
 0.12361542 0.12185793]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5779, -0.5740, -0.5923, -0.6128, -0.5809, -0.5831, -0.5651, -0.5542],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12387494 0.13402109 0.09290335 0.06169003 0.11670619 0.11157677
 0.16019398 0.19903366]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5396, -0.5292, -0.5517, -0.5320, -0.5499, -0.5348, -0.5660, -0.5348],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12840749 0.15803856 0.10078357 0.14952113 0.10456348 0.14152937
 0.07576027 0.14139614]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5150, -0.5190, -0.4838, -0.5144, -0.5634, -0.5249, -0.5042, -0.5269],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1244722  0.11494846 0.23237189 0.12595663 0.04726715 0.10216856
 0.15463291 0.09818219]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.633
key: ssim
value: 0.836
key: lpips
value: 0.123
key: facenet_l2
value: 0.410
key: adaface_l2
value: 0.646
ref_face_img: tensor([[[[ 0.9686,  0.9686,  0.9686,  ..., -0.5529, -0.5294, -0.4902],
          [ 0.9686,  0.9686,  0.9686,  ..., -0.5529, -0.5294, -0.4902],
          [ 0.9686,  0.9686,  0.9686,  ..., -0.5529, -0.5294, -0.4902],
          ...,
          [ 0.9216,  0.9216,  0.9216,  ..., -0.1843, -0.1765, -0.1686],
          [ 0.9216,  0.9216,  0.9216,  ..., -0.1686, -0.1529, -0.1451],
          [ 0.9216,  0.9216,  0.9216,  ..., -0.1451, -0.1294, -0.1216]],

         [[ 0.9686,  0.9686,  0.9686,  ..., -0.5529, -0.5373, -0.4980],
          [ 0.9686,  0.9686,  0.9686,  ..., -0.5529, -0.5373, -0.4980],
          [ 0.9686,  0.9686,  0.9686,  ..., -0.5529, -0.5294, -0.4980],
          ...,
          [ 0.7490,  0.7490,  0.7490,  ..., -0.3569, -0.3490, -0.3412],
          [ 0.7490,  0.7569,  0.7569,  ..., -0.3412, -0.3333, -0.3333],
          [ 0.7569,  0.7569,  0.7569,  ..., -0.3333, -0.3255, -0.3176]],

         [[ 0.9686,  0.9686,  0.9686,  ..., -0.6235, -0.6000, -0.5765],
          [ 0.9686,  0.9686,  0.9686,  ..., -0.6235, -0.6000, -0.5765],
          [ 0.9686,  0.9686,  0.9686,  ..., -0.6235, -0.6000, -0.5686],
          ...,
          [ 0.6471,  0.6471,  0.6471,  ..., -0.4667, -0.4588, -0.4510],
          [ 0.6549,  0.6549,  0.6549,  ..., -0.4588, -0.4510, -0.4510],
          [ 0.6549,  0.6549,  0.6549,  ..., -0.4510, -0.4510, -0.4431]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.96it/s, distance=388]  3%|▎         | 3/100 [00:00<00:14,  6.58it/s, distance=161]  5%|▌         | 5/100 [00:00<00:11,  8.38it/s, distance=128]  7%|▋         | 7/100 [00:00<00:09,  9.40it/s, distance=100]  9%|▉         | 9/100 [00:01<00:13,  6.56it/s, distance=106] 11%|█         | 11/100 [00:01<00:11,  7.71it/s, distance=91.3] 13%|█▎        | 13/100 [00:01<00:10,  8.62it/s, distance=80.4] 15%|█▌        | 15/100 [00:01<00:09,  9.32it/s, distance=73.7] 17%|█▋        | 17/100 [00:02<00:12,  6.81it/s, distance=66.9] 19%|█▉        | 19/100 [00:02<00:10,  7.79it/s, distance=71.1] 21%|██        | 21/100 [00:02<00:09,  8.61it/s, distance=61.2] 23%|██▎       | 23/100 [00:02<00:08,  9.28it/s, distance=53.6] 25%|██▌       | 25/100 [00:03<00:10,  6.87it/s, distance=54.4] 27%|██▋       | 27/100 [00:03<00:09,  7.81it/s, distance=44.9] 29%|██▉       | 29/100 [00:03<00:08,  8.61it/s, distance=45.4] 31%|███       | 31/100 [00:03<00:07,  9.27it/s, distance=44.4] 33%|███▎      | 33/100 [00:04<00:09,  6.88it/s, distance=41.1] 35%|███▌      | 35/100 [00:04<00:08,  7.82it/s, distance=39.2] 37%|███▋      | 37/100 [00:04<00:07,  8.61it/s, distance=37.5] 39%|███▉      | 39/100 [00:04<00:06,  9.27it/s, distance=36]   41%|████      | 41/100 [00:05<00:08,  6.90it/s, distance=34.3] 43%|████▎     | 43/100 [00:05<00:07,  7.84it/s, distance=33.5] 45%|████▌     | 45/100 [00:05<00:06,  8.64it/s, distance=32.9] 47%|████▋     | 47/100 [00:05<00:05,  9.30it/s, distance=32.1] 49%|████▉     | 49/100 [00:06<00:07,  6.89it/s, distance=31.8] 51%|█████     | 51/100 [00:06<00:06,  7.83it/s, distance=30.8] 53%|█████▎    | 53/100 [00:06<00:05,  8.62it/s, distance=30.1] 55%|█████▌    | 55/100 [00:06<00:04,  9.28it/s, distance=29.7] 57%|█████▋    | 57/100 [00:07<00:06,  6.82it/s, distance=29.2] 59%|█████▉    | 59/100 [00:07<00:05,  7.77it/s, distance=28.8] 61%|██████    | 61/100 [00:07<00:04,  8.57it/s, distance=28.3] 63%|██████▎   | 63/100 [00:07<00:04,  9.23it/s, distance=27.9] 65%|██████▌   | 65/100 [00:08<00:05,  6.81it/s, distance=27.6] 67%|██████▋   | 67/100 [00:08<00:04,  7.75it/s, distance=27.2] 69%|██████▉   | 69/100 [00:08<00:03,  8.56it/s, distance=26.8] 71%|███████   | 71/100 [00:08<00:03,  9.22it/s, distance=26.5] 73%|███████▎  | 73/100 [00:09<00:03,  6.83it/s, distance=26.2] 75%|███████▌  | 75/100 [00:09<00:03,  7.77it/s, distance=25.8] 77%|███████▋  | 77/100 [00:09<00:02,  8.56it/s, distance=25.5] 79%|███████▉  | 79/100 [00:09<00:02,  9.23it/s, distance=25.2] 81%|████████  | 81/100 [00:10<00:02,  6.84it/s, distance=24.8] 83%|████████▎ | 83/100 [00:10<00:02,  7.78it/s, distance=24.4] 85%|████████▌ | 85/100 [00:10<00:01,  8.58it/s, distance=24.1] 87%|████████▋ | 87/100 [00:10<00:01,  9.24it/s, distance=23.7] 89%|████████▉ | 89/100 [00:11<00:01,  6.84it/s, distance=23.3] 91%|█████████ | 91/100 [00:11<00:01,  7.78it/s, distance=22.8] 93%|█████████▎| 93/100 [00:11<00:00,  8.58it/s, distance=22.3] 95%|█████████▌| 95/100 [00:11<00:00,  9.24it/s, distance=21.6] 97%|█████████▋| 97/100 [00:12<00:00,  9.77it/s, distance=20.7] 99%|█████████▉| 99/100 [00:12<00:00, 10.17it/s, distance=19]  100%|██████████| 100/100 [00:12<00:00,  8.15it/s, distance=16.3]
2025-06-18 20:39:34,556 [MPGD] >> Inference for image 41
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -2.0224e+00, -5.1200e+08, -2.0935e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9805, -2.0608, -2.0664, -1.9996, -2.0870, -1.9473, -2.0259, -2.0835],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.21500323 0.04311256 0.03853408 0.14673808 0.02552165 0.41715949
 0.08657427 0.02735664]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7749, -1.8250, -1.7229, -1.7451, -1.7881, -1.7427, -1.8249, -1.8189],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10559701 0.03880971 0.29885547 0.19163192 0.08119818 0.20123602
 0.03887981 0.04379188]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7511, -1.4542, -1.6026, -1.6056, -1.6739, -1.5982, -1.6313, -1.6604],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00216887 0.82235497 0.04227293 0.03982176 0.01014998 0.04614944
 0.02377326 0.01330879]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3937, -1.3502, -1.3476, -1.3650, -1.4451, -1.3472, -1.4080, -1.3812],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07935872 0.18925856 0.19956089 0.14084516 0.02839419 0.20110314
 0.05962167 0.10185766]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3212, -1.3031, -1.3619, -1.3242, -1.1367, -1.1617, -1.2879, -1.2970],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01393173 0.02003558 0.00617463 0.01313791 0.55841031 0.33853491
 0.02714928 0.02262565]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0748, -1.2272, -1.0912, -1.0668, -1.1358, -1.0660, -1.0573, -1.1243],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16067866 0.00763264 0.1157934  0.18858744 0.04749242 0.19187237
 0.22814458 0.05979849]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0084, -1.0014, -1.0180, -1.0699, -1.0382, -0.9881, -1.0262, -0.9781],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12740953 0.1465418  0.10503562 0.0372015  0.07009832 0.19118407
 0.08912999 0.23339918]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0398, -0.9881, -1.0014, -0.9259, -1.0121, -1.0489, -1.0759, -1.0084],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04836903 0.1359862  0.10430718 0.47251969 0.08427994 0.04035707
 0.02353166 0.09064922]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9768, -0.9807, -0.9640, -0.9860, -1.0016, -1.0076, -0.9983, -0.9873],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15008094 0.13886739 0.19397025 0.12500596 0.09148095 0.08112426
 0.09776192 0.12170833]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9490, -0.9847, -0.9640, -1.0167, -0.9726, -0.9844, -0.9620, -0.9925],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.20865129 0.10211212 0.15455117 0.05378284 0.13006683 0.10274719
 0.16083714 0.08725142]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9623, -0.9250, -0.9909, -0.9643, -0.9809, -0.9703, -0.9693, -0.9794],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12903359 0.2719254  0.07271289 0.12395822 0.08881383 0.10980974
 0.11211593 0.09163041]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.158
key: ssim
value: 0.873
key: lpips
value: 0.098
key: facenet_l2
value: 0.595
key: adaface_l2
value: 0.883
ref_face_img: tensor([[[[ 0.8196,  0.8353,  0.8510,  ...,  0.9843,  0.9843,  0.9843],
          [ 0.8118,  0.8196,  0.8431,  ...,  0.9843,  0.9843,  0.9843],
          [ 0.7961,  0.8118,  0.8275,  ...,  0.9843,  0.9843,  0.9843],
          ...,
          [ 0.3882,  0.3804,  0.3725,  ...,  0.8039,  0.8275,  0.8353],
          [ 0.3804,  0.3725,  0.3647,  ...,  0.8431,  0.8588,  0.8667],
          [ 0.3725,  0.3647,  0.3647,  ...,  0.8667,  0.8824,  0.8902]],

         [[ 0.8510,  0.8667,  0.8745,  ...,  0.9686,  0.9608,  0.9608],
          [ 0.8431,  0.8510,  0.8667,  ...,  0.9686,  0.9608,  0.9608],
          [ 0.8353,  0.8510,  0.8667,  ...,  0.9686,  0.9608,  0.9608],
          ...,
          [ 0.1529,  0.1451,  0.1373,  ...,  0.7569,  0.7725,  0.7804],
          [ 0.1373,  0.1294,  0.1216,  ...,  0.7961,  0.8118,  0.8196],
          [ 0.1294,  0.1216,  0.1137,  ...,  0.8196,  0.8353,  0.8431]],

         [[ 0.8353,  0.8431,  0.8588,  ...,  0.9529,  0.9451,  0.9373],
          [ 0.8275,  0.8431,  0.8510,  ...,  0.9529,  0.9451,  0.9373],
          [ 0.8275,  0.8431,  0.8510,  ...,  0.9529,  0.9451,  0.9373],
          ...,
          [-0.0196, -0.0275, -0.0353,  ...,  0.7020,  0.7176,  0.7176],
          [-0.0275, -0.0353, -0.0431,  ...,  0.7412,  0.7490,  0.7569],
          [-0.0431, -0.0431, -0.0510,  ...,  0.7725,  0.7882,  0.7882]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:36,  2.69it/s, distance=300]  2%|▏         | 2/100 [00:00<00:21,  4.60it/s, distance=198]  4%|▍         | 4/100 [00:00<00:13,  7.28it/s, distance=155]  6%|▌         | 6/100 [00:00<00:10,  8.75it/s, distance=127]  8%|▊         | 8/100 [00:01<00:09,  9.62it/s, distance=112] 10%|█         | 10/100 [00:01<00:13,  6.69it/s, distance=99.4] 12%|█▏        | 12/100 [00:01<00:11,  7.78it/s, distance=87.9] 14%|█▍        | 14/100 [00:01<00:09,  8.67it/s, distance=76.4] 16%|█▌        | 16/100 [00:02<00:08,  9.37it/s, distance=68]   18%|█▊        | 18/100 [00:02<00:11,  6.91it/s, distance=61.6] 20%|██        | 20/100 [00:02<00:10,  7.85it/s, distance=57.4] 22%|██▏       | 22/100 [00:02<00:09,  8.67it/s, distance=54.4] 24%|██▍       | 24/100 [00:02<00:08,  9.33it/s, distance=50.7] 26%|██▌       | 26/100 [00:03<00:10,  6.94it/s, distance=49.1] 28%|██▊       | 28/100 [00:03<00:09,  7.86it/s, distance=47.1] 30%|███       | 30/100 [00:03<00:08,  8.64it/s, distance=45.9] 32%|███▏      | 32/100 [00:03<00:07,  9.29it/s, distance=44.6] 34%|███▍      | 34/100 [00:04<00:09,  6.96it/s, distance=44.1] 36%|███▌      | 36/100 [00:04<00:08,  7.85it/s, distance=41.3] 38%|███▊      | 38/100 [00:04<00:07,  8.64it/s, distance=39.5] 40%|████      | 40/100 [00:04<00:06,  9.29it/s, distance=38.5] 42%|████▏     | 42/100 [00:05<00:08,  6.90it/s, distance=37.3] 44%|████▍     | 44/100 [00:05<00:07,  7.82it/s, distance=36.1] 46%|████▌     | 46/100 [00:05<00:06,  8.61it/s, distance=34.9] 48%|████▊     | 48/100 [00:05<00:05,  9.27it/s, distance=34.4] 50%|█████     | 50/100 [00:06<00:07,  6.87it/s, distance=33.6] 52%|█████▏    | 52/100 [00:06<00:06,  7.78it/s, distance=32.6] 54%|█████▍    | 54/100 [00:06<00:05,  8.58it/s, distance=31.9] 56%|█████▌    | 56/100 [00:06<00:04,  9.24it/s, distance=31.4] 58%|█████▊    | 58/100 [00:07<00:06,  6.86it/s, distance=30.7] 60%|██████    | 60/100 [00:07<00:05,  7.78it/s, distance=30.3] 62%|██████▏   | 62/100 [00:07<00:04,  8.58it/s, distance=29.9] 64%|██████▍   | 64/100 [00:07<00:03,  9.24it/s, distance=29.3] 66%|██████▌   | 66/100 [00:08<00:04,  6.87it/s, distance=28.8] 68%|██████▊   | 68/100 [00:08<00:04,  7.78it/s, distance=28.3] 70%|███████   | 70/100 [00:08<00:03,  8.57it/s, distance=27.9] 72%|███████▏  | 72/100 [00:08<00:03,  9.23it/s, distance=27.5] 74%|███████▍  | 74/100 [00:09<00:03,  6.87it/s, distance=27.1] 76%|███████▌  | 76/100 [00:09<00:03,  7.78it/s, distance=26.7] 78%|███████▊  | 78/100 [00:09<00:02,  8.57it/s, distance=26.4] 80%|████████  | 80/100 [00:09<00:02,  9.24it/s, distance=26]   82%|████████▏ | 82/100 [00:10<00:02,  6.85it/s, distance=25.5] 84%|████████▍ | 84/100 [00:10<00:02,  7.77it/s, distance=25.1] 86%|████████▌ | 86/100 [00:10<00:01,  8.57it/s, distance=24.6] 88%|████████▊ | 88/100 [00:10<00:01,  9.23it/s, distance=24.2] 90%|█████████ | 90/100 [00:11<00:01,  6.84it/s, distance=23.7] 92%|█████████▏| 92/100 [00:11<00:01,  7.76it/s, distance=23.1] 94%|█████████▍| 94/100 [00:11<00:00,  8.56it/s, distance=22.4] 96%|█████████▌| 96/100 [00:11<00:00,  9.23it/s, distance=21.4] 98%|█████████▊| 98/100 [00:12<00:00,  9.76it/s, distance=20]  100%|██████████| 100/100 [00:12<00:00, 10.16it/s, distance=15.6]100%|██████████| 100/100 [00:12<00:00,  8.12it/s, distance=15.6]
2025-06-18 20:39:48,021 [MPGD] >> Inference for image 42
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -2.1562e+00, -5.1200e+08, -2.0750e+00,
        -5.1200e+08, -1.9580e+00, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0167, -1.8822, -1.8700, -1.9661, -2.0746, -1.8836, -1.8927, -1.9742],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0151058  0.22251048 0.28393025 0.04156371 0.00474191 0.21657255
 0.180236   0.0353393 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6916, -1.6527, -1.7030, -1.6891, -1.5232, -1.5126, -1.4618, -1.6501],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00583665 0.01269838 0.00464435 0.00613327 0.16919524 0.20936523
 0.57875309 0.0133738 ]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3835, -1.4266, -1.2384, -1.3505, -1.3151, -1.2676, -1.4317, -1.3239],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02540418 0.01072984 0.46321955 0.04916341 0.09980059 0.25830904
 0.00970003 0.08367336]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9719, -1.0900, -1.0170, -1.2248, -0.9947, -1.1109, -1.0860, -1.1026],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.42048124 0.03965688 0.17077826 0.00267415 0.26652193 0.02609595
 0.04296691 0.03082468]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0185, -0.9867, -1.0161, -1.1281, -1.0110, -1.1703, -1.0458, -1.0724],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16180365 0.30570634 0.16982535 0.01807539 0.18802418 0.00777354
 0.09378911 0.05500243]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8235, -0.8495, -1.0431, -1.0517, -0.9535, -1.0219, -0.7821, -0.9309],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.24300719 0.14444946 0.00300465 0.0025318  0.01804149 0.00459104
 0.55600926 0.02836512]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8708, -0.8317, -0.9431, -0.7866, -0.8499, -0.8645, -0.9339, -0.8767],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07906762 0.17304123 0.01863788 0.42648443 0.12024459 0.08985809
 0.02239143 0.07027475]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7891, -0.8485, -0.7966, -0.7865, -0.7597, -0.8237, -0.8399, -0.6628],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05436725 0.01656061 0.0468358  0.05726376 0.09782836 0.02720508
 0.01966265 0.68027649]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6836, -0.7634, -0.6961, -0.6881, -0.7614, -0.6976, -0.8001, -0.6746],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.19410766 0.03930003 0.15101093 0.17718091 0.04090846 0.14656307
 0.01886264 0.23206628]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6572, -0.7158, -0.7198, -0.6005, -0.7287, -0.6821, -0.6942, -0.6085],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11532385 0.03571894 0.03298873 0.35813019 0.02757688 0.07007192
 0.05502938 0.30516011]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5889, -0.5761, -0.6282, -0.5719, -0.5425, -0.6597, -0.5835, -0.6285],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1176966  0.15202379 0.05362864 0.16555625 0.297977   0.02860587
 0.13115403 0.05335782]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.948
key: ssim
value: 0.864
key: lpips
value: 0.090
key: facenet_l2
value: 0.342
key: adaface_l2
value: 0.676
ref_face_img: tensor([[[[-0.3569, -0.3569, -0.3647,  ..., -0.2784, -0.2784, -0.2784],
          [-0.3569, -0.3569, -0.3647,  ..., -0.2784, -0.2784, -0.2784],
          [-0.3569, -0.3569, -0.3647,  ..., -0.2784, -0.2784, -0.2784],
          ...,
          [-0.3490, -0.3490, -0.3490,  ..., -0.3020, -0.3020, -0.3020],
          [-0.3490, -0.3490, -0.3490,  ..., -0.3020, -0.3020, -0.3020],
          [-0.3490, -0.3490, -0.3490,  ..., -0.3020, -0.3020, -0.3020]],

         [[-0.3490, -0.3490, -0.3490,  ..., -0.2549, -0.2549, -0.2549],
          [-0.3490, -0.3490, -0.3490,  ..., -0.2549, -0.2549, -0.2549],
          [-0.3490, -0.3490, -0.3490,  ..., -0.2471, -0.2549, -0.2549],
          ...,
          [-0.3412, -0.3412, -0.3412,  ..., -0.2235, -0.2235, -0.2235],
          [-0.3412, -0.3412, -0.3412,  ..., -0.2235, -0.2235, -0.2235],
          [-0.3412, -0.3412, -0.3412,  ..., -0.2235, -0.2235, -0.2235]],

         [[-0.1529, -0.1451, -0.1451,  ..., -0.0275, -0.0275, -0.0275],
          [-0.1529, -0.1451, -0.1451,  ..., -0.0275, -0.0275, -0.0275],
          [-0.1529, -0.1451, -0.1451,  ..., -0.0196, -0.0275, -0.0275],
          ...,
          [-0.1294, -0.1294, -0.1216,  ...,  0.0275,  0.0275,  0.0196],
          [-0.1294, -0.1294, -0.1294,  ...,  0.0275,  0.0275,  0.0196],
          [-0.1294, -0.1294, -0.1294,  ...,  0.0275,  0.0275,  0.0196]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.86it/s, distance=343]  3%|▎         | 3/100 [00:00<00:15,  6.45it/s, distance=175]  5%|▌         | 5/100 [00:00<00:11,  8.27it/s, distance=116]  7%|▋         | 7/100 [00:00<00:09,  9.31it/s, distance=99.4]  9%|▉         | 9/100 [00:01<00:14,  6.47it/s, distance=84.1] 11%|█         | 11/100 [00:01<00:11,  7.64it/s, distance=81.1] 13%|█▎        | 13/100 [00:01<00:10,  8.56it/s, distance=74.9] 15%|█▌        | 15/100 [00:01<00:09,  9.27it/s, distance=66.5] 17%|█▋        | 17/100 [00:02<00:12,  6.69it/s, distance=58.5] 19%|█▉        | 19/100 [00:02<00:10,  7.68it/s, distance=58.9] 21%|██        | 21/100 [00:02<00:09,  8.49it/s, distance=52.8] 23%|██▎       | 23/100 [00:02<00:08,  9.17it/s, distance=50.1] 25%|██▌       | 25/100 [00:03<00:11,  6.76it/s, distance=49.3] 27%|██▋       | 27/100 [00:03<00:09,  7.71it/s, distance=43.3] 29%|██▉       | 29/100 [00:03<00:08,  8.52it/s, distance=41.3] 31%|███       | 31/100 [00:03<00:07,  9.20it/s, distance=38.9] 33%|███▎      | 33/100 [00:04<00:09,  6.82it/s, distance=37.3] 35%|███▌      | 35/100 [00:04<00:08,  7.76it/s, distance=36.6] 37%|███▋      | 37/100 [00:04<00:07,  8.56it/s, distance=36.1] 39%|███▉      | 39/100 [00:04<00:06,  9.23it/s, distance=34.9] 41%|████      | 41/100 [00:05<00:08,  6.82it/s, distance=34.1] 43%|████▎     | 43/100 [00:05<00:07,  7.77it/s, distance=33.3] 45%|████▌     | 45/100 [00:05<00:06,  8.56it/s, distance=32.8] 47%|████▋     | 47/100 [00:05<00:05,  9.23it/s, distance=32]   49%|████▉     | 49/100 [00:06<00:07,  6.83it/s, distance=31.4] 51%|█████     | 51/100 [00:06<00:06,  7.76it/s, distance=30.8] 53%|█████▎    | 53/100 [00:06<00:05,  8.56it/s, distance=30.4] 55%|█████▌    | 55/100 [00:06<00:04,  9.22it/s, distance=30]   57%|█████▋    | 57/100 [00:07<00:06,  6.82it/s, distance=29.7] 59%|█████▉    | 59/100 [00:07<00:05,  7.75it/s, distance=29.2] 61%|██████    | 61/100 [00:07<00:04,  8.55it/s, distance=28.8] 63%|██████▎   | 63/100 [00:07<00:04,  9.21it/s, distance=28.4] 65%|██████▌   | 65/100 [00:08<00:05,  6.77it/s, distance=27.8] 67%|██████▋   | 67/100 [00:08<00:04,  7.71it/s, distance=27.5] 69%|██████▉   | 69/100 [00:08<00:03,  8.52it/s, distance=27.2] 71%|███████   | 71/100 [00:08<00:03,  9.20it/s, distance=26.8] 73%|███████▎  | 73/100 [00:09<00:03,  6.76it/s, distance=26.4] 75%|███████▌  | 75/100 [00:09<00:03,  7.72it/s, distance=26.2] 77%|███████▋  | 77/100 [00:09<00:02,  8.52it/s, distance=25.8] 79%|███████▉  | 79/100 [00:09<00:02,  9.18it/s, distance=25.5] 81%|████████  | 81/100 [00:10<00:02,  6.78it/s, distance=25.2] 83%|████████▎ | 83/100 [00:10<00:02,  7.72it/s, distance=24.8] 85%|████████▌ | 85/100 [00:10<00:01,  8.53it/s, distance=24.4] 87%|████████▋ | 87/100 [00:10<00:01,  9.19it/s, distance=24]   89%|████████▉ | 89/100 [00:11<00:01,  6.75it/s, distance=23.6] 91%|█████████ | 91/100 [00:11<00:01,  7.70it/s, distance=23.1] 93%|█████████▎| 93/100 [00:11<00:00,  8.50it/s, distance=22.5] 95%|█████████▌| 95/100 [00:11<00:00,  9.16it/s, distance=21.7] 97%|█████████▋| 97/100 [00:12<00:00,  9.70it/s, distance=20.7] 99%|█████████▉| 99/100 [00:12<00:00, 10.13it/s, distance=18.7]100%|██████████| 100/100 [00:12<00:00,  8.08it/s, distance=15.7]
2025-06-18 20:40:01,722 [MPGD] >> Inference for image 43
reward_name: adaface, curr_reward: tensor([-2.0780e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -2.1784e+00, -2.0755e+00, -2.0716e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8574, -1.8522, -1.9047, -1.7467, -1.8720, -1.9420, -1.7755, -1.8810],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05450815 0.06044036 0.02115626 0.49891407 0.04068311 0.01003115
 0.28025954 0.03400736]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2938, -1.1256, -1.2652, -1.3509, -1.2956, -1.3510, -1.1652, -1.1049],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01110746 0.32085385 0.01965814 0.0035433  0.0107068  0.0035385
 0.14544298 0.48514897]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0426, -1.1080, -1.0847, -1.1166, -1.0482, -1.0056, -1.1182, -0.9826],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11820417 0.03193212 0.05091156 0.02693006 0.10566545 0.24767952
 0.0260757  0.39260142]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9521, -0.9406, -0.9754, -0.9600, -0.9972, -0.9193, -0.9562, -0.9148],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10977652 0.13823918 0.06897786 0.09381582 0.04455933 0.21185409
 0.10118583 0.23159138]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8067, -0.8498, -0.8329, -0.8340, -0.7681, -0.9335, -0.8370, -0.7960],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15100788 0.06379603 0.08941272 0.08754222 0.32675589 0.01196979
 0.08237359 0.18714189]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7039, -0.7416, -0.6673, -0.7576, -0.7846, -0.7994, -0.7021, -0.8206],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.18611468 0.0875658  0.38715605 0.06362073 0.03706311 0.02756937
 0.19288261 0.01802765]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6838, -0.7499, -0.6168, -0.6488, -0.6186, -0.6024, -0.6605, -0.6964],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05483237 0.01459783 0.20942108 0.11033613 0.20173707 0.27913786
 0.08732512 0.04261254]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6239, -0.6115, -0.6381, -0.6344, -0.6403, -0.6650, -0.6107, -0.6795],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15083174 0.19312696 0.11340374 0.12213783 0.1085594  0.06630172
 0.19607376 0.04956485]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5807, -0.5529, -0.5802, -0.5461, -0.6556, -0.6408, -0.5746, -0.6253],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12798225 0.22316548 0.12913655 0.25578789 0.02858876 0.03846259
 0.14443153 0.05244494]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5397, -0.5669, -0.5925, -0.4979, -0.5775, -0.5121, -0.5404, -0.5760],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12646989 0.07334424 0.0439931  0.29153552 0.05934971 0.21958392
 0.12461445 0.06110916]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5135, -0.4796, -0.4930, -0.4430, -0.5280, -0.5162, -0.5025, -0.5004],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07807796 0.15366803 0.11749012 0.31970047 0.05833338 0.07397361
 0.09729006 0.10146638]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 31.125
key: ssim
value: 0.849
key: lpips
value: 0.118
key: facenet_l2
value: 0.325
key: adaface_l2
value: 0.600
ref_face_img: tensor([[[[0.8980, 0.8980, 0.8980,  ..., 0.9294, 0.9294, 0.9294],
          [0.8980, 0.8980, 0.8980,  ..., 0.9294, 0.9294, 0.9294],
          [0.8980, 0.8980, 0.8980,  ..., 0.9294, 0.9294, 0.9294],
          ...,
          [0.5686, 0.5216, 0.4667,  ..., 0.8902, 0.8902, 0.8824],
          [0.5529, 0.5059, 0.4431,  ..., 0.8902, 0.8902, 0.8824],
          [0.5373, 0.4902, 0.4196,  ..., 0.8902, 0.8902, 0.8824]],

         [[0.8902, 0.8902, 0.8902,  ..., 0.9137, 0.9137, 0.9059],
          [0.8902, 0.8902, 0.8902,  ..., 0.9137, 0.9137, 0.9059],
          [0.8902, 0.8902, 0.8824,  ..., 0.9137, 0.9059, 0.9059],
          ...,
          [0.6392, 0.5922, 0.5294,  ..., 0.9059, 0.8980, 0.8980],
          [0.6235, 0.5686, 0.5059,  ..., 0.9059, 0.9059, 0.8980],
          [0.6078, 0.5529, 0.4824,  ..., 0.9059, 0.9059, 0.8980]],

         [[0.8745, 0.8745, 0.8745,  ..., 0.8196, 0.8353, 0.8353],
          [0.8745, 0.8745, 0.8745,  ..., 0.8196, 0.8353, 0.8353],
          [0.8745, 0.8745, 0.8745,  ..., 0.8275, 0.8275, 0.8353],
          ...,
          [0.7020, 0.6549, 0.5922,  ..., 0.8039, 0.8118, 0.8118],
          [0.6863, 0.6314, 0.5608,  ..., 0.8039, 0.8118, 0.8118],
          [0.6706, 0.6235, 0.5451,  ..., 0.8039, 0.8118, 0.8196]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.91it/s, distance=284]  3%|▎         | 3/100 [00:00<00:14,  6.51it/s, distance=162]  5%|▌         | 5/100 [00:00<00:11,  8.32it/s, distance=147]  7%|▋         | 7/100 [00:00<00:09,  9.35it/s, distance=131]  9%|▉         | 9/100 [00:01<00:14,  6.37it/s, distance=125] 11%|█         | 11/100 [00:01<00:11,  7.53it/s, distance=114] 13%|█▎        | 13/100 [00:01<00:10,  8.47it/s, distance=99.2] 15%|█▌        | 15/100 [00:01<00:09,  9.20it/s, distance=89.9] 17%|█▋        | 17/100 [00:02<00:12,  6.72it/s, distance=65.4] 19%|█▉        | 19/100 [00:02<00:10,  7.70it/s, distance=63.4] 21%|██        | 21/100 [00:02<00:09,  8.53it/s, distance=56.9] 23%|██▎       | 23/100 [00:02<00:08,  9.19it/s, distance=49.1] 25%|██▌       | 25/100 [00:03<00:11,  6.79it/s, distance=45.1] 27%|██▋       | 27/100 [00:03<00:09,  7.74it/s, distance=42.5] 29%|██▉       | 29/100 [00:03<00:08,  8.55it/s, distance=40.2] 31%|███       | 31/100 [00:03<00:07,  9.22it/s, distance=38.3] 33%|███▎      | 33/100 [00:04<00:09,  6.80it/s, distance=37.2] 35%|███▌      | 35/100 [00:04<00:08,  7.74it/s, distance=36]   37%|███▋      | 37/100 [00:04<00:07,  8.55it/s, distance=35.4] 39%|███▉      | 39/100 [00:04<00:06,  9.20it/s, distance=34.2] 41%|████      | 41/100 [00:05<00:08,  6.75it/s, distance=33.6] 43%|████▎     | 43/100 [00:05<00:07,  7.71it/s, distance=33.3] 45%|████▌     | 45/100 [00:05<00:06,  8.52it/s, distance=32.3] 47%|████▋     | 47/100 [00:05<00:05,  9.19it/s, distance=31.9] 49%|████▉     | 49/100 [00:06<00:07,  6.79it/s, distance=31.8] 51%|█████     | 51/100 [00:06<00:06,  7.73it/s, distance=30.7] 53%|█████▎    | 53/100 [00:06<00:05,  8.53it/s, distance=30.3] 55%|█████▌    | 55/100 [00:06<00:04,  9.21it/s, distance=29.9] 57%|█████▋    | 57/100 [00:07<00:06,  6.83it/s, distance=29.4] 59%|█████▉    | 59/100 [00:07<00:05,  7.78it/s, distance=28.9] 61%|██████    | 61/100 [00:07<00:04,  8.58it/s, distance=28.4] 63%|██████▎   | 63/100 [00:07<00:04,  9.24it/s, distance=28]   65%|██████▌   | 65/100 [00:08<00:05,  6.87it/s, distance=27.5] 67%|██████▋   | 67/100 [00:08<00:04,  7.81it/s, distance=27.2] 69%|██████▉   | 69/100 [00:08<00:03,  8.60it/s, distance=26.8] 71%|███████   | 71/100 [00:08<00:03,  9.25it/s, distance=26.5] 73%|███████▎  | 73/100 [00:09<00:03,  6.86it/s, distance=26.1] 75%|███████▌  | 75/100 [00:09<00:03,  7.79it/s, distance=25.8] 77%|███████▋  | 77/100 [00:09<00:02,  8.59it/s, distance=25.4] 79%|███████▉  | 79/100 [00:09<00:02,  9.25it/s, distance=25]   81%|████████  | 81/100 [00:10<00:02,  6.85it/s, distance=24.6] 83%|████████▎ | 83/100 [00:10<00:02,  7.79it/s, distance=24.3] 85%|████████▌ | 85/100 [00:10<00:01,  8.58it/s, distance=23.9] 87%|████████▋ | 87/100 [00:10<00:01,  9.25it/s, distance=23.6] 89%|████████▉ | 89/100 [00:11<00:01,  6.88it/s, distance=23.1] 91%|█████████ | 91/100 [00:11<00:01,  7.81it/s, distance=22.6] 93%|█████████▎| 93/100 [00:11<00:00,  8.61it/s, distance=22.1] 95%|█████████▌| 95/100 [00:11<00:00,  9.27it/s, distance=21.3] 97%|█████████▋| 97/100 [00:12<00:00,  9.79it/s, distance=20.3] 99%|█████████▉| 99/100 [00:12<00:00, 10.19it/s, distance=18.3]100%|██████████| 100/100 [00:12<00:00,  8.11it/s, distance=15.3]
2025-06-18 20:40:15,157 [MPGD] >> Inference for image 44
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -2.0519e+00, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -1.9225e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8599, -1.8555, -1.8742, -1.7542, -1.6764, -1.7990, -1.9432, -1.7261],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01459635 0.01594433 0.0109663  0.12087219 0.57336016 0.04939627
 0.00275726 0.21210714]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4001, -1.4928, -1.4446, -1.5882, -1.5003, -1.4417, -1.5241, -1.4336],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.36285538 0.05684163 0.1489426  0.00842392 0.04893601 0.15778067
 0.03038265 0.18583714]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3578, -1.3213, -1.1905, -1.3818, -1.2387, -1.3191, -1.2893, -1.2806],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01864366 0.03861888 0.52853731 0.01153566 0.20178499 0.04042645
 0.07330243 0.08715063]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0270, -1.0645, -1.0418, -1.0399, -1.0034, -0.9531, -0.9826, -1.0528],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0833633  0.03935052 0.06197064 0.06431158 0.13348919 0.36547083
 0.20229335 0.0497506 ]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8316, -0.9107, -0.8307, -0.7950, -0.9052, -0.8711, -0.8474, -0.7981],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1302527  0.02680723 0.13278894 0.2712951  0.02993857 0.05921078
 0.09507421 0.25463247]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7297, -0.8015, -0.8286, -0.8054, -0.7107, -0.8124, -0.8536, -0.7580],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.25609675 0.06099229 0.03549373 0.05641444 0.37483242 0.0490293
 0.02149366 0.14564741]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7614, -0.7938, -0.6871, -0.7772, -0.8154, -0.7828, -0.6852, -0.7447],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07328723 0.03832659 0.32384445 0.05340375 0.02485815 0.0476901
 0.33639951 0.10219022]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7071, -0.6809, -0.6916, -0.6909, -0.6692, -0.7134, -0.7036, -0.6916],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09178272 0.15502699 0.12528458 0.12707725 0.1960129  0.0809512
 0.09849626 0.12536809]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7050, -0.6506, -0.6150, -0.6672, -0.6928, -0.7055, -0.6674, -0.7163],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05771983 0.17123633 0.34887821 0.1229022  0.07366115 0.05709108
 0.12248068 0.04603052]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6179, -0.5777, -0.6600, -0.6660, -0.6405, -0.6193, -0.6171, -0.6389],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13642833 0.30486556 0.05875044 0.05215495 0.08678612 0.13268349
 0.13861887 0.08971224]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5690, -0.5377, -0.5506, -0.5593, -0.5731, -0.5803, -0.5787, -0.5482],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10437572 0.19510718 0.15057942 0.12661091 0.09610796 0.08320054
 0.08595309 0.15806519]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.708
key: ssim
value: 0.821
key: lpips
value: 0.141
key: facenet_l2
value: 0.298
key: adaface_l2
value: 0.571
ref_face_img: tensor([[[[-0.2157, -0.2235, -0.2314,  ...,  0.2000,  0.2000,  0.1922],
          [-0.2157, -0.2235, -0.2314,  ...,  0.2000,  0.1922,  0.1922],
          [-0.2157, -0.2235, -0.2235,  ...,  0.1922,  0.1922,  0.1922],
          ...,
          [ 0.6784,  0.6706,  0.6706,  ...,  0.3961,  0.3961,  0.3961],
          [ 0.6784,  0.6706,  0.6706,  ...,  0.4039,  0.4039,  0.4039],
          [ 0.6784,  0.6706,  0.6627,  ...,  0.4118,  0.4118,  0.4118]],

         [[-0.2706, -0.2784, -0.2941,  ..., -0.2627, -0.2627, -0.2627],
          [-0.2627, -0.2784, -0.2941,  ..., -0.2627, -0.2627, -0.2627],
          [-0.2627, -0.2706, -0.2863,  ..., -0.2627, -0.2627, -0.2549],
          ...,
          [ 0.3961,  0.3882,  0.3882,  ...,  0.0745,  0.0745,  0.0745],
          [ 0.3961,  0.3882,  0.3882,  ...,  0.0902,  0.0902,  0.0902],
          [ 0.3882,  0.3804,  0.3804,  ...,  0.0980,  0.0980,  0.0980]],

         [[-0.2706, -0.2784, -0.2941,  ..., -0.3804, -0.3804, -0.3804],
          [-0.2627, -0.2706, -0.2863,  ..., -0.3804, -0.3804, -0.3804],
          [-0.2549, -0.2706, -0.2863,  ..., -0.3804, -0.3804, -0.3804],
          ...,
          [ 0.0667,  0.0588,  0.0588,  ..., -0.2078, -0.2078, -0.2078],
          [ 0.0667,  0.0588,  0.0588,  ..., -0.1922, -0.1922, -0.1922],
          [ 0.0667,  0.0510,  0.0510,  ..., -0.1843, -0.1843, -0.1843]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.92it/s, distance=330]  3%|▎         | 3/100 [00:00<00:14,  6.52it/s, distance=177]  5%|▌         | 5/100 [00:00<00:11,  8.33it/s, distance=134]  7%|▋         | 7/100 [00:00<00:09,  9.36it/s, distance=114]  9%|▉         | 9/100 [00:01<00:14,  6.47it/s, distance=110] 11%|█         | 11/100 [00:01<00:11,  7.63it/s, distance=103] 13%|█▎        | 13/100 [00:01<00:10,  8.55it/s, distance=88.1] 15%|█▌        | 15/100 [00:01<00:09,  9.28it/s, distance=75.6] 17%|█▋        | 17/100 [00:02<00:12,  6.83it/s, distance=66]   19%|█▉        | 19/100 [00:02<00:10,  7.81it/s, distance=63.3] 21%|██        | 21/100 [00:02<00:09,  8.62it/s, distance=60.9] 23%|██▎       | 23/100 [00:02<00:08,  9.29it/s, distance=61.5] 25%|██▌       | 25/100 [00:03<00:10,  6.86it/s, distance=56.1] 27%|██▋       | 27/100 [00:03<00:09,  7.81it/s, distance=52.9] 29%|██▉       | 29/100 [00:03<00:08,  8.61it/s, distance=50.2] 31%|███       | 31/100 [00:03<00:07,  9.27it/s, distance=46.2] 33%|███▎      | 33/100 [00:04<00:09,  6.85it/s, distance=44.5] 35%|███▌      | 35/100 [00:04<00:08,  7.80it/s, distance=42.8] 37%|███▋      | 37/100 [00:04<00:07,  8.60it/s, distance=40.8] 39%|███▉      | 39/100 [00:04<00:06,  9.27it/s, distance=39.6] 41%|████      | 41/100 [00:05<00:08,  6.85it/s, distance=38.2] 43%|████▎     | 43/100 [00:05<00:07,  7.79it/s, distance=37.4] 45%|████▌     | 45/100 [00:05<00:06,  8.59it/s, distance=36.5] 47%|████▋     | 47/100 [00:05<00:05,  9.24it/s, distance=35.2] 49%|████▉     | 49/100 [00:06<00:07,  6.84it/s, distance=34.3] 51%|█████     | 51/100 [00:06<00:06,  7.78it/s, distance=33.7] 53%|█████▎    | 53/100 [00:06<00:05,  8.59it/s, distance=32.7] 55%|█████▌    | 55/100 [00:06<00:04,  9.25it/s, distance=32.1] 57%|█████▋    | 57/100 [00:07<00:06,  6.89it/s, distance=31.6] 59%|█████▉    | 59/100 [00:07<00:05,  7.82it/s, distance=31.1] 61%|██████    | 61/100 [00:07<00:04,  8.62it/s, distance=30.5] 63%|██████▎   | 63/100 [00:07<00:03,  9.27it/s, distance=29.9] 65%|██████▌   | 65/100 [00:08<00:05,  6.89it/s, distance=29.2] 67%|██████▋   | 67/100 [00:08<00:04,  7.82it/s, distance=28.9] 69%|██████▉   | 69/100 [00:08<00:03,  8.61it/s, distance=28.4] 71%|███████   | 71/100 [00:08<00:03,  9.26it/s, distance=28]   73%|███████▎  | 73/100 [00:09<00:03,  6.89it/s, distance=27.6] 75%|███████▌  | 75/100 [00:09<00:03,  7.83it/s, distance=27.1] 77%|███████▋  | 77/100 [00:09<00:02,  8.62it/s, distance=26.7] 79%|███████▉  | 79/100 [00:09<00:02,  9.28it/s, distance=26.2] 81%|████████  | 81/100 [00:10<00:02,  6.89it/s, distance=25.7] 83%|████████▎ | 83/100 [00:10<00:02,  7.83it/s, distance=25.3] 85%|████████▌ | 85/100 [00:10<00:01,  8.62it/s, distance=24.9] 87%|████████▋ | 87/100 [00:10<00:01,  9.28it/s, distance=24.4] 89%|████████▉ | 89/100 [00:11<00:01,  6.87it/s, distance=23.9] 91%|█████████ | 91/100 [00:11<00:01,  7.80it/s, distance=23.3] 93%|█████████▎| 93/100 [00:11<00:00,  8.60it/s, distance=22.7] 95%|█████████▌| 95/100 [00:11<00:00,  9.25it/s, distance=21.9] 97%|█████████▋| 97/100 [00:11<00:00,  9.77it/s, distance=20.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.17it/s, distance=18.9]100%|██████████| 100/100 [00:12<00:00,  8.15it/s, distance=15.9]
2025-06-18 20:40:28,822 [MPGD] >> Inference for image 45
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.0079e+00, -1.9187e+00, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -2.0005e+00, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9543, -1.9673, -2.1098, -1.9319, -2.1110, -2.0810, -1.9474, -2.1304],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.21380158 0.16480209 0.0095379  0.33423035 0.00930303 0.01693861
 0.24507093 0.00631552]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7923, -1.6611, -1.5928, -1.6804, -1.5931, -1.4830, -1.6106, -1.6490],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00148434 0.02048848 0.08026883 0.01393122 0.07984054 0.721628
 0.056259   0.02609959]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3117, -1.3652, -1.3137, -1.2030, -1.1958, -1.1601, -1.2079, -1.2134],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01749768 0.00600322 0.01680262 0.15405409 0.17776495 0.3632949
 0.13955519 0.12502736]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1934, -1.0138, -1.0172, -1.1092, -1.1484, -1.0089, -1.1053, -1.0744],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00737063 0.26741574 0.25003694 0.03970974 0.01810721 0.29487495
 0.04286947 0.07961532]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8833, -0.9680, -0.9858, -0.8640, -1.0058, -1.0172, -0.9318, -0.8630],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.20756247 0.03816423 0.02671463 0.30509771 0.01791517 0.0142538
 0.07861919 0.31167279]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7828, -0.8103, -0.7705, -0.8177, -0.7919, -0.8001, -0.7754, -0.7802],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14066379 0.08118967 0.17987519 0.07006812 0.1173618  0.09963568
 0.16300985 0.1481959 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7242, -0.7324, -0.7332, -0.7487, -0.7222, -0.6981, -0.7015, -0.6823],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10094027 0.08573121 0.08424518 0.06188431 0.10506581 0.16999543
 0.15892297 0.23321481]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7028, -0.7193, -0.6782, -0.6733, -0.7093, -0.7080, -0.6988, -0.7147],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1135223  0.08167559 0.18580315 0.20469655 0.09961236 0.10221513
 0.12296422 0.08951069]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6407, -0.6783, -0.6787, -0.6934, -0.6698, -0.6976, -0.7096, -0.7128],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.27336742 0.12888428 0.12801149 0.09538269 0.15300275 0.08776594
 0.06894271 0.06464272]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6632, -0.6653, -0.6301, -0.6465, -0.6405, -0.6757, -0.6315, -0.6073],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07942133 0.07616853 0.15405516 0.11084388 0.12501601 0.06190881
 0.14968544 0.24290084]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6315, -0.6079, -0.6143, -0.6263, -0.5733, -0.6091, -0.5762, -0.6094],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06904713 0.11078961 0.09747456 0.07671209 0.22126588 0.10818599
 0.20896809 0.10755665]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.424
key: ssim
value: 0.860
key: lpips
value: 0.077
key: facenet_l2
value: 0.444
key: adaface_l2
value: 0.640
ref_face_img: tensor([[[[ 0.4980,  0.4980,  0.4980,  ...,  0.3569,  0.3569,  0.3569],
          [ 0.4980,  0.4980,  0.4980,  ...,  0.3569,  0.3569,  0.3569],
          [ 0.4980,  0.4980,  0.4980,  ...,  0.3569,  0.3569,  0.3569],
          ...,
          [ 0.4353,  0.4353,  0.4353,  ...,  0.3647,  0.3725,  0.3725],
          [ 0.4353,  0.4353,  0.4353,  ...,  0.3725,  0.3725,  0.3725],
          [ 0.4353,  0.4353,  0.4353,  ...,  0.3804,  0.3804,  0.3804]],

         [[-0.4196, -0.4196, -0.4118,  ..., -0.9922, -0.9922, -0.9922],
          [-0.4275, -0.4275, -0.4275,  ..., -0.9922, -0.9922, -0.9922],
          [-0.4431, -0.4431, -0.4431,  ..., -0.9922, -0.9922, -0.9922],
          ...,
          [-0.9843, -0.9843, -0.9843,  ..., -0.0588, -0.0588, -0.0588],
          [-0.9765, -0.9765, -0.9765,  ..., -0.0588, -0.0588, -0.0588],
          [-0.9686, -0.9686, -0.9765,  ..., -0.0510, -0.0431, -0.0510]],

         [[-0.4118, -0.4118, -0.4118,  ..., -0.9922, -0.9922, -0.9922],
          [-0.4275, -0.4275, -0.4196,  ..., -0.9922, -0.9922, -0.9922],
          [-0.4353, -0.4353, -0.4353,  ..., -0.9922, -0.9922, -0.9922],
          ...,
          [-0.9765, -0.9765, -0.9765,  ..., -0.0118, -0.0118, -0.0196],
          [-0.9686, -0.9686, -0.9686,  ..., -0.0118, -0.0118, -0.0196],
          [-0.9686, -0.9686, -0.9686,  ..., -0.0118, -0.0118, -0.0039]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.93it/s, distance=245]  3%|▎         | 3/100 [00:00<00:14,  6.52it/s, distance=150]  5%|▌         | 5/100 [00:00<00:11,  8.32it/s, distance=145]  7%|▋         | 7/100 [00:00<00:09,  9.37it/s, distance=128]  9%|▉         | 9/100 [00:01<00:14,  6.47it/s, distance=106] 11%|█         | 11/100 [00:01<00:11,  7.63it/s, distance=98.5] 13%|█▎        | 13/100 [00:01<00:10,  8.55it/s, distance=82.4] 15%|█▌        | 15/100 [00:01<00:09,  9.27it/s, distance=74.9] 17%|█▋        | 17/100 [00:02<00:12,  6.78it/s, distance=66.6] 19%|█▉        | 19/100 [00:02<00:10,  7.77it/s, distance=63.2] 21%|██        | 21/100 [00:02<00:09,  8.59it/s, distance=59.2] 23%|██▎       | 23/100 [00:02<00:08,  9.25it/s, distance=57.2] 25%|██▌       | 25/100 [00:03<00:10,  6.84it/s, distance=54.9] 27%|██▋       | 27/100 [00:03<00:09,  7.79it/s, distance=53.9] 29%|██▉       | 29/100 [00:03<00:08,  8.59it/s, distance=50.1] 31%|███       | 31/100 [00:03<00:07,  9.25it/s, distance=49]   33%|███▎      | 33/100 [00:04<00:09,  6.87it/s, distance=47.1] 35%|███▌      | 35/100 [00:04<00:08,  7.81it/s, distance=45.9] 37%|███▋      | 37/100 [00:04<00:07,  8.61it/s, distance=44.4] 39%|███▉      | 39/100 [00:04<00:06,  9.27it/s, distance=42.7] 41%|████      | 41/100 [00:05<00:08,  6.89it/s, distance=42.3] 43%|████▎     | 43/100 [00:05<00:07,  7.83it/s, distance=40.5] 45%|████▌     | 45/100 [00:05<00:06,  8.62it/s, distance=39.4] 47%|████▋     | 47/100 [00:05<00:05,  9.27it/s, distance=38.3] 49%|████▉     | 49/100 [00:06<00:07,  6.89it/s, distance=37.6] 51%|█████     | 51/100 [00:06<00:06,  7.82it/s, distance=36.7] 53%|█████▎    | 53/100 [00:06<00:05,  8.62it/s, distance=35.7] 55%|█████▌    | 55/100 [00:06<00:04,  9.27it/s, distance=34.9] 57%|█████▋    | 57/100 [00:07<00:06,  6.89it/s, distance=34.3] 59%|█████▉    | 59/100 [00:07<00:05,  7.82it/s, distance=33.6] 61%|██████    | 61/100 [00:07<00:04,  8.61it/s, distance=32.9] 63%|██████▎   | 63/100 [00:07<00:03,  9.26it/s, distance=32.2] 65%|██████▌   | 65/100 [00:08<00:05,  6.90it/s, distance=31.7] 67%|██████▋   | 67/100 [00:08<00:04,  7.83it/s, distance=31.1] 69%|██████▉   | 69/100 [00:08<00:03,  8.62it/s, distance=30.6] 71%|███████   | 71/100 [00:08<00:03,  9.28it/s, distance=30]   73%|███████▎  | 73/100 [00:09<00:03,  6.88it/s, distance=29.6] 75%|███████▌  | 75/100 [00:09<00:03,  7.82it/s, distance=29.1] 77%|███████▋  | 77/100 [00:09<00:02,  8.61it/s, distance=28.6] 79%|███████▉  | 79/100 [00:09<00:02,  9.26it/s, distance=28.1] 81%|████████  | 81/100 [00:10<00:02,  6.86it/s, distance=27.6] 83%|████████▎ | 83/100 [00:10<00:02,  7.79it/s, distance=27.2] 85%|████████▌ | 85/100 [00:10<00:01,  8.59it/s, distance=26.6] 87%|████████▋ | 87/100 [00:10<00:01,  9.24it/s, distance=26.1] 89%|████████▉ | 89/100 [00:11<00:01,  6.85it/s, distance=25.5] 91%|█████████ | 91/100 [00:11<00:01,  7.78it/s, distance=24.8] 93%|█████████▎| 93/100 [00:11<00:00,  8.58it/s, distance=24.1] 95%|█████████▌| 95/100 [00:11<00:00,  9.24it/s, distance=23.2] 97%|█████████▋| 97/100 [00:11<00:00,  9.77it/s, distance=21.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.15it/s, distance=19.7]100%|██████████| 100/100 [00:12<00:00,  8.15it/s, distance=16.5]
2025-06-18 20:40:42,261 [MPGD] >> Inference for image 46
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -2.1541e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -2.0896e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.1088, -2.1940, -2.2274, -2.0839, -2.1983, -2.2369, -1.9972, -2.2352],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07962636 0.01446838 0.00742375 0.13093558 0.01329698 0.0061394
 0.7417588  0.00635075]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6041, -1.6948, -1.6074, -1.5757, -1.7581, -1.6718, -1.7524, -1.7304],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.23256838 0.0379221  0.21766794 0.41042381 0.01069317 0.06011268
 0.01199526 0.01861667]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2858, -1.1924, -1.3590, -1.3312, -1.3838, -1.4596, -1.3118, -1.2156],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07716639 0.50018578 0.01786484 0.0311037  0.01086924 0.00238947
 0.0459282  0.31449239]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1417, -1.1665, -1.1916, -1.2116, -1.2236, -1.1832, -1.1314, -1.1245],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.18190209 0.11076229 0.0670972  0.04497265 0.03534995 0.07934669
 0.22376836 0.25680078]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9177, -1.0364, -0.9667, -1.0788, -0.9719, -0.9855, -0.9334, -0.9899],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.32556409 0.03031297 0.12236281 0.01299472 0.11016052 0.08397892
 0.23779002 0.07683594]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8659, -0.8585, -0.8430, -0.7621, -0.9055, -0.8416, -0.9438, -0.8486],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06488856 0.07515554 0.10250733 0.51731881 0.02938772 0.10544485
 0.01366144 0.09163576]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7074, -0.7258, -0.8226, -0.6286, -0.7357, -0.7161, -0.6347, -0.6720],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06976265 0.04824301 0.00695785 0.33696121 0.03955765 0.05858911
 0.29848794 0.14144059]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6578, -0.5903, -0.6365, -0.6098, -0.5454, -0.6004, -0.5732, -0.5722],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03065733 0.11828559 0.04694094 0.08014602 0.29057973 0.09672684
 0.16655122 0.17011233]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6127, -0.6254, -0.5687, -0.5387, -0.5919, -0.5654, -0.5353, -0.5591],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04923285 0.03821865 0.11870938 0.21627439 0.0746959  0.12682263
 0.2319463  0.1440999 ]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6249, -0.5791, -0.5959, -0.5680, -0.5804, -0.5958, -0.5729, -0.5645],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05319808 0.13291683 0.09496305 0.16604222 0.12954235 0.09513686
 0.1504183  0.1777823 ]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5541, -0.5957, -0.5904, -0.5887, -0.5618, -0.6502, -0.5219, -0.5526],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15724852 0.06843545 0.07615562 0.07868117 0.13484937 0.02302713
 0.29945358 0.16214916]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 31.242
key: ssim
value: 0.888
key: lpips
value: 0.062
key: facenet_l2
value: 0.412
key: adaface_l2
value: 0.593
ref_face_img: tensor([[[[-0.7725, -0.7725, -0.7725,  ..., -0.9843, -0.9843, -0.9843],
          [-0.7647, -0.7569, -0.7569,  ..., -0.9843, -0.9843, -0.9843],
          [-0.7490, -0.7490, -0.7412,  ..., -0.9843, -0.9843, -0.9843],
          ...,
          [-0.9373, -0.9373, -0.9373,  ..., -0.9686, -0.9686, -0.9686],
          [-0.9373, -0.9373, -0.9373,  ..., -0.9686, -0.9686, -0.9686],
          [-0.9373, -0.9373, -0.9373,  ..., -0.9686, -0.9686, -0.9686]],

         [[-0.8745, -0.8745, -0.8745,  ..., -0.9843, -0.9843, -0.9843],
          [-0.8745, -0.8745, -0.8745,  ..., -0.9843, -0.9843, -0.9843],
          [-0.8667, -0.8667, -0.8667,  ..., -0.9843, -0.9843, -0.9843],
          ...,
          [-0.9373, -0.9373, -0.9373,  ..., -0.9765, -0.9765, -0.9765],
          [-0.9373, -0.9373, -0.9373,  ..., -0.9765, -0.9765, -0.9765],
          [-0.9373, -0.9373, -0.9373,  ..., -0.9765, -0.9765, -0.9765]],

         [[-0.9608, -0.9608, -0.9608,  ..., -1.0000, -1.0000, -1.0000],
          [-0.9608, -0.9608, -0.9608,  ..., -1.0000, -1.0000, -1.0000],
          [-0.9608, -0.9608, -0.9529,  ..., -1.0000, -1.0000, -1.0000],
          ...,
          [-0.9451, -0.9451, -0.9451,  ..., -0.9922, -0.9922, -0.9922],
          [-0.9451, -0.9451, -0.9451,  ..., -0.9922, -0.9922, -0.9922],
          [-0.9451, -0.9451, -0.9451,  ..., -0.9922, -0.9922, -0.9922]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.96it/s, distance=252]  3%|▎         | 3/100 [00:00<00:14,  6.56it/s, distance=153]  5%|▌         | 5/100 [00:00<00:11,  8.36it/s, distance=144]  7%|▋         | 7/100 [00:00<00:09,  9.38it/s, distance=126]  9%|▉         | 9/100 [00:01<00:13,  6.56it/s, distance=100] 11%|█         | 11/100 [00:01<00:11,  7.72it/s, distance=94.7] 13%|█▎        | 13/100 [00:01<00:10,  8.62it/s, distance=83.7] 15%|█▌        | 15/100 [00:01<00:09,  9.33it/s, distance=73]   17%|█▋        | 17/100 [00:02<00:12,  6.88it/s, distance=59.5] 19%|█▉        | 19/100 [00:02<00:10,  7.85it/s, distance=55.7] 21%|██        | 21/100 [00:02<00:09,  8.65it/s, distance=52.2] 23%|██▎       | 23/100 [00:02<00:08,  9.31it/s, distance=47]   25%|██▌       | 25/100 [00:03<00:10,  6.87it/s, distance=46.9] 27%|██▋       | 27/100 [00:03<00:09,  7.82it/s, distance=42.7] 29%|██▉       | 29/100 [00:03<00:08,  8.61it/s, distance=42.1] 31%|███       | 31/100 [00:03<00:07,  9.27it/s, distance=41.2] 33%|███▎      | 33/100 [00:04<00:09,  6.93it/s, distance=40.6] 35%|███▌      | 35/100 [00:04<00:08,  7.86it/s, distance=39.7] 37%|███▋      | 37/100 [00:04<00:07,  8.65it/s, distance=37.7] 39%|███▉      | 39/100 [00:04<00:06,  9.30it/s, distance=37.1] 41%|████      | 41/100 [00:05<00:08,  6.93it/s, distance=33.3] 43%|████▎     | 43/100 [00:05<00:07,  7.86it/s, distance=34.3] 45%|████▌     | 45/100 [00:05<00:06,  8.64it/s, distance=33.1] 47%|████▋     | 47/100 [00:05<00:05,  9.29it/s, distance=31.7] 49%|████▉     | 49/100 [00:06<00:07,  6.92it/s, distance=31.4] 51%|█████     | 51/100 [00:06<00:06,  7.84it/s, distance=30.1] 53%|█████▎    | 53/100 [00:06<00:05,  8.63it/s, distance=29.5] 55%|█████▌    | 55/100 [00:06<00:04,  9.29it/s, distance=28.9] 57%|█████▋    | 57/100 [00:07<00:06,  6.93it/s, distance=28.5] 59%|█████▉    | 59/100 [00:07<00:05,  7.86it/s, distance=27.8] 61%|██████    | 61/100 [00:07<00:04,  8.65it/s, distance=27.5] 63%|██████▎   | 63/100 [00:07<00:03,  9.29it/s, distance=27.2] 65%|██████▌   | 65/100 [00:08<00:05,  6.92it/s, distance=26.6] 67%|██████▋   | 67/100 [00:08<00:04,  7.85it/s, distance=26.2] 69%|██████▉   | 69/100 [00:08<00:03,  8.64it/s, distance=25.9] 71%|███████   | 71/100 [00:08<00:03,  9.28it/s, distance=25.6] 73%|███████▎  | 73/100 [00:09<00:03,  6.91it/s, distance=25.3] 75%|███████▌  | 75/100 [00:09<00:03,  7.84it/s, distance=25]   77%|███████▋  | 77/100 [00:09<00:02,  8.63it/s, distance=24.7] 79%|███████▉  | 79/100 [00:09<00:02,  9.27it/s, distance=24.4] 81%|████████  | 81/100 [00:10<00:02,  6.91it/s, distance=24.1] 83%|████████▎ | 83/100 [00:10<00:02,  7.85it/s, distance=23.7] 85%|████████▌ | 85/100 [00:10<00:01,  8.63it/s, distance=23.4] 87%|████████▋ | 87/100 [00:10<00:01,  9.28it/s, distance=23]   89%|████████▉ | 89/100 [00:11<00:01,  6.91it/s, distance=22.6] 91%|█████████ | 91/100 [00:11<00:01,  7.84it/s, distance=22.1] 93%|█████████▎| 93/100 [00:11<00:00,  8.63it/s, distance=21.6] 95%|█████████▌| 95/100 [00:11<00:00,  9.28it/s, distance=20.9] 97%|█████████▋| 97/100 [00:11<00:00,  9.81it/s, distance=19.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.20it/s, distance=18]  100%|██████████| 100/100 [00:12<00:00,  8.19it/s, distance=14.9]
2025-06-18 20:40:55,662 [MPGD] >> Inference for image 47
reward_name: adaface, curr_reward: tensor([-1.9700e+00, -5.1200e+08, -5.1200e+08, -1.9624e+00, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9269, -1.8262, -1.5970, -1.7502, -1.9612, -1.6707, -1.8100, -1.8863],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [1.04408641e-03 7.83829583e-03 7.66170755e-01 3.57952251e-02
 5.25844430e-04 1.75450330e-01 1.08237458e-02 2.35171758e-03]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5253, -1.5401, -1.6487, -1.5531, -1.7335, -1.5957, -1.5459, -1.6025],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.28270761 0.2101207  0.02396844 0.16208728 0.00439628 0.06910364
 0.187288   0.06032804]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4776, -1.3757, -1.4489, -1.3906, -1.3620, -1.3502, -1.3998, -1.5306],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02264585 0.17404914 0.04027454 0.1291893  0.22877672 0.2897696
 0.10744547 0.00784938]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1405, -1.3550, -1.1512, -1.1979, -1.1677, -1.1764, -1.2388, -1.2249],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.28331444 0.00388453 0.22845556 0.08982762 0.16428325 0.13821958
 0.03962201 0.05239301]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0130, -1.0826, -1.1364, -1.0893, -0.9547, -1.0540, -1.0254, -0.9916],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13294068 0.03310397 0.01128939 0.02890624 0.42729137 0.05860197
 0.10384    0.20402638]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9850, -0.9969, -0.8745, -0.9534, -1.0024, -0.8417, -0.8704, -0.9127],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0221182  0.01743458 0.20164019 0.04160779 0.01561236 0.38858203
 0.2190465  0.09395836]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7894, -0.7161, -0.8540, -0.7496, -0.7667, -0.8170, -0.7571, -0.7267],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0649587  0.28134622 0.01787082 0.14398593 0.10240195 0.03740535
 0.12408065 0.22795038]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6511, -0.5935, -0.6229, -0.6258, -0.5487, -0.7044, -0.6008, -0.5871],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04543239 0.14391117 0.07982096 0.07531119 0.35210264 0.01566534
 0.12433048 0.16342583]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5228, -0.5383, -0.5212, -0.5146, -0.4904, -0.4710, -0.4968, -0.4878],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08084548 0.05923348 0.08350936 0.095133   0.15457694 0.22789217
 0.13606491 0.16274467]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4583, -0.4542, -0.4881, -0.4466, -0.4454, -0.4457, -0.4791, -0.4406],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11679427 0.1267222  0.0644148  0.14744402 0.15105688 0.15025274
 0.07701865 0.16629643]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4809, -0.4782, -0.4777, -0.4685, -0.4768, -0.4468, -0.4311, -0.4379],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07974687 0.08417597 0.0850606  0.10220181 0.08654859 0.15777402
 0.21606853 0.18842361]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.825
key: ssim
value: 0.830
key: lpips
value: 0.152
key: facenet_l2
value: 0.341
key: adaface_l2
value: 0.568
ref_face_img: tensor([[[[-0.2941, -0.2941, -0.3020,  ..., -0.4353, -0.4353, -0.4275],
          [-0.2941, -0.2941, -0.3020,  ..., -0.4353, -0.4353, -0.4275],
          [-0.2941, -0.2941, -0.3020,  ..., -0.4353, -0.4353, -0.4275],
          ...,
          [-0.4980, -0.4980, -0.4902,  ..., -0.6549, -0.6549, -0.6549],
          [-0.4902, -0.4902, -0.4902,  ..., -0.6471, -0.6471, -0.6471],
          [-0.4902, -0.4902, -0.4902,  ..., -0.6392, -0.6392, -0.6392]],

         [[-0.3020, -0.3020, -0.3020,  ..., -0.4353, -0.4353, -0.4353],
          [-0.3020, -0.3020, -0.3020,  ..., -0.4353, -0.4353, -0.4353],
          [-0.3020, -0.3020, -0.3020,  ..., -0.4353, -0.4353, -0.4353],
          ...,
          [-0.4902, -0.4902, -0.4902,  ..., -0.6549, -0.6549, -0.6549],
          [-0.4824, -0.4824, -0.4824,  ..., -0.6549, -0.6549, -0.6471],
          [-0.4824, -0.4824, -0.4824,  ..., -0.6471, -0.6471, -0.6471]],

         [[-0.2549, -0.2549, -0.2549,  ..., -0.4196, -0.4196, -0.4196],
          [-0.2549, -0.2549, -0.2549,  ..., -0.4196, -0.4196, -0.4196],
          [-0.2549, -0.2549, -0.2549,  ..., -0.4196, -0.4196, -0.4196],
          ...,
          [-0.4431, -0.4431, -0.4431,  ..., -0.6392, -0.6392, -0.6392],
          [-0.4431, -0.4431, -0.4431,  ..., -0.6392, -0.6392, -0.6392],
          [-0.4431, -0.4431, -0.4431,  ..., -0.6314, -0.6314, -0.6314]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.88it/s, distance=359]  3%|▎         | 3/100 [00:00<00:15,  6.45it/s, distance=126]  5%|▌         | 5/100 [00:00<00:11,  8.27it/s, distance=105]  7%|▋         | 7/100 [00:00<00:09,  9.32it/s, distance=100]  9%|▉         | 9/100 [00:01<00:13,  6.50it/s, distance=76]  11%|█         | 11/100 [00:01<00:11,  7.66it/s, distance=74.4] 13%|█▎        | 13/100 [00:01<00:10,  8.58it/s, distance=68]   15%|█▌        | 15/100 [00:01<00:09,  9.29it/s, distance=57.8] 17%|█▋        | 17/100 [00:02<00:12,  6.85it/s, distance=48.4] 19%|█▉        | 19/100 [00:02<00:10,  7.84it/s, distance=45.9] 21%|██        | 21/100 [00:02<00:09,  8.64it/s, distance=44.6] 23%|██▎       | 23/100 [00:02<00:08,  9.31it/s, distance=41]   25%|██▌       | 25/100 [00:03<00:10,  6.95it/s, distance=39.5] 27%|██▋       | 27/100 [00:03<00:09,  7.88it/s, distance=38.1] 29%|██▉       | 29/100 [00:03<00:08,  8.67it/s, distance=35.6] 31%|███       | 31/100 [00:03<00:07,  9.32it/s, distance=34.7] 33%|███▎      | 33/100 [00:04<00:09,  6.94it/s, distance=32.4] 35%|███▌      | 35/100 [00:04<00:08,  7.88it/s, distance=31.8] 37%|███▋      | 37/100 [00:04<00:07,  8.66it/s, distance=31.3] 39%|███▉      | 39/100 [00:04<00:06,  9.31it/s, distance=30.4] 41%|████      | 41/100 [00:05<00:08,  6.93it/s, distance=30.2] 43%|████▎     | 43/100 [00:05<00:07,  7.87it/s, distance=29.5] 45%|████▌     | 45/100 [00:05<00:06,  8.65it/s, distance=29.2] 47%|████▋     | 47/100 [00:05<00:05,  9.30it/s, distance=28.6] 49%|████▉     | 49/100 [00:06<00:07,  6.93it/s, distance=28.3] 51%|█████     | 51/100 [00:06<00:06,  7.86it/s, distance=27.8] 53%|█████▎    | 53/100 [00:06<00:05,  8.65it/s, distance=27.5] 55%|█████▌    | 55/100 [00:06<00:04,  9.30it/s, distance=27.1] 57%|█████▋    | 57/100 [00:07<00:06,  6.88it/s, distance=26.7] 59%|█████▉    | 59/100 [00:07<00:05,  7.81it/s, distance=26.5] 61%|██████    | 61/100 [00:07<00:04,  8.61it/s, distance=26.3] 63%|██████▎   | 63/100 [00:07<00:03,  9.26it/s, distance=26]   65%|██████▌   | 65/100 [00:08<00:05,  6.85it/s, distance=25.6] 67%|██████▋   | 67/100 [00:08<00:04,  7.79it/s, distance=25.4] 69%|██████▉   | 69/100 [00:08<00:03,  8.58it/s, distance=25.1] 71%|███████   | 71/100 [00:08<00:03,  9.25it/s, distance=24.9] 73%|███████▎  | 73/100 [00:09<00:03,  6.85it/s, distance=24.6] 75%|███████▌  | 75/100 [00:09<00:03,  7.80it/s, distance=24.4] 77%|███████▋  | 77/100 [00:09<00:02,  8.59it/s, distance=24.1] 79%|███████▉  | 79/100 [00:09<00:02,  9.26it/s, distance=23.8] 81%|████████  | 81/100 [00:10<00:02,  6.83it/s, distance=23.6] 83%|████████▎ | 83/100 [00:10<00:02,  7.78it/s, distance=23.3] 85%|████████▌ | 85/100 [00:10<00:01,  8.58it/s, distance=23]   87%|████████▋ | 87/100 [00:10<00:01,  9.24it/s, distance=22.7] 89%|████████▉ | 89/100 [00:11<00:01,  6.85it/s, distance=22.4] 91%|█████████ | 91/100 [00:11<00:01,  7.80it/s, distance=22]   93%|█████████▎| 93/100 [00:11<00:00,  8.59it/s, distance=21.5] 95%|█████████▌| 95/100 [00:11<00:00,  9.25it/s, distance=20.9] 97%|█████████▋| 97/100 [00:11<00:00,  9.77it/s, distance=20]   99%|█████████▉| 99/100 [00:12<00:00, 10.17it/s, distance=18.3]100%|██████████| 100/100 [00:12<00:00,  8.17it/s, distance=15.7]
2025-06-18 20:41:09,236 [MPGD] >> Inference for image 48
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -1.8352e+00, -1.8349e+00, -2.0350e+00, -5.1200e+08,
        -5.1200e+08, -1.8675e+00, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8604, -1.8797, -1.6863, -1.8949, -1.9692, -1.7209, -1.8738, -1.6710],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0104151  0.00707423 0.33850368 0.0052217  0.00118192 0.16972665
 0.00797072 0.459906  ]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4613, -1.5056, -1.4538, -1.4501, -1.5005, -1.5039, -1.4967, -1.4548],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1577492  0.06504372 0.18313492 0.19750683 0.07203884 0.06722097
 0.07765835 0.17964716]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2105, -1.2376, -1.2278, -1.1488, -1.2191, -1.1653, -1.2810, -1.1737],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08796119 0.0511893  0.06231366 0.30216166 0.07405319 0.21732393
 0.02148619 0.18351088]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8877, -0.8183, -0.9311, -0.8388, -0.8308, -0.8539, -0.7772, -0.8900],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04300419 0.17221417 0.01806383 0.11446366 0.13425668 0.08460545
 0.39233597 0.04105605]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7320, -0.6081, -0.6299, -0.6686, -0.6208, -0.6080, -0.6944, -0.7219],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02054442 0.24450948 0.15823037 0.07291837 0.18980009 0.24526968
 0.04358546 0.02514211]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6101, -0.6581, -0.5927, -0.5908, -0.4989, -0.6468, -0.5870, -0.5305],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04881132 0.01868996 0.06904189 0.07182088 0.450995   0.02341039
 0.07743993 0.23979063]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5320, -0.5509, -0.5852, -0.5405, -0.5440, -0.5068, -0.5108, -0.5219],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12407043 0.08500562 0.04283338 0.10452214 0.09747267 0.20511345
 0.18935167 0.15163063]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4957, -0.5266, -0.5133, -0.5111, -0.5428, -0.5110, -0.5260, -0.4979],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17834036 0.09609397 0.12542472 0.13121907 0.06960827 0.13144373
 0.09725645 0.17061343]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4799, -0.5359, -0.4834, -0.5153, -0.4693, -0.4771, -0.5104, -0.5414],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16999869 0.05545746 0.15866382 0.08380661 0.21002019 0.17995325
 0.09238211 0.04971787]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4635, -0.4542, -0.4610, -0.4478, -0.4723, -0.4999, -0.4791, -0.4526],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12634319 0.15188618 0.13261162 0.17273164 0.10592305 0.06096864
 0.09247896 0.15705674]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4292, -0.4808, -0.4440, -0.4414, -0.4515, -0.4166, -0.4346, -0.4482],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15645403 0.05576544 0.1162944  0.12256425 0.10009164 0.20136408
 0.140565   0.10690116]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 31.820
key: ssim
value: 0.821
key: lpips
value: 0.116
key: facenet_l2
value: 0.342
key: adaface_l2
value: 0.542
ref_face_img: tensor([[[[ 0.6627,  0.6627,  0.6627,  ...,  0.2627,  0.2627,  0.2627],
          [ 0.6941,  0.6941,  0.6941,  ...,  0.2941,  0.2941,  0.2941],
          [ 0.7176,  0.7176,  0.7176,  ...,  0.3255,  0.3333,  0.3255],
          ...,
          [-0.1059, -0.1137, -0.1059,  ..., -0.0824, -0.1373, -0.1216],
          [-0.1059, -0.1059, -0.1059,  ..., -0.0353, -0.1137, -0.1137],
          [-0.0980, -0.0980, -0.1137,  ..., -0.0510, -0.0980, -0.1059]],

         [[ 0.6392,  0.6392,  0.6392,  ...,  0.2392,  0.2392,  0.2392],
          [ 0.6706,  0.6706,  0.6706,  ...,  0.2706,  0.2706,  0.2706],
          [ 0.6941,  0.6941,  0.6941,  ...,  0.3020,  0.3098,  0.3020],
          ...,
          [-0.1451, -0.1529, -0.1451,  ..., -0.0824, -0.1373, -0.1216],
          [-0.1451, -0.1451, -0.1451,  ..., -0.0353, -0.1137, -0.1137],
          [-0.1373, -0.1373, -0.1529,  ..., -0.0510, -0.0980, -0.1059]],

         [[ 0.8667,  0.8667,  0.8667,  ...,  0.4745,  0.4745,  0.4745],
          [ 0.8980,  0.8980,  0.8980,  ...,  0.5137,  0.5137,  0.5216],
          [ 0.9216,  0.9216,  0.9216,  ...,  0.5451,  0.5529,  0.5451],
          ...,
          [-0.0980, -0.1059, -0.0980,  ..., -0.0039, -0.0588, -0.0431],
          [-0.0980, -0.0980, -0.0980,  ...,  0.0431, -0.0353, -0.0353],
          [-0.0902, -0.0902, -0.1059,  ...,  0.0275, -0.0196, -0.0275]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.98it/s, distance=342]  3%|▎         | 3/100 [00:00<00:14,  6.59it/s, distance=194]  5%|▌         | 5/100 [00:00<00:11,  8.38it/s, distance=135]  7%|▋         | 7/100 [00:00<00:09,  9.41it/s, distance=111]  9%|▉         | 9/100 [00:01<00:14,  6.42it/s, distance=96.6] 11%|█         | 11/100 [00:01<00:11,  7.59it/s, distance=86.3] 13%|█▎        | 13/100 [00:01<00:10,  8.51it/s, distance=80.5] 15%|█▌        | 15/100 [00:01<00:09,  9.24it/s, distance=75.5] 17%|█▋        | 17/100 [00:02<00:12,  6.72it/s, distance=69.8] 19%|█▉        | 19/100 [00:02<00:10,  7.70it/s, distance=69.4] 21%|██        | 21/100 [00:02<00:09,  8.54it/s, distance=66]   23%|██▎       | 23/100 [00:02<00:08,  9.23it/s, distance=62.5] 25%|██▌       | 25/100 [00:03<00:11,  6.80it/s, distance=58.4] 27%|██▋       | 27/100 [00:03<00:09,  7.76it/s, distance=56.5] 29%|██▉       | 29/100 [00:03<00:08,  8.56it/s, distance=54.5] 31%|███       | 31/100 [00:03<00:07,  9.24it/s, distance=52.7] 33%|███▎      | 33/100 [00:04<00:09,  6.76it/s, distance=49.9] 35%|███▌      | 35/100 [00:04<00:08,  7.71it/s, distance=49.5] 37%|███▋      | 37/100 [00:04<00:07,  8.52it/s, distance=47.7] 39%|███▉      | 39/100 [00:04<00:06,  9.21it/s, distance=45.8] 41%|████      | 41/100 [00:05<00:08,  6.77it/s, distance=44.5] 43%|████▎     | 43/100 [00:05<00:07,  7.71it/s, distance=42.8] 45%|████▌     | 45/100 [00:05<00:06,  8.52it/s, distance=41.5] 47%|████▋     | 47/100 [00:05<00:05,  9.19it/s, distance=40.5] 49%|████▉     | 49/100 [00:06<00:07,  6.76it/s, distance=39.7] 51%|█████     | 51/100 [00:06<00:06,  7.71it/s, distance=38.5] 53%|█████▎    | 53/100 [00:06<00:05,  8.52it/s, distance=37.4] 55%|█████▌    | 55/100 [00:06<00:04,  9.18it/s, distance=36.6] 57%|█████▋    | 57/100 [00:07<00:06,  6.77it/s, distance=36.1] 59%|█████▉    | 59/100 [00:07<00:05,  7.72it/s, distance=35.2] 61%|██████    | 61/100 [00:07<00:04,  8.52it/s, distance=34.4] 63%|██████▎   | 63/100 [00:07<00:04,  9.20it/s, distance=33.8] 65%|██████▌   | 65/100 [00:08<00:05,  6.76it/s, distance=33.3] 67%|██████▋   | 67/100 [00:08<00:04,  7.71it/s, distance=32.6] 69%|██████▉   | 69/100 [00:08<00:03,  8.53it/s, distance=32]   71%|███████   | 71/100 [00:08<00:03,  9.20it/s, distance=31.3] 73%|███████▎  | 73/100 [00:09<00:03,  6.78it/s, distance=30.7] 75%|███████▌  | 75/100 [00:09<00:03,  7.72it/s, distance=30.1] 77%|███████▋  | 77/100 [00:09<00:02,  8.52it/s, distance=29.5] 79%|███████▉  | 79/100 [00:09<00:02,  9.19it/s, distance=28.9] 81%|████████  | 81/100 [00:10<00:02,  6.76it/s, distance=28.3] 83%|████████▎ | 83/100 [00:10<00:02,  7.71it/s, distance=27.8] 85%|████████▌ | 85/100 [00:10<00:01,  8.52it/s, distance=27.2] 87%|████████▋ | 87/100 [00:10<00:01,  9.18it/s, distance=26.5] 89%|████████▉ | 89/100 [00:11<00:01,  6.75it/s, distance=25.9] 91%|█████████ | 91/100 [00:11<00:01,  7.71it/s, distance=25.2] 93%|█████████▎| 93/100 [00:11<00:00,  8.51it/s, distance=24.4] 95%|█████████▌| 95/100 [00:11<00:00,  9.19it/s, distance=23.5] 97%|█████████▋| 97/100 [00:12<00:00,  9.73it/s, distance=22.3] 99%|█████████▉| 99/100 [00:12<00:00, 10.15it/s, distance=20.3]100%|██████████| 100/100 [00:12<00:00,  8.08it/s, distance=17.7]
2025-06-18 20:41:22,919 [MPGD] >> Inference for image 49
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -1.9628e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -1.8703e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7228, -1.8019, -1.8303, -1.8917, -1.6279, -1.6192, -1.8211, -1.6589],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05079387 0.01042721 0.00591327 0.00173115 0.33866796 0.40326062
 0.00710048 0.18210544]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2990, -1.3971, -1.2224, -1.3188, -1.3577, -1.4614, -1.2998, -1.3514],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12305254 0.01730848 0.56971162 0.08281113 0.03804626 0.0047793
 0.12115103 0.04313964]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0520, -1.0178, -1.1535, -1.1299, -0.9785, -1.0546, -0.9877, -1.1209],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08006186 0.15869847 0.01052291 0.01685594 0.3482712  0.0760254
 0.28937732 0.02018689]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9498, -1.0328, -0.9286, -1.0010, -0.9159, -0.9254, -1.0797, -0.9352],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12359555 0.023525   0.18875607 0.04443048 0.24362413 0.20122681
 0.00919174 0.16565022]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0332, -0.9186, -0.9994, -1.0760, -0.9425, -1.0001, -0.8646, -0.9508],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01795584 0.17756867 0.03527947 0.00761973 0.11005339 0.03482681
 0.52340186 0.09329423]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8735, -0.9166, -0.8891, -0.9180, -0.9214, -0.8995, -0.9191, -0.9600],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.24246901 0.10248455 0.17761883 0.0996378  0.09313233 0.1442435
 0.09737574 0.04303823]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8016, -0.8253, -0.8515, -0.7204, -0.8303, -0.9113, -0.7901, -0.8905],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10907915 0.0679864  0.0401927  0.55326476 0.06150257 0.01217485
 0.13734974 0.01844984]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7114, -0.6994, -0.7234, -0.6768, -0.7015, -0.7089, -0.7235, -0.6389],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08073292 0.10277239 0.06355505 0.16133905 0.09847841 0.08489354
 0.06340983 0.34481881]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6668, -0.6722, -0.6357, -0.6083, -0.6320, -0.6691, -0.6424, -0.6357],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07445998 0.06682188 0.1385084  0.23988716 0.14935608 0.07108085
 0.12119186 0.13869379]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6584, -0.6352, -0.5982, -0.6265, -0.5680, -0.5962, -0.6145, -0.6086],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04447992 0.07068462 0.14823907 0.08413167 0.2709934  0.15406892
 0.10699916 0.12040325]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6057, -0.6335, -0.5766, -0.6147, -0.6069, -0.6356, -0.5737, -0.5846],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10926957 0.06267031 0.19559816 0.0914044  0.10670205 0.06014184
 0.20754312 0.16667054]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.979
key: ssim
value: 0.899
key: lpips
value: 0.086
key: facenet_l2
value: 0.247
key: adaface_l2
value: 0.534
ref_face_img: tensor([[[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          ...,
          [0.8980, 0.8745, 0.8510,  ..., 0.7255, 0.7255, 0.7255],
          [0.8980, 0.8824, 0.8588,  ..., 0.7255, 0.7255, 0.7255],
          [0.9059, 0.8902, 0.8667,  ..., 0.7255, 0.7255, 0.7255]],

         [[0.9922, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [0.9922, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [0.9922, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          ...,
          [0.8824, 0.8588, 0.8196,  ..., 0.8510, 0.8510, 0.8431],
          [0.8824, 0.8588, 0.8275,  ..., 0.8510, 0.8510, 0.8431],
          [0.8902, 0.8667, 0.8353,  ..., 0.8510, 0.8510, 0.8431]],

         [[0.9843, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [0.9843, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          [0.9843, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
          ...,
          [0.8431, 0.8118, 0.7725,  ..., 0.9765, 0.9686, 0.9608],
          [0.8510, 0.8196, 0.7804,  ..., 0.9765, 0.9686, 0.9608],
          [0.8510, 0.8353, 0.7961,  ..., 0.9765, 0.9686, 0.9608]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.94it/s, distance=234]  3%|▎         | 3/100 [00:00<00:14,  6.55it/s, distance=157]  5%|▌         | 5/100 [00:00<00:11,  8.35it/s, distance=145]  7%|▋         | 7/100 [00:00<00:09,  9.39it/s, distance=126]  9%|▉         | 9/100 [00:01<00:14,  6.49it/s, distance=119] 11%|█         | 11/100 [00:01<00:11,  7.66it/s, distance=101] 13%|█▎        | 13/100 [00:01<00:10,  8.57it/s, distance=91.7] 15%|█▌        | 15/100 [00:01<00:09,  9.28it/s, distance=83.9] 17%|█▋        | 17/100 [00:02<00:12,  6.82it/s, distance=71.8] 19%|█▉        | 19/100 [00:02<00:10,  7.80it/s, distance=65.3] 21%|██        | 21/100 [00:02<00:09,  8.61it/s, distance=63.9] 23%|██▎       | 23/100 [00:02<00:08,  9.28it/s, distance=57.8] 25%|██▌       | 25/100 [00:03<00:10,  6.86it/s, distance=56.9] 27%|██▋       | 27/100 [00:03<00:09,  7.81it/s, distance=51.6] 29%|██▉       | 29/100 [00:03<00:08,  8.61it/s, distance=48]   31%|███       | 31/100 [00:03<00:07,  9.27it/s, distance=46.2] 33%|███▎      | 33/100 [00:04<00:09,  6.85it/s, distance=44.6] 35%|███▌      | 35/100 [00:04<00:08,  7.79it/s, distance=43.5] 37%|███▋      | 37/100 [00:04<00:07,  8.59it/s, distance=42.7] 39%|███▉      | 39/100 [00:04<00:06,  9.25it/s, distance=41.3] 41%|████      | 41/100 [00:05<00:08,  6.84it/s, distance=40.3] 43%|████▎     | 43/100 [00:05<00:07,  7.78it/s, distance=38.8] 45%|████▌     | 45/100 [00:05<00:06,  8.58it/s, distance=38.1] 47%|████▋     | 47/100 [00:05<00:05,  9.24it/s, distance=36.7] 49%|████▉     | 49/100 [00:06<00:07,  6.85it/s, distance=36.4] 51%|█████     | 51/100 [00:06<00:06,  7.79it/s, distance=35.3] 53%|█████▎    | 53/100 [00:06<00:05,  8.59it/s, distance=34.6] 55%|█████▌    | 55/100 [00:06<00:04,  9.24it/s, distance=33.8] 57%|█████▋    | 57/100 [00:07<00:06,  6.87it/s, distance=33.1] 59%|█████▉    | 59/100 [00:07<00:05,  7.80it/s, distance=32.6] 61%|██████    | 61/100 [00:07<00:04,  8.60it/s, distance=32.1] 63%|██████▎   | 63/100 [00:07<00:04,  9.24it/s, distance=31.4] 65%|██████▌   | 65/100 [00:08<00:05,  6.86it/s, distance=30.9] 67%|██████▋   | 67/100 [00:08<00:04,  7.79it/s, distance=30.4] 69%|██████▉   | 69/100 [00:08<00:03,  8.59it/s, distance=29.9] 71%|███████   | 71/100 [00:08<00:03,  9.25it/s, distance=29.4] 73%|███████▎  | 73/100 [00:09<00:03,  6.86it/s, distance=29.1] 75%|███████▌  | 75/100 [00:09<00:03,  7.79it/s, distance=28.6] 77%|███████▋  | 77/100 [00:09<00:02,  8.59it/s, distance=28.1] 79%|███████▉  | 79/100 [00:09<00:02,  9.24it/s, distance=27.7] 81%|████████  | 81/100 [00:10<00:02,  6.86it/s, distance=27.2] 83%|████████▎ | 83/100 [00:10<00:02,  7.81it/s, distance=26.7] 85%|████████▌ | 85/100 [00:10<00:01,  8.60it/s, distance=26.2] 87%|████████▋ | 87/100 [00:10<00:01,  9.26it/s, distance=25.7] 89%|████████▉ | 89/100 [00:11<00:01,  6.86it/s, distance=25.2] 91%|█████████ | 91/100 [00:11<00:01,  7.80it/s, distance=24.5] 93%|█████████▎| 93/100 [00:11<00:00,  8.60it/s, distance=23.8] 95%|█████████▌| 95/100 [00:11<00:00,  9.25it/s, distance=23]   97%|█████████▋| 97/100 [00:12<00:00,  9.77it/s, distance=21.7] 99%|█████████▉| 99/100 [00:12<00:00, 10.18it/s, distance=19.5]100%|██████████| 100/100 [00:12<00:00,  8.15it/s, distance=16.3]
2025-06-18 20:41:36,340 [MPGD] >> Inference for image 50
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -1.9968e+00, -5.1200e+08, -5.1200e+08, -2.0983e+00,
        -5.1200e+08, -1.9511e+00, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6163, -1.7553, -1.9271, -1.8546, -2.0313, -1.7524, -1.8715, -2.0757],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [8.73526150e-01 5.42376927e-02 1.74365913e-03 7.43490594e-03
 2.17108875e-04 5.74514311e-02 5.29977781e-03 8.92742324e-05]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5429, -1.5931, -1.4825, -1.5979, -1.4803, -1.4847, -1.4378, -1.5296],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0471389  0.0172576  0.15750257 0.01568383 0.16476096 0.15097193
 0.38529243 0.06139178]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5243, -1.3770, -1.6229, -1.5880, -1.4586, -1.4820, -1.4953, -1.5122],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03380556 0.64362971 0.00470525 0.00945587 0.12596802 0.07891058
 0.06043208 0.04309294]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2468, -1.2974, -1.3551, -1.2725, -1.2436, -1.2751, -1.3868, -1.3862],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.26085221 0.09496287 0.02994818 0.15600347 0.2780617  0.14821459
 0.01587864 0.01607833]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0959, -1.1553, -1.1019, -1.0549, -1.0535, -1.1356, -1.0405, -1.0879],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08725842 0.02661845 0.07751069 0.19839396 0.20398075 0.03943737
 0.26439185 0.10240851]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9379, -0.9731, -0.9431, -0.9357, -1.0488, -0.9562, -0.9315, -0.9903],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17440773 0.08626587 0.15742454 0.18229695 0.0190158  0.12110939
 0.19828198 0.06119773]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8589, -0.8640, -0.7476, -0.7892, -0.7946, -0.8020, -0.8598, -0.8835],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04254314 0.03840099 0.39340509 0.17144455 0.15383558 0.13262379
 0.04177353 0.02597334]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7450, -0.6172, -0.7072, -0.6766, -0.6591, -0.6841, -0.6920, -0.7319],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03019566 0.38969137 0.06440361 0.11874396 0.16840263 0.10213726
 0.08719585 0.03922966]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6612, -0.6675, -0.5843, -0.6523, -0.5740, -0.6106, -0.6539, -0.6931],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0559198  0.04929241 0.2605177  0.06679319 0.3195068  0.15373337
 0.06466956 0.02956718]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5459, -0.5883, -0.5672, -0.6070, -0.5312, -0.5776, -0.5650, -0.5453],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16817357 0.07207842 0.10994718 0.04956849 0.22567491 0.08922571
 0.11488616 0.17044557]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5158, -0.5018, -0.5330, -0.4923, -0.5479, -0.5164, -0.4906, -0.5183],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11424863 0.15120649 0.08094272 0.18268242 0.06007361 0.11282117
 0.18928142 0.10874353]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 32.157
key: ssim
value: 0.858
key: lpips
value: 0.100
key: facenet_l2
value: 0.235
key: adaface_l2
value: 0.478
ref_face_img: tensor([[[[-0.9529, -0.9529, -0.9529,  ..., -0.7725, -0.7725, -0.7725],
          [-0.9529, -0.9529, -0.9529,  ..., -0.7725, -0.7725, -0.7725],
          [-0.9529, -0.9529, -0.9529,  ..., -0.7725, -0.7725, -0.7725],
          ...,
          [-0.8980, -0.8980, -0.8980,  ..., -0.7647, -0.7647, -0.7647],
          [-0.8902, -0.8902, -0.8980,  ..., -0.7647, -0.7647, -0.7647],
          [-0.8902, -0.8902, -0.8902,  ..., -0.7647, -0.7647, -0.7647]],

         [[-0.9451, -0.9451, -0.9451,  ...,  0.0824,  0.0824,  0.0667],
          [-0.9451, -0.9451, -0.9451,  ...,  0.0824,  0.0824,  0.0667],
          [-0.9451, -0.9451, -0.9451,  ...,  0.0824,  0.0824,  0.0667],
          ...,
          [-0.8980, -0.8980, -0.8980,  ..., -0.7647, -0.7647, -0.7647],
          [-0.8902, -0.8902, -0.8980,  ..., -0.7647, -0.7647, -0.7647],
          [-0.8902, -0.8902, -0.8902,  ..., -0.7647, -0.7647, -0.7647]],

         [[-0.9451, -0.9529, -0.9529,  ..., -0.0353, -0.0353, -0.0510],
          [-0.9451, -0.9529, -0.9529,  ..., -0.0353, -0.0353, -0.0510],
          [-0.9451, -0.9529, -0.9529,  ..., -0.0353, -0.0353, -0.0510],
          ...,
          [-0.8980, -0.8980, -0.8980,  ..., -0.7490, -0.7490, -0.7490],
          [-0.8902, -0.8902, -0.8902,  ..., -0.7490, -0.7490, -0.7569],
          [-0.8902, -0.8902, -0.8902,  ..., -0.7490, -0.7569, -0.7569]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.99it/s, distance=319]  3%|▎         | 3/100 [00:00<00:14,  6.59it/s, distance=160]  5%|▌         | 5/100 [00:00<00:11,  8.39it/s, distance=117]  7%|▋         | 7/100 [00:00<00:09,  9.41it/s, distance=110]  9%|▉         | 9/100 [00:01<00:14,  6.46it/s, distance=84]  11%|█         | 11/100 [00:01<00:11,  7.63it/s, distance=75.5] 13%|█▎        | 13/100 [00:01<00:10,  8.55it/s, distance=72.5] 15%|█▌        | 15/100 [00:01<00:09,  9.28it/s, distance=71.3] 17%|█▋        | 17/100 [00:02<00:12,  6.74it/s, distance=61.2] 19%|█▉        | 19/100 [00:02<00:10,  7.72it/s, distance=57]   21%|██        | 21/100 [00:02<00:09,  8.55it/s, distance=50.5] 23%|██▎       | 23/100 [00:02<00:08,  9.23it/s, distance=47.5] 25%|██▌       | 25/100 [00:03<00:11,  6.80it/s, distance=44.5] 27%|██▋       | 27/100 [00:03<00:09,  7.75it/s, distance=43.3] 29%|██▉       | 29/100 [00:03<00:08,  8.55it/s, distance=40.9] 31%|███       | 31/100 [00:03<00:07,  9.22it/s, distance=39.3] 33%|███▎      | 33/100 [00:04<00:09,  6.83it/s, distance=37.7] 35%|███▌      | 35/100 [00:04<00:08,  7.77it/s, distance=37.3] 37%|███▋      | 37/100 [00:04<00:07,  8.57it/s, distance=36.2] 39%|███▉      | 39/100 [00:04<00:06,  9.23it/s, distance=35.4] 41%|████      | 41/100 [00:05<00:08,  6.85it/s, distance=34.3] 43%|████▎     | 43/100 [00:05<00:07,  7.79it/s, distance=33.8] 45%|████▌     | 45/100 [00:05<00:06,  8.59it/s, distance=33.1] 47%|████▋     | 47/100 [00:05<00:05,  9.25it/s, distance=32.7] 49%|████▉     | 49/100 [00:06<00:07,  6.83it/s, distance=32.4] 51%|█████     | 51/100 [00:06<00:06,  7.77it/s, distance=31.6] 53%|█████▎    | 53/100 [00:06<00:05,  8.57it/s, distance=30.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.24it/s, distance=30.5] 57%|█████▋    | 57/100 [00:07<00:06,  6.80it/s, distance=30.2] 59%|█████▉    | 59/100 [00:07<00:05,  7.74it/s, distance=29.8] 61%|██████    | 61/100 [00:07<00:04,  8.55it/s, distance=29.4] 63%|██████▎   | 63/100 [00:07<00:04,  9.22it/s, distance=29]   65%|██████▌   | 65/100 [00:08<00:05,  6.81it/s, distance=28.6] 67%|██████▋   | 67/100 [00:08<00:04,  7.76it/s, distance=28.2] 69%|██████▉   | 69/100 [00:08<00:03,  8.55it/s, distance=27.9] 71%|███████   | 71/100 [00:08<00:03,  9.22it/s, distance=27.5] 73%|███████▎  | 73/100 [00:09<00:03,  6.80it/s, distance=27.3] 75%|███████▌  | 75/100 [00:09<00:03,  7.74it/s, distance=26.8] 77%|███████▋  | 77/100 [00:09<00:02,  8.55it/s, distance=26.5] 79%|███████▉  | 79/100 [00:09<00:02,  9.22it/s, distance=26]   81%|████████  | 81/100 [00:10<00:02,  6.81it/s, distance=25.7] 83%|████████▎ | 83/100 [00:10<00:02,  7.76it/s, distance=25.3] 85%|████████▌ | 85/100 [00:10<00:01,  8.56it/s, distance=24.9] 87%|████████▋ | 87/100 [00:10<00:01,  9.23it/s, distance=24.4] 89%|████████▉ | 89/100 [00:11<00:01,  6.85it/s, distance=24]   91%|█████████ | 91/100 [00:11<00:01,  7.79it/s, distance=23.5] 93%|█████████▎| 93/100 [00:11<00:00,  8.59it/s, distance=22.8] 95%|█████████▌| 95/100 [00:11<00:00,  9.24it/s, distance=22.1] 97%|█████████▋| 97/100 [00:12<00:00,  9.76it/s, distance=21]   99%|█████████▉| 99/100 [00:12<00:00, 10.17it/s, distance=18.9]100%|██████████| 100/100 [00:12<00:00,  8.12it/s, distance=15.8]
2025-06-18 20:41:51,340 [MPGD] >> Inference for image 51
reward_name: adaface, curr_reward: tensor([-2.0081e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -1.9689e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0143, -2.0980, -1.7677, -2.0409, -1.9061, -1.8702, -1.9710, -1.9859],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00584231 0.00109574 0.81032973 0.00343275 0.05083869 0.10424471
 0.01389381 0.01032226]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5864, -1.5078, -1.4916, -1.6255, -1.5520, -1.5411, -1.3573, -1.4884],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00818474 0.03940918 0.05457761 0.00374299 0.01630312 0.02027209
 0.79932778 0.05818248]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2011, -1.2650, -1.3798, -1.3252, -1.3758, -1.3630, -1.4044, -1.3176],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.63546894 0.17689732 0.01778794 0.053011   0.01929761 0.02491252
 0.01089113 0.06173354]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1842, -1.1460, -1.1266, -1.1890, -1.1889, -1.1272, -1.1387, -1.3749],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0726388  0.15595186 0.22978069 0.06603227 0.06619101 0.22711838
 0.18068306 0.00160393]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8906, -1.0022, -0.9177, -1.2563, -1.1109, -1.0352, -1.1544, -0.9832],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [5.21127322e-01 5.59106670e-02 3.02851215e-01 3.46842965e-04
 6.36121415e-03 2.88935086e-02 2.66368415e-03 8.18455457e-02]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7676, -0.8417, -0.6715, -0.8022, -0.8852, -0.7651, -1.0018, -0.9315],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10249847 0.02328652 0.70052284 0.05128963 0.0097593  0.10782819
 0.00094728 0.00386777]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6722, -0.7750, -0.7002, -0.6963, -0.7422, -0.5990, -0.6248, -0.6483],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09027865 0.01153739 0.05151072 0.05577311 0.02227261 0.39024669
 0.23278444 0.14559639]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6150, -0.5596, -0.6802, -0.5662, -0.6133, -0.5055, -0.6259, -0.5778],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05041272 0.15264338 0.01368503 0.13379039 0.05220858 0.45046441
 0.04056902 0.10622647]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5889, -0.5729, -0.5426, -0.5440, -0.4963, -0.5206, -0.5605, -0.5643],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04751922 0.06543446 0.11982289 0.1166481  0.30288937 0.18625496
 0.08375838 0.07767263]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5279, -0.4902, -0.5926, -0.5715, -0.4445, -0.5013, -0.5044, -0.5006],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07066836 0.15027689 0.01937627 0.02955604 0.3747098  0.12040457
 0.1130759  0.12193218]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5121, -0.5057, -0.4550, -0.4432, -0.5215, -0.4574, -0.4625, -0.4761],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05614783 0.063855   0.17591502 0.22266697 0.04655509 0.16783379
 0.1515772  0.11544911]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 31.790
key: ssim
value: 0.852
key: lpips
value: 0.084
key: facenet_l2
value: 0.274
key: adaface_l2
value: 0.543
ref_face_img: tensor([[[[ 0.7412,  0.7412,  0.7412,  ...,  0.7020,  0.7020,  0.7020],
          [ 0.7412,  0.7412,  0.7412,  ...,  0.7020,  0.7020,  0.7020],
          [ 0.7412,  0.7412,  0.7412,  ...,  0.7020,  0.7020,  0.7020],
          ...,
          [-0.9059, -0.9059, -0.9059,  ..., -0.6863, -0.6706, -0.6549],
          [-0.8980, -0.9059, -0.9059,  ..., -0.6863, -0.6706, -0.6549],
          [-0.8980, -0.9059, -0.9059,  ..., -0.6863, -0.6627, -0.6549]],

         [[ 0.7412,  0.7412,  0.7412,  ...,  0.7020,  0.7020,  0.7020],
          [ 0.7412,  0.7412,  0.7412,  ...,  0.7020,  0.7020,  0.7020],
          [ 0.7412,  0.7412,  0.7412,  ...,  0.7020,  0.7020,  0.7020],
          ...,
          [-0.9216, -0.9137, -0.9137,  ..., -0.7020, -0.6784, -0.6706],
          [-0.9137, -0.9137, -0.9137,  ..., -0.7020, -0.6784, -0.6706],
          [-0.9137, -0.9137, -0.9137,  ..., -0.6941, -0.6784, -0.6627]],

         [[ 0.7725,  0.7725,  0.7725,  ...,  0.7020,  0.7020,  0.7020],
          [ 0.7725,  0.7725,  0.7725,  ...,  0.7020,  0.7020,  0.7020],
          [ 0.7725,  0.7725,  0.7725,  ...,  0.7020,  0.7020,  0.7020],
          ...,
          [-0.9451, -0.9451, -0.9373,  ..., -0.7176, -0.6941, -0.6863],
          [-0.9373, -0.9451, -0.9451,  ..., -0.7176, -0.6941, -0.6784],
          [-0.9373, -0.9373, -0.9451,  ..., -0.7098, -0.6941, -0.6784]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:36,  2.71it/s, distance=315]  3%|▎         | 3/100 [00:00<00:15,  6.18it/s, distance=148]  5%|▌         | 5/100 [00:00<00:11,  8.05it/s, distance=130]  7%|▋         | 7/100 [00:00<00:10,  9.16it/s, distance=119]  9%|▉         | 9/100 [00:01<00:14,  6.37it/s, distance=106] 11%|█         | 11/100 [00:01<00:11,  7.53it/s, distance=89.1] 13%|█▎        | 13/100 [00:01<00:10,  8.47it/s, distance=74.2] 15%|█▌        | 15/100 [00:01<00:09,  9.20it/s, distance=68.5] 17%|█▋        | 17/100 [00:02<00:12,  6.68it/s, distance=57.2] 19%|█▉        | 19/100 [00:02<00:10,  7.68it/s, distance=60.4] 21%|██        | 21/100 [00:02<00:09,  8.51it/s, distance=55.2] 23%|██▎       | 23/100 [00:02<00:08,  9.20it/s, distance=51.9] 25%|██▌       | 25/100 [00:03<00:11,  6.69it/s, distance=45.3] 27%|██▋       | 27/100 [00:03<00:09,  7.66it/s, distance=45.3] 29%|██▉       | 29/100 [00:03<00:08,  8.48it/s, distance=41.6] 31%|███       | 31/100 [00:03<00:07,  9.17it/s, distance=40.5] 33%|███▎      | 33/100 [00:04<00:09,  6.73it/s, distance=40.4] 35%|███▌      | 35/100 [00:04<00:08,  7.68it/s, distance=38.3] 37%|███▋      | 37/100 [00:04<00:07,  8.50it/s, distance=36.7] 39%|███▉      | 39/100 [00:04<00:06,  9.17it/s, distance=35.3] 41%|████      | 41/100 [00:05<00:08,  6.73it/s, distance=33.9] 43%|████▎     | 43/100 [00:05<00:07,  7.68it/s, distance=33.7] 45%|████▌     | 45/100 [00:05<00:06,  8.49it/s, distance=32.8] 47%|████▋     | 47/100 [00:05<00:05,  9.18it/s, distance=32.3] 49%|████▉     | 49/100 [00:06<00:07,  6.76it/s, distance=31.8] 51%|█████     | 51/100 [00:06<00:06,  7.71it/s, distance=31.1] 53%|█████▎    | 53/100 [00:06<00:05,  8.52it/s, distance=30.7] 55%|█████▌    | 55/100 [00:06<00:04,  9.19it/s, distance=30.2] 57%|█████▋    | 57/100 [00:07<00:06,  6.70it/s, distance=29.9] 59%|█████▉    | 59/100 [00:07<00:05,  7.65it/s, distance=29.4] 61%|██████    | 61/100 [00:07<00:04,  8.47it/s, distance=29]   63%|██████▎   | 63/100 [00:07<00:04,  9.15it/s, distance=28.6] 65%|██████▌   | 65/100 [00:08<00:05,  6.66it/s, distance=28.1] 67%|██████▋   | 67/100 [00:08<00:04,  7.62it/s, distance=27.9] 69%|██████▉   | 69/100 [00:08<00:03,  8.43it/s, distance=27.6] 71%|███████   | 71/100 [00:08<00:03,  9.12it/s, distance=27.2] 73%|███████▎  | 73/100 [00:09<00:04,  6.61it/s, distance=26.9] 75%|███████▌  | 75/100 [00:09<00:03,  7.57it/s, distance=26.6] 77%|███████▋  | 77/100 [00:09<00:02,  8.39it/s, distance=26.2] 79%|███████▉  | 79/100 [00:10<00:02,  9.10it/s, distance=25.9] 81%|████████  | 81/100 [00:10<00:02,  6.58it/s, distance=25.6] 83%|████████▎ | 83/100 [00:10<00:02,  7.54it/s, distance=25.2] 85%|████████▌ | 85/100 [00:10<00:01,  8.37it/s, distance=24.8] 87%|████████▋ | 87/100 [00:11<00:01,  9.07it/s, distance=24.3] 89%|████████▉ | 89/100 [00:11<00:01,  6.61it/s, distance=23.9] 91%|█████████ | 91/100 [00:11<00:01,  7.57it/s, distance=23.4] 93%|█████████▎| 93/100 [00:11<00:00,  8.40it/s, distance=22.8] 95%|█████████▌| 95/100 [00:12<00:00,  9.09it/s, distance=22]   97%|█████████▋| 97/100 [00:12<00:00,  9.65it/s, distance=20.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.09it/s, distance=18.8]100%|██████████| 100/100 [00:12<00:00,  7.99it/s, distance=15.7]
2025-06-18 20:42:05,110 [MPGD] >> Inference for image 52
reward_name: adaface, curr_reward: tensor([-2.0026e+00, -2.0202e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9199, -1.8795, -1.9715, -2.0524, -1.9501, -1.9533, -1.9826, -1.8794],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13777839 0.30879767 0.04902795 0.00973385 0.07525867 0.07063839
 0.03929229 0.30947279]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8077, -1.8075, -1.7209, -1.8735, -1.8022, -1.7649, -1.8035, -1.7942],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07241531 0.07260911 0.41091692 0.01939211 0.08080048 0.17034046
 0.07866712 0.09485849]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6642, -1.7038, -1.6672, -1.7122, -1.7431, -1.6435, -1.7019, -1.5801],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09668147 0.04382454 0.0911704  0.03700878 0.01995771 0.14627949
 0.04548369 0.51959392]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3555, -1.2972, -1.4069, -1.3232, -1.2579, -1.3163, -1.1806, -1.5388],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [2.04759134e-02 6.58334607e-02 7.32887809e-03 3.90867331e-02
 1.44257424e-01 4.48919724e-02 6.77601379e-01 5.24239291e-04]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9921, -1.0834, -1.0478, -1.1206, -1.0873, -1.2014, -1.0451, -0.9904],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.32152987 0.05178447 0.1055145  0.02460472 0.04792399 0.00488261
 0.11135507 0.33240478]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8954, -0.9058, -0.9757, -0.9117, -0.9302, -0.8556, -0.9355, -0.9084],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1500261  0.12175774 0.03010326 0.10824944 0.07485129 0.33219373
 0.06723873 0.1155797 ]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8037, -0.8619, -0.9373, -0.8478, -0.8661, -0.8139, -0.8723, -0.8320],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.26901631 0.08400725 0.01856713 0.11130764 0.07716052 0.21928995
 0.06816291 0.15248829]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7761, -0.7639, -0.8710, -0.7245, -0.8572, -0.7834, -0.7869, -0.7701],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12160896 0.15522066 0.01822336 0.34095014 0.02399832 0.10500463
 0.09786964 0.1371243 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7795, -0.6734, -0.7628, -0.8177, -0.7746, -0.6814, -0.7064, -0.7299],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03785122 0.31572295 0.05284314 0.01762956 0.0417538  0.26893639
 0.16318711 0.10207582]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6909, -0.7552, -0.6589, -0.7115, -0.7578, -0.7650, -0.6919, -0.7205],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1706989  0.04720477 0.3236767  0.11310597 0.04479291 0.03880339
 0.16728678 0.09443058]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7312, -0.6717, -0.6616, -0.7180, -0.7221, -0.7038, -0.7775, -0.7210],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07070525 0.23198419 0.28391478 0.09206123 0.08467569 0.1221019
 0.02800736 0.0865496 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.078
key: ssim
value: 0.844
key: lpips
value: 0.097
key: facenet_l2
value: 0.265
key: adaface_l2
value: 0.645
ref_face_img: tensor([[[[-0.9216, -0.9216, -0.9216,  ..., -0.9922, -0.9922, -0.9922],
          [-0.9294, -0.9216, -0.9216,  ..., -0.9922, -0.9922, -0.9922],
          [-0.9294, -0.9294, -0.9294,  ..., -0.9922, -0.9922, -0.9922],
          ...,
          [-0.9216, -0.9137, -0.9059,  ..., -0.7176, -0.7804, -0.8196],
          [-0.9216, -0.9137, -0.8980,  ..., -0.7020, -0.7725, -0.8196],
          [-0.9059, -0.8980, -0.8902,  ..., -0.6941, -0.7647, -0.8039]],

         [[ 0.0510,  0.0510,  0.0510,  ..., -0.2784, -0.2784, -0.2784],
          [ 0.0588,  0.0588,  0.0510,  ..., -0.2784, -0.2784, -0.2784],
          [ 0.0667,  0.0588,  0.0588,  ..., -0.2784, -0.2784, -0.2784],
          ...,
          [ 0.1451,  0.1451,  0.1373,  ..., -0.0353, -0.0510, -0.0588],
          [ 0.1451,  0.1373,  0.1373,  ..., -0.0353, -0.0431, -0.0510],
          [ 0.1451,  0.1451,  0.1451,  ..., -0.0353, -0.0431, -0.0510]],

         [[ 0.7647,  0.7647,  0.7647,  ...,  0.5451,  0.5451,  0.5451],
          [ 0.7725,  0.7725,  0.7725,  ...,  0.5451,  0.5451,  0.5451],
          [ 0.7804,  0.7804,  0.7725,  ...,  0.5451,  0.5451,  0.5451],
          ...,
          [ 0.8275,  0.8275,  0.8196,  ...,  0.5373,  0.5765,  0.6078],
          [ 0.8275,  0.8275,  0.8196,  ...,  0.5294,  0.5686,  0.6078],
          [ 0.8275,  0.8275,  0.8196,  ...,  0.5216,  0.5686,  0.6000]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.94it/s, distance=242]  3%|▎         | 3/100 [00:00<00:14,  6.54it/s, distance=160]  5%|▌         | 5/100 [00:00<00:11,  8.35it/s, distance=140]  7%|▋         | 7/100 [00:00<00:09,  9.38it/s, distance=123]  9%|▉         | 9/100 [00:01<00:13,  6.58it/s, distance=112] 11%|█         | 11/100 [00:01<00:11,  7.73it/s, distance=97.3] 13%|█▎        | 13/100 [00:01<00:10,  8.64it/s, distance=85.9] 15%|█▌        | 15/100 [00:01<00:09,  9.33it/s, distance=75.9] 17%|█▋        | 17/100 [00:02<00:12,  6.88it/s, distance=63.3] 19%|█▉        | 19/100 [00:02<00:10,  7.85it/s, distance=59.3] 21%|██        | 21/100 [00:02<00:09,  8.66it/s, distance=55.7] 23%|██▎       | 23/100 [00:02<00:08,  9.32it/s, distance=50.8] 25%|██▌       | 25/100 [00:03<00:10,  6.95it/s, distance=48.8] 27%|██▋       | 27/100 [00:03<00:09,  7.89it/s, distance=46.5] 29%|██▉       | 29/100 [00:03<00:08,  8.67it/s, distance=45.6] 31%|███       | 31/100 [00:03<00:07,  9.32it/s, distance=44.4] 33%|███▎      | 33/100 [00:04<00:09,  7.00it/s, distance=40.5] 35%|███▌      | 35/100 [00:04<00:08,  7.93it/s, distance=40.2] 37%|███▋      | 37/100 [00:04<00:07,  8.70it/s, distance=39.5] 39%|███▉      | 39/100 [00:04<00:06,  9.33it/s, distance=38.4] 41%|████      | 41/100 [00:05<00:08,  7.00it/s, distance=37.9] 43%|████▎     | 43/100 [00:05<00:07,  7.93it/s, distance=36.1] 45%|████▌     | 45/100 [00:05<00:06,  8.70it/s, distance=35.1] 47%|████▋     | 47/100 [00:05<00:05,  9.34it/s, distance=34.4] 49%|████▉     | 49/100 [00:06<00:07,  7.02it/s, distance=34.5] 51%|█████     | 51/100 [00:06<00:06,  7.94it/s, distance=33]   53%|█████▎    | 53/100 [00:06<00:05,  8.72it/s, distance=32.1] 55%|█████▌    | 55/100 [00:06<00:04,  9.37it/s, distance=31.6] 57%|█████▋    | 57/100 [00:07<00:06,  7.02it/s, distance=31.1] 59%|█████▉    | 59/100 [00:07<00:05,  7.95it/s, distance=30.5] 61%|██████    | 61/100 [00:07<00:04,  8.72it/s, distance=29.9] 63%|██████▎   | 63/100 [00:07<00:03,  9.35it/s, distance=29.3] 65%|██████▌   | 65/100 [00:08<00:04,  7.02it/s, distance=28.8] 67%|██████▋   | 67/100 [00:08<00:04,  7.95it/s, distance=28.4] 69%|██████▉   | 69/100 [00:08<00:03,  8.71it/s, distance=28]   71%|███████   | 71/100 [00:08<00:03,  9.35it/s, distance=27.6] 73%|███████▎  | 73/100 [00:09<00:03,  7.03it/s, distance=27.2] 75%|███████▌  | 75/100 [00:09<00:03,  7.95it/s, distance=26.8] 77%|███████▋  | 77/100 [00:09<00:02,  8.72it/s, distance=26.4] 79%|███████▉  | 79/100 [00:09<00:02,  9.35it/s, distance=26]   81%|████████  | 81/100 [00:10<00:02,  7.02it/s, distance=25.7] 83%|████████▎ | 83/100 [00:10<00:02,  7.94it/s, distance=25.3] 85%|████████▌ | 85/100 [00:10<00:01,  8.73it/s, distance=24.8] 87%|████████▋ | 87/100 [00:10<00:01,  9.36it/s, distance=24.4] 89%|████████▉ | 89/100 [00:11<00:01,  7.01it/s, distance=23.8] 91%|█████████ | 91/100 [00:11<00:01,  7.94it/s, distance=23.3] 93%|█████████▎| 93/100 [00:11<00:00,  8.70it/s, distance=22.7] 95%|█████████▌| 95/100 [00:11<00:00,  9.34it/s, distance=21.9] 97%|█████████▋| 97/100 [00:11<00:00,  9.86it/s, distance=20.8] 99%|█████████▉| 99/100 [00:12<00:00, 10.24it/s, distance=18.7]100%|██████████| 100/100 [00:12<00:00,  8.26it/s, distance=15.6]
2025-06-18 20:42:18,478 [MPGD] >> Inference for image 53
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -1.9142e+00, -5.1200e+08, -1.9937e+00,
        -5.1200e+08, -5.1200e+08, -1.9345e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0915, -2.0983, -2.0615, -2.0210, -2.1043, -2.0079, -1.9583, -2.0910],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03415426 0.02983707 0.06229127 0.14000748 0.02648151 0.18206373
 0.49064827 0.03451641]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7595, -1.8473, -1.8638, -1.7065, -1.9267, -1.7833, -1.6317, -1.7408],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05213246 0.00899867 0.00647865 0.15059198 0.00184178 0.03239879
 0.67172373 0.07583395]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5365, -1.5802, -1.5525, -1.5450, -1.5656, -1.6567, -1.4036, -1.5521],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05362212 0.02239595 0.03892221 0.04521658 0.02998028 0.00484994
 0.76578645 0.03922648]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4241, -1.4457, -1.3285, -1.4105, -1.3776, -1.3166, -1.4423, -1.2540],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01937703 0.01258194 0.13121969 0.02545921 0.04912798 0.16645208
 0.0134593  0.58232277]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3559, -1.3064, -1.1665, -1.2492, -1.2497, -1.2377, -1.3117, -1.2393],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01135748 0.03056738 0.50164242 0.09606678 0.09500468 0.12078634
 0.02750221 0.1170727 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1197, -1.1730, -1.1697, -1.0781, -1.1537, -1.1292, -1.1422, -1.1769],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15861066 0.05466023 0.05834798 0.36491113 0.0804188  0.13128084
 0.10124744 0.05052292]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0475, -1.0444, -1.1042, -1.0977, -0.9497, -1.0499, -1.0423, -1.0130],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07205314 0.07666646 0.02319376 0.02638753 0.50957439 0.06863808
 0.07993862 0.14354802]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9112, -0.9670, -0.9173, -0.8948, -0.9580, -0.9668, -0.9637, -0.9209],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.18195312 0.05960485 0.16097241 0.25277531 0.07135137 0.05983458
 0.06370643 0.14980194]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8846, -0.9085, -0.8920, -0.8869, -0.9365, -0.8824, -0.9417, -0.9160],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17566834 0.10896704 0.15152486 0.16780315 0.06230191 0.18375974
 0.05615853 0.09381643]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8869, -0.8976, -0.8826, -0.9212, -0.9298, -0.8740, -0.9208, -0.9324],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16591886 0.13386576 0.18059646 0.08359627 0.07035889 0.21477542
 0.0841832  0.06670514]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8859, -0.9024, -0.8715, -0.8883, -0.9143, -0.8642, -0.8682, -0.9032],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12118857 0.08719444 0.1617115  0.1154477  0.06865686 0.18718333
 0.1728344  0.0857832 ]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.490
key: ssim
value: 0.862
key: lpips
value: 0.083
key: facenet_l2
value: 0.507
key: adaface_l2
value: 0.642
ref_face_img: tensor([[[[ 0.6863,  0.6863,  0.6863,  ...,  0.7412,  0.7412,  0.7412],
          [ 0.6863,  0.6863,  0.6863,  ...,  0.7412,  0.7412,  0.7412],
          [ 0.6863,  0.6863,  0.6863,  ...,  0.7412,  0.7412,  0.7333],
          ...,
          [-0.1765, -0.1765, -0.1765,  ..., -0.0745, -0.0824, -0.0902],
          [-0.1765, -0.1765, -0.1843,  ..., -0.0745, -0.0824, -0.0824],
          [-0.1765, -0.1765, -0.1843,  ..., -0.0745, -0.0745, -0.0824]],

         [[ 0.7255,  0.7255,  0.7255,  ...,  0.7804,  0.7804,  0.7725],
          [ 0.7255,  0.7255,  0.7255,  ...,  0.7804,  0.7804,  0.7725],
          [ 0.7255,  0.7255,  0.7255,  ...,  0.7804,  0.7804,  0.7725],
          ...,
          [-0.3490, -0.3490, -0.3569,  ..., -0.3412, -0.3412, -0.3412],
          [-0.3569, -0.3647, -0.3647,  ..., -0.3333, -0.3412, -0.3412],
          [-0.3569, -0.3647, -0.3647,  ..., -0.3333, -0.3333, -0.3412]],

         [[ 0.7490,  0.7490,  0.7490,  ...,  0.8039,  0.8039,  0.7961],
          [ 0.7490,  0.7490,  0.7490,  ...,  0.8039,  0.8039,  0.7961],
          [ 0.7490,  0.7490,  0.7490,  ...,  0.8039,  0.8039,  0.7961],
          ...,
          [-0.4902, -0.4824, -0.4980,  ..., -0.5294, -0.5373, -0.5373],
          [-0.4980, -0.4980, -0.5059,  ..., -0.5294, -0.5294, -0.5294],
          [-0.4980, -0.4980, -0.5059,  ..., -0.5216, -0.5294, -0.5294]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.98it/s, distance=318]  3%|▎         | 3/100 [00:00<00:14,  6.61it/s, distance=199]  5%|▌         | 5/100 [00:00<00:11,  8.39it/s, distance=163]  7%|▋         | 7/100 [00:00<00:09,  9.41it/s, distance=134]  9%|▉         | 9/100 [00:01<00:14,  6.50it/s, distance=117] 11%|█         | 11/100 [00:01<00:11,  7.66it/s, distance=102] 13%|█▎        | 13/100 [00:01<00:10,  8.58it/s, distance=90.9] 15%|█▌        | 15/100 [00:01<00:09,  9.29it/s, distance=85.3] 17%|█▋        | 17/100 [00:02<00:12,  6.76it/s, distance=85.3] 19%|█▉        | 19/100 [00:02<00:10,  7.74it/s, distance=71.8] 21%|██        | 21/100 [00:02<00:09,  8.58it/s, distance=66.7] 23%|██▎       | 23/100 [00:02<00:08,  9.25it/s, distance=62.6] 25%|██▌       | 25/100 [00:03<00:10,  6.84it/s, distance=60.2] 27%|██▋       | 27/100 [00:03<00:09,  7.78it/s, distance=58.1] 29%|██▉       | 29/100 [00:03<00:08,  8.59it/s, distance=55.5] 31%|███       | 31/100 [00:03<00:07,  9.26it/s, distance=53.4] 33%|███▎      | 33/100 [00:04<00:09,  6.86it/s, distance=50.9] 35%|███▌      | 35/100 [00:04<00:08,  7.80it/s, distance=49.2] 37%|███▋      | 37/100 [00:04<00:07,  8.60it/s, distance=48]   39%|███▉      | 39/100 [00:04<00:06,  9.26it/s, distance=45.6] 41%|████      | 41/100 [00:05<00:08,  6.85it/s, distance=45.1] 43%|████▎     | 43/100 [00:05<00:07,  7.80it/s, distance=43.2] 45%|████▌     | 45/100 [00:05<00:06,  8.59it/s, distance=41.8] 47%|████▋     | 47/100 [00:05<00:05,  9.26it/s, distance=40.4] 49%|████▉     | 49/100 [00:06<00:07,  6.87it/s, distance=39.9] 51%|█████     | 51/100 [00:06<00:06,  7.82it/s, distance=38.7] 53%|█████▎    | 53/100 [00:06<00:05,  8.60it/s, distance=37.7] 55%|█████▌    | 55/100 [00:06<00:04,  9.26it/s, distance=36.7] 57%|█████▋    | 57/100 [00:07<00:06,  6.87it/s, distance=36]   59%|█████▉    | 59/100 [00:07<00:05,  7.80it/s, distance=35.2] 61%|██████    | 61/100 [00:07<00:04,  8.60it/s, distance=34.6] 63%|██████▎   | 63/100 [00:07<00:04,  9.25it/s, distance=33.9] 65%|██████▌   | 65/100 [00:08<00:05,  6.87it/s, distance=33.1] 67%|██████▋   | 67/100 [00:08<00:04,  7.80it/s, distance=32.4] 69%|██████▉   | 69/100 [00:08<00:03,  8.60it/s, distance=31.6] 71%|███████   | 71/100 [00:08<00:03,  9.26it/s, distance=31.1] 73%|███████▎  | 73/100 [00:09<00:03,  6.86it/s, distance=30.4] 75%|███████▌  | 75/100 [00:09<00:03,  7.80it/s, distance=29.9] 77%|███████▋  | 77/100 [00:09<00:02,  8.59it/s, distance=29.4] 79%|███████▉  | 79/100 [00:09<00:02,  9.25it/s, distance=28.8] 81%|████████  | 81/100 [00:10<00:02,  6.86it/s, distance=28.3] 83%|████████▎ | 83/100 [00:10<00:02,  7.81it/s, distance=27.8] 85%|████████▌ | 85/100 [00:10<00:01,  8.59it/s, distance=27.3] 87%|████████▋ | 87/100 [00:10<00:01,  9.26it/s, distance=26.6] 89%|████████▉ | 89/100 [00:11<00:01,  6.88it/s, distance=26.2] 91%|█████████ | 91/100 [00:11<00:01,  7.82it/s, distance=25.5] 93%|█████████▎| 93/100 [00:11<00:00,  8.62it/s, distance=24.7] 95%|█████████▌| 95/100 [00:11<00:00,  9.27it/s, distance=23.7] 97%|█████████▋| 97/100 [00:12<00:00,  9.79it/s, distance=22.4] 99%|█████████▉| 99/100 [00:12<00:00, 10.20it/s, distance=20]  100%|██████████| 100/100 [00:12<00:00,  8.15it/s, distance=16.8]
2025-06-18 20:42:31,834 [MPGD] >> Inference for image 54
reward_name: adaface, curr_reward: tensor([-1.9584e+00, -5.1200e+08, -5.1200e+08, -1.9869e+00, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9726, -2.0459, -2.1916, -2.0184, -2.1202, -1.9897, -2.0601, -2.1018],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.37650477 0.08691521 0.00471783 0.15074352 0.01969965 0.26750319
 0.06546342 0.02845241]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5390, -1.5758, -1.6690, -1.7818, -1.6313, -1.7351, -1.7696, -1.6752],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.55133354 0.26396268 0.04095557 0.00429052 0.08692507 0.01091872
 0.00546928 0.03614461]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3542, -1.4484, -1.4288, -1.4696, -1.4391, -1.3004, -1.1977, -1.4183],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03606982 0.00548378 0.00810645 0.00358746 0.00660551 0.10573303
 0.8244033  0.01001065]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1653, -1.2180, -1.1809, -1.1323, -1.1430, -1.0531, -1.1465, -1.1338],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05454619 0.01901668 0.03992178 0.10542614 0.08512904 0.5141275
 0.0794306  0.10240206]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9424, -0.9269, -1.0056, -1.0110, -0.9289, -1.0230, -0.9857, -1.0009],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.19454644 0.2652812  0.05495613 0.04932478 0.25481934 0.03883683
 0.08182387 0.0604114 ]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9148, -0.8630, -0.8948, -0.8902, -0.9163, -0.7799, -0.9411, -0.8541],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03743353 0.10537901 0.05579321 0.06126829 0.03629664 0.55561615
 0.02210539 0.12610777]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8154, -0.8131, -0.7794, -0.7861, -0.7798, -0.7938, -0.8199, -0.8219],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08871427 0.09298365 0.18243974 0.15939903 0.1807469  0.13664548
 0.08116978 0.07790116]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8059, -0.8827, -0.8247, -0.7864, -0.8487, -0.8780, -0.8212, -0.8346],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.18732674 0.04029991 0.12855331 0.276416   0.07958044 0.04430787
 0.13797457 0.10554118]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7949, -0.8341, -0.8186, -0.8005, -0.7875, -0.7689, -0.7710, -0.8315],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12641697 0.05771325 0.07868414 0.11307621 0.14650327 0.21276653
 0.20401688 0.06082275]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8158, -0.7402, -0.7450, -0.7544, -0.7811, -0.7691, -0.7523, -0.7619],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04147601 0.18801909 0.17078184 0.14160191 0.08303165 0.10550868
 0.14765698 0.12192384]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7095, -0.7385, -0.8324, -0.7539, -0.7588, -0.7409, -0.7697, -0.7299],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.2545087  0.14255494 0.02180724 0.10478968 0.09495338 0.13577895
 0.07638353 0.16922358]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 25.167
key: ssim
value: 0.880
key: lpips
value: 0.052
key: facenet_l2
value: 0.495
key: adaface_l2
value: 0.673
ref_face_img: tensor([[[[ 0.4980,  0.4431,  0.3647,  ...,  0.2392,  0.2392,  0.2392],
          [ 0.4902,  0.4431,  0.3647,  ...,  0.2392,  0.2392,  0.2392],
          [ 0.4902,  0.4275,  0.3490,  ...,  0.2392,  0.2471,  0.2471],
          ...,
          [ 0.1529,  0.1686,  0.1686,  ..., -0.7882, -0.7804, -0.7725],
          [ 0.1686,  0.1765,  0.1765,  ..., -0.7882, -0.7804, -0.7725],
          [ 0.1529,  0.1843,  0.2157,  ..., -0.7882, -0.7804, -0.7725]],

         [[ 0.4902,  0.4431,  0.3647,  ...,  0.2078,  0.2078,  0.2000],
          [ 0.4824,  0.4353,  0.3647,  ...,  0.2078,  0.2078,  0.2000],
          [ 0.4824,  0.4275,  0.3490,  ...,  0.2078,  0.2157,  0.2078],
          ...,
          [ 0.1451,  0.1608,  0.1608,  ..., -0.7882, -0.7882, -0.7804],
          [ 0.1608,  0.1686,  0.1686,  ..., -0.7882, -0.7882, -0.7804],
          [ 0.1451,  0.1765,  0.2078,  ..., -0.7882, -0.7882, -0.7804]],

         [[ 0.5294,  0.4588,  0.3804,  ...,  0.2157,  0.2157,  0.2157],
          [ 0.5216,  0.4588,  0.3804,  ...,  0.2157,  0.2157,  0.2157],
          [ 0.5216,  0.4431,  0.3647,  ...,  0.2157,  0.2235,  0.2157],
          ...,
          [ 0.1843,  0.2000,  0.2000,  ..., -0.7961, -0.8039, -0.7961],
          [ 0.2000,  0.2078,  0.2078,  ..., -0.7961, -0.8039, -0.7961],
          [ 0.1843,  0.2157,  0.2471,  ..., -0.7961, -0.8039, -0.7961]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.96it/s, distance=236]  3%|▎         | 3/100 [00:00<00:14,  6.57it/s, distance=165]  5%|▌         | 5/100 [00:00<00:11,  8.37it/s, distance=149]  7%|▋         | 7/100 [00:00<00:09,  9.39it/s, distance=126]  9%|▉         | 9/100 [00:01<00:13,  6.51it/s, distance=118] 11%|█         | 11/100 [00:01<00:11,  7.66it/s, distance=100] 13%|█▎        | 13/100 [00:01<00:10,  8.58it/s, distance=95.7] 15%|█▌        | 15/100 [00:01<00:09,  9.30it/s, distance=86.1] 17%|█▋        | 17/100 [00:02<00:12,  6.85it/s, distance=66.4] 19%|█▉        | 19/100 [00:02<00:10,  7.83it/s, distance=71]   21%|██        | 21/100 [00:02<00:09,  8.65it/s, distance=59.5] 23%|██▎       | 23/100 [00:02<00:08,  9.31it/s, distance=51.8] 25%|██▌       | 25/100 [00:03<00:10,  6.91it/s, distance=42.2] 27%|██▋       | 27/100 [00:03<00:09,  7.86it/s, distance=41.3] 29%|██▉       | 29/100 [00:03<00:08,  8.64it/s, distance=39.6] 31%|███       | 31/100 [00:03<00:07,  9.29it/s, distance=37.8] 33%|███▎      | 33/100 [00:04<00:09,  6.87it/s, distance=36.7] 35%|███▌      | 35/100 [00:04<00:08,  7.82it/s, distance=35.2] 37%|███▋      | 37/100 [00:04<00:07,  8.61it/s, distance=34.9] 39%|███▉      | 39/100 [00:04<00:06,  9.26it/s, distance=33.2] 41%|████      | 41/100 [00:05<00:08,  6.76it/s, distance=33.1] 43%|████▎     | 43/100 [00:05<00:07,  7.69it/s, distance=31.6] 45%|████▌     | 45/100 [00:05<00:06,  8.49it/s, distance=31]   47%|████▋     | 47/100 [00:05<00:05,  9.16it/s, distance=30.2] 49%|████▉     | 49/100 [00:06<00:07,  6.78it/s, distance=30]   51%|█████     | 51/100 [00:06<00:06,  7.73it/s, distance=29.2] 53%|█████▎    | 53/100 [00:06<00:05,  8.52it/s, distance=28.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.20it/s, distance=28.2] 57%|█████▋    | 57/100 [00:07<00:06,  6.79it/s, distance=27.8] 59%|█████▉    | 59/100 [00:07<00:05,  7.73it/s, distance=27.4] 61%|██████    | 61/100 [00:07<00:04,  8.54it/s, distance=27.2] 63%|██████▎   | 63/100 [00:07<00:04,  9.20it/s, distance=26.7] 65%|██████▌   | 65/100 [00:08<00:05,  6.83it/s, distance=26.4] 67%|██████▋   | 67/100 [00:08<00:04,  7.77it/s, distance=26.1] 69%|██████▉   | 69/100 [00:08<00:03,  8.57it/s, distance=25.8] 71%|███████   | 71/100 [00:08<00:03,  9.24it/s, distance=25.6] 73%|███████▎  | 73/100 [00:09<00:03,  6.83it/s, distance=25.2] 75%|███████▌  | 75/100 [00:09<00:03,  7.77it/s, distance=25]   77%|███████▋  | 77/100 [00:09<00:02,  8.56it/s, distance=24.6] 79%|███████▉  | 79/100 [00:09<00:02,  9.23it/s, distance=24.3] 81%|████████  | 81/100 [00:10<00:02,  6.81it/s, distance=23.9] 83%|████████▎ | 83/100 [00:10<00:02,  7.76it/s, distance=23.6] 85%|████████▌ | 85/100 [00:10<00:01,  8.55it/s, distance=23.2] 87%|████████▋ | 87/100 [00:10<00:01,  9.23it/s, distance=22.9] 89%|████████▉ | 89/100 [00:11<00:01,  6.79it/s, distance=22.5] 91%|█████████ | 91/100 [00:11<00:01,  7.72it/s, distance=22.1] 93%|█████████▎| 93/100 [00:11<00:00,  8.53it/s, distance=21.5] 95%|█████████▌| 95/100 [00:11<00:00,  9.19it/s, distance=20.9] 97%|█████████▋| 97/100 [00:12<00:00,  9.72it/s, distance=19.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.12it/s, distance=18]  100%|██████████| 100/100 [00:12<00:00,  8.12it/s, distance=14.9]
2025-06-18 20:42:45,463 [MPGD] >> Inference for image 55
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -1.8312e+00, -1.9746e+00, -1.9350e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8548, -1.8416, -1.8852, -2.0131, -1.8042, -1.8847, -2.0533, -1.9515],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15752321 0.20506915 0.0856656  0.00663435 0.43283144 0.08654713
 0.00297178 0.02275733]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7387, -1.6460, -1.7123, -1.6961, -1.8474, -1.7545, -1.7147, -1.8186],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07097673 0.45292652 0.12044183 0.16659193 0.00808057 0.05179402
 0.1148302  0.01435819]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4292, -1.2559, -1.3843, -1.3351, -1.3456, -1.3426, -1.3529, -1.3739],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01649118 0.52796183 0.04045962 0.10835284 0.08786102 0.09326429
 0.07581884 0.04979038]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0774, -1.1384, -1.0724, -1.1274, -1.0776, -1.1741, -1.1653, -1.1152],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.21968119 0.06482715 0.24282345 0.08084865 0.21909066 0.03177944
 0.03786154 0.10308792]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7782, -0.9229, -0.9136, -0.8997, -0.8583, -0.9510, -0.9609, -0.9423],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.66363935 0.03671458 0.04423003 0.05849459 0.1338746  0.02093192
 0.0171752  0.02493974]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6787, -0.7426, -0.7367, -0.7144, -0.6842, -0.7501, -0.7112, -0.7677],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.25605957 0.07135009 0.08019534 0.12534589 0.22905019 0.06137749
 0.13350959 0.04311183]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6074, -0.5923, -0.7456, -0.5986, -0.6277, -0.5763, -0.5713, -0.5719],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09771364 0.13217898 0.00616604 0.11666361 0.06512906 0.18224675
 0.20117528 0.19872664]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6045, -0.5789, -0.5689, -0.5797, -0.5251, -0.5036, -0.5838, -0.5945],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04652994 0.07756455 0.09474827 0.07635185 0.22754731 0.35012667
 0.07036821 0.0567632 ]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5461, -0.5146, -0.4683, -0.5432, -0.5503, -0.5195, -0.5099, -0.4542],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0509317  0.09553346 0.24126861 0.05390255 0.04674918 0.08662835
 0.10504898 0.31993717]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4809, -0.4407, -0.4621, -0.4726, -0.4311, -0.4962, -0.4599, -0.4704],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0827944  0.18508028 0.1206487  0.09785096 0.22437776 0.06096306
 0.1260724  0.10221244]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5110, -0.4786, -0.4494, -0.4895, -0.4780, -0.4744, -0.4748, -0.4447],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05643907 0.10790727 0.19359894 0.08680886 0.10910171 0.11732692
 0.11627077 0.21254646]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 32.044
key: ssim
value: 0.837
key: lpips
value: 0.129
key: facenet_l2
value: 0.368
key: adaface_l2
value: 0.558
ref_face_img: tensor([[[[-0.0980, -0.0980, -0.0980,  ..., -0.0824, -0.0824, -0.0824],
          [-0.0980, -0.0980, -0.0980,  ..., -0.0824, -0.0745, -0.0745],
          [-0.0980, -0.0980, -0.0980,  ..., -0.0667, -0.0667, -0.0667],
          ...,
          [-0.3255, -0.3255, -0.3412,  ...,  0.6627,  0.6627,  0.6627],
          [-0.3333, -0.3412, -0.3412,  ...,  0.6471,  0.6471,  0.6471],
          [-0.3412, -0.3412, -0.3333,  ...,  0.6392,  0.6392,  0.6392]],

         [[-0.0902, -0.0902, -0.0902,  ..., -0.0824, -0.0824, -0.0824],
          [-0.0902, -0.0902, -0.0902,  ..., -0.0745, -0.0745, -0.0745],
          [-0.0902, -0.0902, -0.0902,  ..., -0.0667, -0.0667, -0.0667],
          ...,
          [-0.3333, -0.3412, -0.3490,  ...,  0.4745,  0.4745,  0.4745],
          [-0.3412, -0.3569, -0.3569,  ...,  0.4588,  0.4667,  0.4667],
          [-0.3490, -0.3569, -0.3490,  ...,  0.4510,  0.4510,  0.4510]],

         [[-0.1373, -0.1373, -0.1373,  ..., -0.1373, -0.1373, -0.1373],
          [-0.1373, -0.1373, -0.1373,  ..., -0.1294, -0.1294, -0.1294],
          [-0.1373, -0.1373, -0.1373,  ..., -0.1216, -0.1216, -0.1216],
          ...,
          [-0.4118, -0.4118, -0.4275,  ...,  0.1922,  0.2000,  0.2000],
          [-0.4196, -0.4353, -0.4353,  ...,  0.1843,  0.1922,  0.1922],
          [-0.4275, -0.4353, -0.4353,  ...,  0.1765,  0.1843,  0.1843]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.92it/s, distance=263]  3%|▎         | 3/100 [00:00<00:14,  6.52it/s, distance=185]  5%|▌         | 5/100 [00:00<00:11,  8.32it/s, distance=153]  7%|▋         | 7/100 [00:00<00:09,  9.35it/s, distance=130]  9%|▉         | 9/100 [00:01<00:14,  6.46it/s, distance=112] 11%|█         | 11/100 [00:01<00:11,  7.62it/s, distance=94.5] 13%|█▎        | 13/100 [00:01<00:10,  8.53it/s, distance=85.7] 15%|█▌        | 15/100 [00:01<00:09,  9.26it/s, distance=83.9] 17%|█▋        | 17/100 [00:02<00:12,  6.79it/s, distance=74.3] 19%|█▉        | 19/100 [00:02<00:10,  7.77it/s, distance=67.1] 21%|██        | 21/100 [00:02<00:09,  8.59it/s, distance=66.8] 23%|██▎       | 23/100 [00:02<00:08,  9.27it/s, distance=64]   25%|██▌       | 25/100 [00:03<00:10,  6.88it/s, distance=71.3] 27%|██▋       | 27/100 [00:03<00:09,  7.82it/s, distance=57.6] 29%|██▉       | 29/100 [00:03<00:08,  8.61it/s, distance=54.5] 31%|███       | 31/100 [00:03<00:07,  9.27it/s, distance=52.6] 33%|███▎      | 33/100 [00:04<00:09,  6.95it/s, distance=50]   35%|███▌      | 35/100 [00:04<00:08,  7.88it/s, distance=48.7] 37%|███▋      | 37/100 [00:04<00:07,  8.66it/s, distance=47.5] 39%|███▉      | 39/100 [00:04<00:06,  9.30it/s, distance=45.9] 41%|████      | 41/100 [00:05<00:08,  6.94it/s, distance=43.8] 43%|████▎     | 43/100 [00:05<00:07,  7.87it/s, distance=42.8] 45%|████▌     | 45/100 [00:05<00:06,  8.65it/s, distance=41.9] 47%|████▋     | 47/100 [00:05<00:05,  9.29it/s, distance=40.8] 49%|████▉     | 49/100 [00:06<00:07,  6.92it/s, distance=39.5] 51%|█████     | 51/100 [00:06<00:06,  7.84it/s, distance=38.7] 53%|█████▎    | 53/100 [00:06<00:05,  8.62it/s, distance=37.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.25it/s, distance=37]   57%|█████▋    | 57/100 [00:07<00:06,  6.85it/s, distance=36.4] 59%|█████▉    | 59/100 [00:07<00:05,  7.78it/s, distance=35.6] 61%|██████    | 61/100 [00:07<00:04,  8.57it/s, distance=35.1] 63%|██████▎   | 63/100 [00:07<00:04,  9.21it/s, distance=34.3] 65%|██████▌   | 65/100 [00:08<00:05,  6.84it/s, distance=33.9] 67%|██████▋   | 67/100 [00:08<00:04,  7.77it/s, distance=33.2] 69%|██████▉   | 69/100 [00:08<00:03,  8.55it/s, distance=32.5] 71%|███████   | 71/100 [00:08<00:03,  9.21it/s, distance=31.8] 73%|███████▎  | 73/100 [00:09<00:03,  6.86it/s, distance=31.4] 75%|███████▌  | 75/100 [00:09<00:03,  7.80it/s, distance=30.7] 77%|███████▋  | 77/100 [00:09<00:02,  8.59it/s, distance=30.1] 79%|███████▉  | 79/100 [00:09<00:02,  9.24it/s, distance=29.5] 81%|████████  | 81/100 [00:10<00:02,  6.76it/s, distance=28.8] 83%|████████▎ | 83/100 [00:10<00:02,  7.71it/s, distance=28.2] 85%|████████▌ | 85/100 [00:10<00:01,  8.52it/s, distance=27.6] 87%|████████▋ | 87/100 [00:10<00:01,  9.18it/s, distance=27]   89%|████████▉ | 89/100 [00:11<00:01,  6.88it/s, distance=26.3] 91%|█████████ | 91/100 [00:11<00:01,  7.82it/s, distance=25.6] 93%|█████████▎| 93/100 [00:11<00:00,  8.62it/s, distance=24.8] 95%|█████████▌| 95/100 [00:11<00:00,  9.26it/s, distance=23.8] 97%|█████████▋| 97/100 [00:12<00:00,  9.78it/s, distance=22.5] 99%|█████████▉| 99/100 [00:12<00:00, 10.18it/s, distance=20.1]100%|██████████| 100/100 [00:12<00:00,  8.15it/s, distance=16.9]
2025-06-18 20:42:58,990 [MPGD] >> Inference for image 56
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -1.8974e+00, -5.1200e+08, -1.8327e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0411, -1.8793, -1.9347, -1.8539, -1.9027, -1.8473, -1.8852, -1.8293],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00429029 0.10920534 0.03600632 0.18124385 0.06832528 0.20713377
 0.09703227 0.29676288]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5166, -1.6156, -1.4703, -1.5810, -1.5075, -1.5192, -1.5462, -1.5571],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14117841 0.01948395 0.35637464 0.03891117 0.1692961  0.13387475
 0.07807248 0.06280849]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1371, -1.2263, -1.3783, -1.1959, -1.3225, -1.3424, -1.3556, -1.2737],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.62390686 0.10472701 0.00500796 0.19232352 0.01530165 0.01027193
 0.00788704 0.04057403]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0720, -1.0531, -1.0296, -0.9288, -1.0123, -1.0604, -1.0563, -0.9791],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02885251 0.04212207 0.06733769 0.50563137 0.0951889  0.0363609
 0.03948798 0.18501858]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9239, -0.8996, -0.9399, -1.0441, -0.8924, -0.9542, -0.9188, -0.9608],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13416927 0.21811697 0.09749537 0.01212658 0.25190193 0.07323486
 0.14876066 0.06419437]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8478, -0.7859, -0.8374, -0.8429, -0.8404, -0.7202, -0.7982, -0.7950],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03796564 0.13087759 0.04678243 0.04187293 0.04401586 0.48687547
 0.10241697 0.10919311]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6996, -0.6199, -0.6393, -0.6751, -0.6661, -0.6914, -0.6205, -0.6185],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04170989 0.20566767 0.13944586 0.06815895 0.08163504 0.04914136
 0.20293537 0.21130587]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5701, -0.5821, -0.5380, -0.5872, -0.5391, -0.4847, -0.5925, -0.5780],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07542161 0.05929025 0.14312539 0.05358553 0.14008061 0.41604042
 0.04810834 0.06434785]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5014, -0.4928, -0.5153, -0.5478, -0.4614, -0.4946, -0.4873, -0.4679],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10017435 0.11888133 0.07577642 0.03955138 0.22262457 0.1146484
 0.13276672 0.19557685]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4386, -0.4689, -0.4734, -0.4630, -0.4530, -0.4441, -0.4334, -0.4312],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15207746 0.08302906 0.07586336 0.09340746 0.11403155 0.13630866
 0.16871464 0.17656781]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.4442, -0.4330, -0.4267, -0.4004, -0.4320, -0.4408, -0.4409, -0.4731],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09949629 0.12440597 0.14130346 0.23892212 0.12714036 0.10661799
 0.10627291 0.0558409 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.791
key: ssim
value: 0.868
key: lpips
value: 0.083
key: facenet_l2
value: 0.249
key: adaface_l2
value: 0.461
ref_face_img: tensor([[[[0.5451, 0.5451, 0.5451,  ..., 0.7412, 0.7412, 0.7412],
          [0.5451, 0.5451, 0.5529,  ..., 0.7412, 0.7412, 0.7412],
          [0.5529, 0.5529, 0.5529,  ..., 0.7490, 0.7490, 0.7490],
          ...,
          [0.6941, 0.6941, 0.6941,  ..., 0.8431, 0.8510, 0.8588],
          [0.6941, 0.6941, 0.6941,  ..., 0.8431, 0.8588, 0.8667],
          [0.6941, 0.6941, 0.6941,  ..., 0.8431, 0.8510, 0.8588]],

         [[0.5373, 0.5373, 0.5373,  ..., 0.7333, 0.7333, 0.7333],
          [0.5373, 0.5373, 0.5451,  ..., 0.7333, 0.7333, 0.7333],
          [0.5451, 0.5451, 0.5451,  ..., 0.7412, 0.7412, 0.7412],
          ...,
          [0.6863, 0.6863, 0.6863,  ..., 0.8510, 0.8588, 0.8667],
          [0.6863, 0.6863, 0.6863,  ..., 0.8510, 0.8588, 0.8667],
          [0.6863, 0.6863, 0.6863,  ..., 0.8510, 0.8588, 0.8667]],

         [[0.5843, 0.5843, 0.5843,  ..., 0.7804, 0.7804, 0.7804],
          [0.5843, 0.5843, 0.5922,  ..., 0.7804, 0.7804, 0.7804],
          [0.5922, 0.5922, 0.5922,  ..., 0.7882, 0.7882, 0.7882],
          ...,
          [0.7333, 0.7333, 0.7333,  ..., 0.8824, 0.8902, 0.8980],
          [0.7333, 0.7333, 0.7333,  ..., 0.8824, 0.8902, 0.8980],
          [0.7333, 0.7333, 0.7333,  ..., 0.8824, 0.8902, 0.8980]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.93it/s, distance=283]  3%|▎         | 3/100 [00:00<00:14,  6.55it/s, distance=168]  5%|▌         | 5/100 [00:00<00:11,  8.35it/s, distance=143]  7%|▋         | 7/100 [00:00<00:09,  9.38it/s, distance=129]  9%|▉         | 9/100 [00:01<00:14,  6.49it/s, distance=126] 11%|█         | 11/100 [00:01<00:11,  7.65it/s, distance=101] 13%|█▎        | 13/100 [00:01<00:10,  8.56it/s, distance=87.3] 15%|█▌        | 15/100 [00:01<00:09,  9.27it/s, distance=80.2] 17%|█▋        | 17/100 [00:02<00:12,  6.79it/s, distance=72.2] 19%|█▉        | 19/100 [00:02<00:10,  7.77it/s, distance=65.5] 21%|██        | 21/100 [00:02<00:09,  8.59it/s, distance=58.8] 23%|██▎       | 23/100 [00:02<00:08,  9.25it/s, distance=55.3] 25%|██▌       | 25/100 [00:03<00:10,  6.83it/s, distance=56.1] 27%|██▋       | 27/100 [00:03<00:09,  7.77it/s, distance=50]   29%|██▉       | 29/100 [00:03<00:08,  8.57it/s, distance=48.9] 31%|███       | 31/100 [00:03<00:07,  9.24it/s, distance=46.6] 33%|███▎      | 33/100 [00:04<00:09,  6.79it/s, distance=45.1] 35%|███▌      | 35/100 [00:04<00:08,  7.74it/s, distance=43]   37%|███▋      | 37/100 [00:04<00:07,  8.54it/s, distance=42.3] 39%|███▉      | 39/100 [00:04<00:06,  9.21it/s, distance=41.2] 41%|████      | 41/100 [00:05<00:08,  6.84it/s, distance=39.7] 43%|████▎     | 43/100 [00:05<00:07,  7.77it/s, distance=38.6] 45%|████▌     | 45/100 [00:05<00:06,  8.58it/s, distance=37.8] 47%|████▋     | 47/100 [00:05<00:05,  9.24it/s, distance=36.5] 49%|████▉     | 49/100 [00:06<00:07,  6.88it/s, distance=36]   51%|█████     | 51/100 [00:06<00:06,  7.81it/s, distance=35] 53%|█████▎    | 53/100 [00:06<00:05,  8.61it/s, distance=34] 55%|█████▌    | 55/100 [00:06<00:04,  9.27it/s, distance=33.4] 57%|█████▋    | 57/100 [00:07<00:06,  6.88it/s, distance=33.1] 59%|█████▉    | 59/100 [00:07<00:05,  7.82it/s, distance=32]   61%|██████    | 61/100 [00:07<00:04,  8.61it/s, distance=31.4] 63%|██████▎   | 63/100 [00:07<00:03,  9.27it/s, distance=30.7] 65%|██████▌   | 65/100 [00:08<00:05,  6.88it/s, distance=30.2] 67%|██████▋   | 67/100 [00:08<00:04,  7.82it/s, distance=29.8] 69%|██████▉   | 69/100 [00:08<00:03,  8.61it/s, distance=29.3] 71%|███████   | 71/100 [00:08<00:03,  9.27it/s, distance=28.8] 73%|███████▎  | 73/100 [00:09<00:03,  6.86it/s, distance=28.3] 75%|███████▌  | 75/100 [00:09<00:03,  7.80it/s, distance=27.9] 77%|███████▋  | 77/100 [00:09<00:02,  8.59it/s, distance=27.5] 79%|███████▉  | 79/100 [00:09<00:02,  9.25it/s, distance=27]   81%|████████  | 81/100 [00:10<00:02,  6.81it/s, distance=26.6] 83%|████████▎ | 83/100 [00:10<00:02,  7.74it/s, distance=26.2] 85%|████████▌ | 85/100 [00:10<00:01,  8.55it/s, distance=25.7] 87%|████████▋ | 87/100 [00:10<00:01,  9.21it/s, distance=25.2] 89%|████████▉ | 89/100 [00:11<00:01,  6.86it/s, distance=24.8] 91%|█████████ | 91/100 [00:11<00:01,  7.79it/s, distance=24.1] 93%|█████████▎| 93/100 [00:11<00:00,  8.59it/s, distance=23.4] 95%|█████████▌| 95/100 [00:11<00:00,  9.25it/s, distance=22.5] 97%|█████████▋| 97/100 [00:12<00:00,  9.77it/s, distance=21.3] 99%|█████████▉| 99/100 [00:12<00:00, 10.17it/s, distance=19.1]100%|██████████| 100/100 [00:12<00:00,  8.14it/s, distance=16] 
2025-06-18 20:43:12,715 [MPGD] >> Inference for image 57
reward_name: adaface, curr_reward: tensor([-1.9078e+00, -2.0539e+00, -5.1200e+08, -5.1200e+08, -2.0921e+00,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9353, -1.9238, -1.8709, -1.9876, -2.0293, -1.9554, -1.9239, -1.8245],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05719547 0.07192051 0.20721239 0.02007598 0.00872422 0.03826924
 0.07187766 0.52472453]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5827, -1.6882, -1.6226, -1.5554, -1.6350, -1.5909, -1.5916, -1.6300],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17462958 0.02118689 0.07871765 0.30145601 0.06137579 0.14836769
 0.14639085 0.06787555]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2629, -1.3961, -1.4106, -1.3960, -1.3415, -1.2876, -1.2966, -1.3336],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.36205138 0.02519812 0.01886787 0.02526225 0.07516262 0.22092345
 0.18458906 0.08794526]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0910, -1.2514, -1.2865, -1.3048, -1.1864, -1.1677, -1.2690, -1.2793],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.67107892 0.0271502  0.01345485 0.00932841 0.09962273 0.14472388
 0.01909126 0.01554976]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0511, -0.8911, -0.8529, -0.9916, -1.0009, -0.9441, -1.0314, -1.1247],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01058922 0.25972285 0.55765243 0.03483945 0.02891327 0.09013036
 0.01571952 0.00243291]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8791, -0.8518, -0.6925, -0.7797, -0.7699, -0.7542, -0.7782, -0.7734],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01128406 0.01945937 0.47124458 0.08234732 0.10026319 0.13713882
 0.08492328 0.09333938]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6656, -0.6607, -0.6914, -0.6929, -0.6536, -0.6745, -0.6501, -0.6334],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11558173 0.12741103 0.06897198 0.06699644 0.14698194 0.09671671
 0.1574203  0.21991988]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6263, -0.6044, -0.5982, -0.5876, -0.5892, -0.6179, -0.5879, -0.5870],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0709076  0.10982755 0.12443837 0.15379719 0.14896309 0.08378
 0.15274221 0.155544  ]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5438, -0.5425, -0.5982, -0.5398, -0.5694, -0.5853, -0.4975, -0.5430],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12455466 0.12805054 0.04203259 0.13509731 0.0747365  0.05432528
 0.31446423 0.12673889]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5331, -0.4983, -0.4833, -0.5007, -0.5008, -0.4772, -0.5063, -0.4981],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0612584  0.12287155 0.16592427 0.11724389 0.11695869 0.18750915
 0.10470939 0.12352465]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5161, -0.5148, -0.5373, -0.5091, -0.5005, -0.4876, -0.5267, -0.4933],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10697945 0.10969491 0.0700489  0.12297142 0.14606714 0.18897258
 0.08645429 0.16881131]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.192
key: ssim
value: 0.841
key: lpips
value: 0.091
key: facenet_l2
value: 0.373
key: adaface_l2
value: 0.551
ref_face_img: tensor([[[[ 0.4196,  0.4196,  0.4196,  ...,  0.5373,  0.5373,  0.5373],
          [ 0.4196,  0.4196,  0.4196,  ...,  0.5373,  0.5373,  0.5373],
          [ 0.4275,  0.4275,  0.4275,  ...,  0.5373,  0.5373,  0.5373],
          ...,
          [ 0.5451,  0.5451,  0.5451,  ..., -0.0745, -0.0196,  0.0039],
          [ 0.5451,  0.5451,  0.5451,  ..., -0.1137, -0.0902, -0.0667],
          [ 0.5451,  0.5451,  0.5451,  ..., -0.1059, -0.0745, -0.0667]],

         [[-0.1137, -0.1137, -0.1137,  ...,  0.0824,  0.0745,  0.0667],
          [-0.1137, -0.1137, -0.1137,  ...,  0.0824,  0.0824,  0.0745],
          [-0.1137, -0.1137, -0.1059,  ...,  0.0824,  0.0824,  0.0745],
          ...,
          [-0.1765, -0.1765, -0.1765,  ..., -0.4745, -0.4510, -0.4353],
          [-0.1765, -0.1765, -0.1765,  ..., -0.5059, -0.4902, -0.4745],
          [-0.1765, -0.1765, -0.1765,  ..., -0.4902, -0.4824, -0.4667]],

         [[ 0.0980,  0.0980,  0.1059,  ...,  0.2627,  0.2627,  0.2549],
          [ 0.0980,  0.1059,  0.1059,  ...,  0.2627,  0.2627,  0.2627],
          [ 0.1059,  0.1059,  0.1059,  ...,  0.2627,  0.2627,  0.2627],
          ...,
          [ 0.1059,  0.1059,  0.1059,  ..., -0.3020, -0.2627, -0.2392],
          [ 0.1059,  0.1059,  0.1059,  ..., -0.3412, -0.3176, -0.2941],
          [ 0.1059,  0.1059,  0.1059,  ..., -0.3255, -0.3020, -0.2941]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.86it/s, distance=312]  3%|▎         | 3/100 [00:00<00:15,  6.43it/s, distance=145]  5%|▌         | 5/100 [00:00<00:11,  8.27it/s, distance=116]  7%|▋         | 7/100 [00:00<00:09,  9.31it/s, distance=108]  9%|▉         | 9/100 [00:01<00:14,  6.49it/s, distance=88.4] 11%|█         | 11/100 [00:01<00:11,  7.65it/s, distance=82.9] 13%|█▎        | 13/100 [00:01<00:10,  8.56it/s, distance=76.3] 15%|█▌        | 15/100 [00:01<00:09,  9.28it/s, distance=70.3] 17%|█▋        | 17/100 [00:02<00:12,  6.75it/s, distance=61.8] 19%|█▉        | 19/100 [00:02<00:10,  7.73it/s, distance=62]   21%|██        | 21/100 [00:02<00:09,  8.55it/s, distance=55.7] 23%|██▎       | 23/100 [00:02<00:08,  9.24it/s, distance=54]   25%|██▌       | 25/100 [00:03<00:11,  6.74it/s, distance=50.6] 27%|██▋       | 27/100 [00:03<00:09,  7.70it/s, distance=48.3] 29%|██▉       | 29/100 [00:03<00:08,  8.51it/s, distance=46.4] 31%|███       | 31/100 [00:03<00:07,  9.19it/s, distance=44.2] 33%|███▎      | 33/100 [00:04<00:09,  6.78it/s, distance=42.2] 35%|███▌      | 35/100 [00:04<00:08,  7.73it/s, distance=39.6] 37%|███▋      | 37/100 [00:04<00:07,  8.54it/s, distance=38.8] 39%|███▉      | 39/100 [00:04<00:06,  9.21it/s, distance=37.3] 41%|████      | 41/100 [00:05<00:08,  6.71it/s, distance=35.7] 43%|████▎     | 43/100 [00:05<00:07,  7.66it/s, distance=35.1] 45%|████▌     | 45/100 [00:05<00:06,  8.48it/s, distance=34.4] 47%|████▋     | 47/100 [00:05<00:05,  9.16it/s, distance=33.5] 49%|████▉     | 49/100 [00:06<00:07,  6.81it/s, distance=32.4] 51%|█████     | 51/100 [00:06<00:06,  7.76it/s, distance=32]   53%|█████▎    | 53/100 [00:06<00:05,  8.56it/s, distance=31.4] 55%|█████▌    | 55/100 [00:06<00:04,  9.23it/s, distance=30.9] 57%|█████▋    | 57/100 [00:07<00:06,  6.83it/s, distance=30.4] 59%|█████▉    | 59/100 [00:07<00:05,  7.78it/s, distance=29.9] 61%|██████    | 61/100 [00:07<00:04,  8.57it/s, distance=29.4] 63%|██████▎   | 63/100 [00:07<00:04,  9.23it/s, distance=28.9] 65%|██████▌   | 65/100 [00:08<00:05,  6.82it/s, distance=28.3] 67%|██████▋   | 67/100 [00:08<00:04,  7.76it/s, distance=28]   69%|██████▉   | 69/100 [00:08<00:03,  8.55it/s, distance=27.6] 71%|███████   | 71/100 [00:08<00:03,  9.22it/s, distance=27.3] 73%|███████▎  | 73/100 [00:09<00:03,  6.81it/s, distance=26.8] 75%|███████▌  | 75/100 [00:09<00:03,  7.75it/s, distance=26.5] 77%|███████▋  | 77/100 [00:09<00:02,  8.55it/s, distance=26.1] 79%|███████▉  | 79/100 [00:09<00:02,  9.21it/s, distance=25.7] 81%|████████  | 81/100 [00:10<00:02,  6.74it/s, distance=25.4] 83%|████████▎ | 83/100 [00:10<00:02,  7.69it/s, distance=25]   85%|████████▌ | 85/100 [00:10<00:01,  8.50it/s, distance=24.5] 87%|████████▋ | 87/100 [00:10<00:01,  9.19it/s, distance=24.1] 89%|████████▉ | 89/100 [00:11<00:01,  6.73it/s, distance=23.6] 91%|█████████ | 91/100 [00:11<00:01,  7.67it/s, distance=23.1] 93%|█████████▎| 93/100 [00:11<00:00,  8.48it/s, distance=22.5] 95%|█████████▌| 95/100 [00:11<00:00,  9.17it/s, distance=21.7] 97%|█████████▋| 97/100 [00:12<00:00,  9.71it/s, distance=20.7] 99%|█████████▉| 99/100 [00:12<00:00, 10.14it/s, distance=18.6]100%|██████████| 100/100 [00:12<00:00,  8.08it/s, distance=15.5]
2025-06-18 20:43:26,353 [MPGD] >> Inference for image 58
reward_name: adaface, curr_reward: tensor([-1.9700e+00, -2.1007e+00, -2.0143e+00, -1.9337e+00, -5.1200e+08,
        -2.0367e+00, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7502, -1.8410, -1.8844, -1.7564, -1.8221, -1.8808, -1.8071, -1.8918],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.35635856 0.05801944 0.02435214 0.31522759 0.08468764 0.02618045
 0.11419182 0.02098236]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3734, -1.5430, -1.4716, -1.4149, -1.3716, -1.4089, -1.5049, -1.4656],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.29675462 0.00999017 0.04168431 0.12942592 0.30760638 0.14614369
 0.02142754 0.04696737]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2860, -1.4278, -1.4077, -1.4011, -1.2852, -1.4064, -1.3750, -1.3652],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.36692538 0.02152289 0.03217573 0.03668005 0.37253873 0.03300295
 0.06183133 0.07532295]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1816, -1.2065, -1.2666, -1.1795, -1.3274, -1.2202, -1.2647, -1.1693],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.20743532 0.12629048 0.03792626 0.21637076 0.01125272 0.09591057
 0.03936671 0.26544718]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0661, -0.9646, -0.9943, -0.8542, -1.0079, -0.8871, -1.0279, -0.9242],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00712457 0.05422538 0.0299639  0.49331107 0.02282843 0.25556984
 0.01528818 0.12168863]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8667, -0.9374, -0.8682, -0.9149, -0.9099, -0.8176, -0.8820, -0.8922],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14229727 0.03459556 0.13829369 0.05433293 0.0600091  0.38015973
 0.10487771 0.08543401]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8118, -0.7033, -0.7693, -0.8305, -0.7209, -0.8872, -0.8100, -0.8217],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0476101  0.41681086 0.1111802  0.03273985 0.29280406 0.01053396
 0.04928709 0.03903389]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6195, -0.6505, -0.6963, -0.7325, -0.7277, -0.7057, -0.6601, -0.7188],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.36590281 0.19689139 0.07883963 0.0382133  0.04208422 0.06524338
 0.1626201  0.05020517]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5836, -0.6424, -0.7109, -0.6518, -0.6400, -0.6430, -0.6245, -0.6036],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.29557421 0.09126723 0.02318573 0.0755185  0.09579402 0.09012131
 0.1305031  0.19803589]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5769, -0.5608, -0.6224, -0.6704, -0.5987, -0.5968, -0.5393, -0.5665],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.13152347 0.18140478 0.05288728 0.02027065 0.08503662 0.08832022
 0.27889974 0.16165723]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5343, -0.5215, -0.5335, -0.5100, -0.5482, -0.5530, -0.5043, -0.5384],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.1096576  0.14158645 0.1113811  0.17823258 0.08302417 0.07541492
 0.19975665 0.10094654]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 28.393
key: ssim
value: 0.831
key: lpips
value: 0.127
key: facenet_l2
value: 0.272
key: adaface_l2
value: 0.513
ref_face_img: tensor([[[[ 0.1373,  0.0980,  0.0353,  ...,  0.1216,  0.0353, -0.0196],
          [ 0.0039, -0.0353, -0.0824,  ...,  0.1059,  0.0039, -0.0431],
          [-0.1765, -0.2314, -0.2549,  ...,  0.0902, -0.0118, -0.0588],
          ...,
          [ 0.1373,  0.0980,  0.0902,  ...,  0.2627,  0.2784,  0.3020],
          [ 0.2314,  0.2078,  0.2078,  ...,  0.2627,  0.2784,  0.3020],
          [ 0.2863,  0.2863,  0.2941,  ...,  0.2627,  0.2863,  0.2941]],

         [[ 0.2784,  0.2549,  0.2314,  ...,  0.2706,  0.2078,  0.1765],
          [ 0.2000,  0.1765,  0.1765,  ...,  0.2706,  0.2235,  0.1843],
          [ 0.1137,  0.0745,  0.0667,  ...,  0.2627,  0.2157,  0.1765],
          ...,
          [ 0.2784,  0.2549,  0.2706,  ...,  0.3255,  0.3176,  0.3333],
          [ 0.3333,  0.3255,  0.3333,  ...,  0.3255,  0.3176,  0.3333],
          [ 0.3804,  0.3804,  0.3961,  ...,  0.3255,  0.3255,  0.3255]],

         [[ 0.3255,  0.2941,  0.2706,  ...,  0.3725,  0.2784,  0.2314],
          [ 0.2157,  0.1843,  0.1529,  ...,  0.3490,  0.2627,  0.2157],
          [ 0.0588,  0.0118, -0.0118,  ...,  0.3412,  0.2471,  0.2000],
          ...,
          [ 0.3490,  0.3176,  0.3255,  ...,  0.5373,  0.5451,  0.5608],
          [ 0.4275,  0.4118,  0.4196,  ...,  0.5451,  0.5451,  0.5608],
          [ 0.4902,  0.4902,  0.4980,  ...,  0.5451,  0.5529,  0.5529]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.84it/s, distance=274]  3%|▎         | 3/100 [00:00<00:15,  6.42it/s, distance=156]  5%|▌         | 5/100 [00:00<00:11,  8.25it/s, distance=133]  7%|▋         | 7/100 [00:00<00:09,  9.30it/s, distance=122]  9%|▉         | 9/100 [00:01<00:13,  6.50it/s, distance=94.6] 11%|█         | 11/100 [00:01<00:11,  7.65it/s, distance=87.3] 13%|█▎        | 13/100 [00:01<00:10,  8.58it/s, distance=76.1] 15%|█▌        | 15/100 [00:01<00:09,  9.30it/s, distance=69.4] 17%|█▋        | 17/100 [00:02<00:12,  6.84it/s, distance=59.8] 19%|█▉        | 19/100 [00:02<00:10,  7.81it/s, distance=55.2] 21%|██        | 21/100 [00:02<00:09,  8.63it/s, distance=51.4] 23%|██▎       | 23/100 [00:02<00:08,  9.29it/s, distance=49.4] 25%|██▌       | 25/100 [00:03<00:10,  6.96it/s, distance=52.1] 27%|██▋       | 27/100 [00:03<00:09,  7.90it/s, distance=49]   29%|██▉       | 29/100 [00:03<00:08,  8.69it/s, distance=45.5] 31%|███       | 31/100 [00:03<00:07,  9.34it/s, distance=44.7] 33%|███▎      | 33/100 [00:04<00:09,  7.01it/s, distance=43.7] 35%|███▌      | 35/100 [00:04<00:08,  7.93it/s, distance=42.7] 37%|███▋      | 37/100 [00:04<00:07,  8.70it/s, distance=39.3] 39%|███▉      | 39/100 [00:04<00:06,  9.34it/s, distance=38]   41%|████      | 41/100 [00:05<00:08,  7.02it/s, distance=36.9] 43%|████▎     | 43/100 [00:05<00:07,  7.94it/s, distance=35.9] 45%|████▌     | 45/100 [00:05<00:06,  8.71it/s, distance=35]   47%|████▋     | 47/100 [00:05<00:05,  9.35it/s, distance=34.3] 49%|████▉     | 49/100 [00:06<00:07,  7.01it/s, distance=33.6] 51%|█████     | 51/100 [00:06<00:06,  7.93it/s, distance=32.7] 53%|█████▎    | 53/100 [00:06<00:05,  8.71it/s, distance=32.2] 55%|█████▌    | 55/100 [00:06<00:04,  9.33it/s, distance=31.4] 57%|█████▋    | 57/100 [00:07<00:06,  6.97it/s, distance=31.1] 59%|█████▉    | 59/100 [00:07<00:05,  7.90it/s, distance=30.5] 61%|██████    | 61/100 [00:07<00:04,  8.67it/s, distance=30]   63%|██████▎   | 63/100 [00:07<00:03,  9.31it/s, distance=29.5] 65%|██████▌   | 65/100 [00:08<00:05,  6.97it/s, distance=29.1] 67%|██████▋   | 67/100 [00:08<00:04,  7.90it/s, distance=28.7] 69%|██████▉   | 69/100 [00:08<00:03,  8.68it/s, distance=28.3] 71%|███████   | 71/100 [00:08<00:03,  9.32it/s, distance=27.9] 73%|███████▎  | 73/100 [00:09<00:03,  6.96it/s, distance=27.4] 75%|███████▌  | 75/100 [00:09<00:03,  7.88it/s, distance=27]   77%|███████▋  | 77/100 [00:09<00:02,  8.66it/s, distance=26.6] 79%|███████▉  | 79/100 [00:09<00:02,  9.31it/s, distance=26.3] 81%|████████  | 81/100 [00:10<00:02,  6.96it/s, distance=26]   83%|████████▎ | 83/100 [00:10<00:02,  7.90it/s, distance=25.5] 85%|████████▌ | 85/100 [00:10<00:01,  8.68it/s, distance=25.1] 87%|████████▋ | 87/100 [00:10<00:01,  9.32it/s, distance=24.6] 89%|████████▉ | 89/100 [00:11<00:01,  6.96it/s, distance=24.2] 91%|█████████ | 91/100 [00:11<00:01,  7.89it/s, distance=23.6] 93%|█████████▎| 93/100 [00:11<00:00,  8.66it/s, distance=22.9] 95%|█████████▌| 95/100 [00:11<00:00,  9.31it/s, distance=22.1] 97%|█████████▋| 97/100 [00:11<00:00,  9.82it/s, distance=21]   99%|█████████▉| 99/100 [00:12<00:00, 10.21it/s, distance=18.8]100%|██████████| 100/100 [00:12<00:00,  8.22it/s, distance=15.7]
2025-06-18 20:43:39,725 [MPGD] >> Inference for image 59
reward_name: adaface, curr_reward: tensor([-2.0199e+00, -1.9423e+00, -5.1200e+08, -2.0203e+00, -5.1200e+08,
        -2.0878e+00, -2.0154e+00, -1.9595e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0336, -2.0214, -1.8797, -2.0618, -1.9257, -2.0037, -2.0436, -1.9291],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02276202 0.0290222  0.49456834 0.01294678 0.19676576 0.04140928
 0.01862709 0.18389852]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.7850, -1.8080, -1.8625, -1.7478, -1.7317, -1.7475, -1.9298, -1.9295],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.11024123 0.06957424 0.02338293 0.23177053 0.31985735 0.23296163
 0.00608933 0.00612277]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4540, -1.6201, -1.6206, -1.5740, -1.5866, -1.5699, -1.5573, -1.4567],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.41554486 0.01500998 0.01484194 0.03771994 0.02931354 0.0409392
 0.05268472 0.39394582]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3537, -1.3242, -1.2977, -1.1972, -1.2914, -1.4040, -1.4091, -1.3533],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0295091  0.05317028 0.09046824 0.67413944 0.10247099 0.01077894
 0.00973224 0.02973077]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0766, -1.0166, -1.1780, -1.2139, -1.1301, -1.2526, -1.2195, -1.0415],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14359648 0.47684635 0.01888716 0.00920857 0.04924807 0.00425043
 0.00823913 0.28972382]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9966, -1.0972, -1.0774, -1.1075, -1.1578, -1.1053, -0.9876, -1.0596],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.32511536 0.04350533 0.06465148 0.03538275 0.01293138 0.0370054
 0.38924355 0.09216474]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0427, -0.9915, -0.9344, -0.9964, -1.0231, -1.0666, -0.9819, -0.9416],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03564684 0.09930624 0.31088343 0.09002413 0.05279515 0.02208433
 0.12015797 0.2691019 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9069, -0.9229, -0.9239, -0.7843, -0.8671, -0.8895, -0.9360, -0.9272],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.05289182 0.0383719  0.03766535 0.61432743 0.11714671 0.07486921
 0.02952315 0.03520442]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7937, -0.8228, -0.7940, -0.7944, -0.8412, -0.8429, -0.7803, -0.8155],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15996815 0.08935277 0.1588275  0.15769251 0.06185797 0.05977999
 0.20908614 0.10343497]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7890, -0.8119, -0.8426, -0.7855, -0.7771, -0.8260, -0.8229, -0.7907],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15954962 0.10091373 0.05466032 0.17098671 0.20257516 0.07614049
 0.08105318 0.15412079]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8562, -0.8231, -0.8097, -0.8036, -0.8662, -0.8436, -0.7929, -0.8177],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06189666 0.12006419 0.15684331 0.17732624 0.05069592 0.07963542
 0.219635   0.13390325]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.333
key: ssim
value: 0.846
key: lpips
value: 0.105
key: facenet_l2
value: 0.668
key: adaface_l2
value: 0.666
ref_face_img: tensor([[[[-0.9294, -0.9294, -0.9294,  ..., -0.6314, -0.6235, -0.6157],
          [-0.9373, -0.9373, -0.9373,  ..., -0.6314, -0.6235, -0.6157],
          [-0.9373, -0.9373, -0.9373,  ..., -0.6235, -0.6157, -0.6078],
          ...,
          [-0.8980, -0.9059, -0.9216,  ..., -0.7412, -0.7412, -0.7412],
          [-0.8980, -0.9059, -0.9216,  ..., -0.7333, -0.7412, -0.7412],
          [-0.8980, -0.9059, -0.9216,  ..., -0.7333, -0.7412, -0.7412]],

         [[-0.9137, -0.9137, -0.9137,  ..., -0.4902, -0.4902, -0.4980],
          [-0.9216, -0.9216, -0.9216,  ..., -0.4902, -0.4902, -0.4902],
          [-0.9216, -0.9216, -0.9216,  ..., -0.4824, -0.4902, -0.4902],
          ...,
          [-0.8824, -0.8902, -0.8980,  ..., -0.6627, -0.6706, -0.6706],
          [-0.8824, -0.8902, -0.8980,  ..., -0.6706, -0.6784, -0.6784],
          [-0.8745, -0.8824, -0.8980,  ..., -0.6784, -0.6784, -0.6863]],

         [[-0.9608, -0.9608, -0.9529,  ..., -0.7882, -0.7882, -0.7882],
          [-0.9608, -0.9608, -0.9608,  ..., -0.7882, -0.7882, -0.7882],
          [-0.9608, -0.9608, -0.9608,  ..., -0.7882, -0.7882, -0.7882],
          ...,
          [-0.9373, -0.9451, -0.9529,  ..., -0.8510, -0.8588, -0.8588],
          [-0.9373, -0.9451, -0.9529,  ..., -0.8510, -0.8510, -0.8588],
          [-0.9373, -0.9451, -0.9529,  ..., -0.8510, -0.8510, -0.8588]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.96it/s, distance=269]  3%|▎         | 3/100 [00:00<00:14,  6.57it/s, distance=158]  5%|▌         | 5/100 [00:00<00:11,  8.36it/s, distance=148]  7%|▋         | 7/100 [00:00<00:09,  9.39it/s, distance=125]  9%|▉         | 9/100 [00:01<00:13,  6.52it/s, distance=104] 11%|█         | 11/100 [00:01<00:11,  7.68it/s, distance=103] 13%|█▎        | 13/100 [00:01<00:10,  8.59it/s, distance=85.1] 15%|█▌        | 15/100 [00:01<00:09,  9.30it/s, distance=76.7] 17%|█▋        | 17/100 [00:02<00:12,  6.79it/s, distance=62.4] 19%|█▉        | 19/100 [00:02<00:10,  7.78it/s, distance=59]   21%|██        | 21/100 [00:02<00:09,  8.59it/s, distance=55.9] 23%|██▎       | 23/100 [00:02<00:08,  9.26it/s, distance=52.9] 25%|██▌       | 25/100 [00:03<00:11,  6.76it/s, distance=48.6] 27%|██▋       | 27/100 [00:03<00:09,  7.72it/s, distance=49.2] 29%|██▉       | 29/100 [00:03<00:08,  8.53it/s, distance=47.5] 31%|███       | 31/100 [00:03<00:07,  9.21it/s, distance=45.3] 33%|███▎      | 33/100 [00:04<00:09,  6.78it/s, distance=44.1] 35%|███▌      | 35/100 [00:04<00:08,  7.72it/s, distance=42.8] 37%|███▋      | 37/100 [00:04<00:07,  8.52it/s, distance=41]   39%|███▉      | 39/100 [00:04<00:06,  9.20it/s, distance=39.6] 41%|████      | 41/100 [00:05<00:08,  6.74it/s, distance=38.2] 43%|████▎     | 43/100 [00:05<00:07,  7.68it/s, distance=36.6] 45%|████▌     | 45/100 [00:05<00:06,  8.50it/s, distance=35.3] 47%|████▋     | 47/100 [00:05<00:05,  9.18it/s, distance=34.5] 49%|████▉     | 49/100 [00:06<00:07,  6.74it/s, distance=34.2] 51%|█████     | 51/100 [00:06<00:06,  7.68it/s, distance=33.2] 53%|█████▎    | 53/100 [00:06<00:05,  8.49it/s, distance=32.3] 55%|█████▌    | 55/100 [00:06<00:04,  9.17it/s, distance=31.7] 57%|█████▋    | 57/100 [00:07<00:06,  6.71it/s, distance=30.9] 59%|█████▉    | 59/100 [00:07<00:05,  7.66it/s, distance=30.6] 61%|██████    | 61/100 [00:07<00:04,  8.48it/s, distance=30.1] 63%|██████▎   | 63/100 [00:07<00:04,  9.15it/s, distance=29.6] 65%|██████▌   | 65/100 [00:08<00:05,  6.73it/s, distance=29.4] 67%|██████▋   | 67/100 [00:08<00:04,  7.68it/s, distance=28.8] 69%|██████▉   | 69/100 [00:08<00:03,  8.49it/s, distance=28.3] 71%|███████   | 71/100 [00:08<00:03,  9.17it/s, distance=27.8] 73%|███████▎  | 73/100 [00:09<00:04,  6.74it/s, distance=27.4] 75%|███████▌  | 75/100 [00:09<00:03,  7.69it/s, distance=27]   77%|███████▋  | 77/100 [00:09<00:02,  8.51it/s, distance=26.7] 79%|███████▉  | 79/100 [00:09<00:02,  9.17it/s, distance=26.2] 81%|████████  | 81/100 [00:10<00:02,  6.75it/s, distance=25.9] 83%|████████▎ | 83/100 [00:10<00:02,  7.70it/s, distance=25.4] 85%|████████▌ | 85/100 [00:10<00:01,  8.51it/s, distance=25]   87%|████████▋ | 87/100 [00:10<00:01,  9.19it/s, distance=24.5] 89%|████████▉ | 89/100 [00:11<00:01,  6.77it/s, distance=24.1] 91%|█████████ | 91/100 [00:11<00:01,  7.72it/s, distance=23.5] 93%|█████████▎| 93/100 [00:11<00:00,  8.52it/s, distance=22.8] 95%|█████████▌| 95/100 [00:11<00:00,  9.19it/s, distance=22]   97%|█████████▋| 97/100 [00:12<00:00,  9.73it/s, distance=20.9] 99%|█████████▉| 99/100 [00:12<00:00, 10.14it/s, distance=18.7]100%|██████████| 100/100 [00:12<00:00,  8.07it/s, distance=15.6]
2025-06-18 20:43:53,356 [MPGD] >> Inference for image 60
reward_name: adaface, curr_reward: tensor([-1.9896e+00, -2.0455e+00, -5.1200e+08, -5.1200e+08, -5.1200e+08,
        -5.1200e+08, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9780, -1.8720, -1.8751, -1.7711, -1.9466, -1.8107, -1.8249, -1.6440],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00107885 0.00898014 0.00845054 0.06758067 0.00202077 0.03061671
 0.02304719 0.85822512]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5348, -1.7393, -1.6945, -1.4623, -1.5693, -1.5743, -1.5926, -1.6435],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14922371 0.00249645 0.00611502 0.63581804 0.07475788 0.06766099
 0.04697105 0.01695688]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.5535, -1.5929, -1.5412, -1.5859, -1.4942, -1.5175, -1.4925, -1.5770],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07932417 0.03608766 0.10153042 0.041547   0.25999436 0.16319099
 0.26872038 0.04960501]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3743, -1.4085, -1.2318, -1.3641, -1.3596, -1.4485, -1.4723, -1.5055],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04591728 0.02313105 0.79291957 0.05626147 0.06158221 0.01039638
 0.00646214 0.0033299 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2084, -1.0994, -1.0888, -1.0799, -1.1983, -1.1188, -0.9591, -1.1711],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00527505 0.0467259  0.0577042  0.06894469 0.00645214 0.03167676
 0.77210475 0.01111652]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8925, -0.9719, -0.9733, -0.8745, -0.9128, -1.0129, -0.9224, -0.8593],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16446115 0.03355674 0.03264408 0.23558291 0.10946795 0.01479688
 0.09047293 0.31901735]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8205, -0.8501, -0.7910, -0.8794, -0.8259, -0.8234, -0.8186, -0.9060],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14866261 0.08227002 0.26833886 0.0457517  0.13350443 0.14024148
 0.15434362 0.02688728]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7508, -0.7559, -0.7969, -0.7778, -0.8063, -0.7556, -0.7850, -0.7274],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16066813 0.14501783 0.06394845 0.09365249 0.0530118  0.14606855
 0.0811706  0.25646216]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6916, -0.7903, -0.7317, -0.6988, -0.7677, -0.7180, -0.7162, -0.8190],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.25322482 0.03516103 0.11350903 0.21904505 0.05521185 0.14923238
 0.15481533 0.01980052]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7258, -0.7037, -0.7053, -0.7086, -0.6810, -0.7093, -0.7335, -0.7541],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09319353 0.14479067 0.14037047 0.131277   0.22817774 0.12947448
 0.07987588 0.05284025]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7059, -0.6927, -0.7229, -0.7022, -0.7243, -0.7159, -0.6798, -0.7254],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12553898 0.16348613 0.08934222 0.13521545 0.08679915 0.10285778
 0.21171971 0.08504059]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 30.010
key: ssim
value: 0.850
key: lpips
value: 0.093
key: facenet_l2
value: 0.390
key: adaface_l2
value: 0.658
ref_face_img: tensor([[[[-0.5843, -0.5843, -0.5843,  ..., -0.5922, -0.5922, -0.5843],
          [-0.5843, -0.5843, -0.5843,  ..., -0.5922, -0.5922, -0.5843],
          [-0.5765, -0.5765, -0.5765,  ..., -0.5922, -0.5922, -0.5922],
          ...,
          [-0.5216, -0.5216, -0.5137,  ..., -0.5765, -0.5765, -0.5765],
          [-0.5216, -0.5216, -0.5137,  ..., -0.5843, -0.5765, -0.5765],
          [-0.5216, -0.5216, -0.5137,  ..., -0.5843, -0.5843, -0.5843]],

         [[-0.5843, -0.5843, -0.5843,  ..., -0.5922, -0.5922, -0.5843],
          [-0.5843, -0.5843, -0.5843,  ..., -0.5922, -0.5922, -0.5843],
          [-0.5843, -0.5843, -0.5843,  ..., -0.5922, -0.5922, -0.5922],
          ...,
          [-0.5216, -0.5216, -0.5137,  ..., -0.7176, -0.7176, -0.7176],
          [-0.5216, -0.5216, -0.5216,  ..., -0.7176, -0.7176, -0.7176],
          [-0.5216, -0.5216, -0.5216,  ..., -0.7176, -0.7176, -0.7176]],

         [[-0.5608, -0.5608, -0.5608,  ..., -0.5765, -0.5686, -0.5686],
          [-0.5608, -0.5608, -0.5608,  ..., -0.5765, -0.5686, -0.5686],
          [-0.5608, -0.5608, -0.5608,  ..., -0.5765, -0.5765, -0.5765],
          ...,
          [-0.5059, -0.5059, -0.5059,  ..., -0.7882, -0.7882, -0.7882],
          [-0.5059, -0.5059, -0.5059,  ..., -0.7882, -0.7882, -0.7882],
          [-0.5059, -0.5059, -0.5059,  ..., -0.7882, -0.7882, -0.7882]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.96it/s, distance=282]  3%|▎         | 3/100 [00:00<00:14,  6.58it/s, distance=158]  5%|▌         | 5/100 [00:00<00:11,  8.37it/s, distance=138]  7%|▋         | 7/100 [00:00<00:09,  9.38it/s, distance=124]  9%|▉         | 9/100 [00:01<00:14,  6.44it/s, distance=104] 11%|█         | 11/100 [00:01<00:11,  7.61it/s, distance=95.9] 13%|█▎        | 13/100 [00:01<00:10,  8.54it/s, distance=88.3] 15%|█▌        | 15/100 [00:01<00:09,  9.27it/s, distance=76]   17%|█▋        | 17/100 [00:02<00:12,  6.78it/s, distance=69.7] 19%|█▉        | 19/100 [00:02<00:10,  7.77it/s, distance=63.1] 21%|██        | 21/100 [00:02<00:09,  8.59it/s, distance=57.6] 23%|██▎       | 23/100 [00:02<00:08,  9.26it/s, distance=54.4] 25%|██▌       | 25/100 [00:03<00:10,  6.85it/s, distance=52]   27%|██▋       | 27/100 [00:03<00:09,  7.80it/s, distance=50.3] 29%|██▉       | 29/100 [00:03<00:08,  8.59it/s, distance=48]   31%|███       | 31/100 [00:03<00:07,  9.26it/s, distance=46.5] 33%|███▎      | 33/100 [00:04<00:09,  6.87it/s, distance=44.5] 35%|███▌      | 35/100 [00:04<00:08,  7.82it/s, distance=43.5] 37%|███▋      | 37/100 [00:04<00:07,  8.61it/s, distance=42.5] 39%|███▉      | 39/100 [00:04<00:06,  9.26it/s, distance=41.7] 41%|████      | 41/100 [00:05<00:08,  6.87it/s, distance=40]   43%|████▎     | 43/100 [00:05<00:07,  7.81it/s, distance=38.5] 45%|████▌     | 45/100 [00:05<00:06,  8.60it/s, distance=37.3] 47%|████▋     | 47/100 [00:05<00:05,  9.25it/s, distance=36.6] 49%|████▉     | 49/100 [00:06<00:07,  6.87it/s, distance=35.4] 51%|█████     | 51/100 [00:06<00:06,  7.80it/s, distance=34.9] 53%|█████▎    | 53/100 [00:06<00:05,  8.60it/s, distance=33.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.26it/s, distance=33.1] 57%|█████▋    | 57/100 [00:07<00:06,  6.87it/s, distance=32.8] 59%|█████▉    | 59/100 [00:07<00:05,  7.81it/s, distance=32]   61%|██████    | 61/100 [00:07<00:04,  8.60it/s, distance=31.5] 63%|██████▎   | 63/100 [00:07<00:03,  9.25it/s, distance=30.9] 65%|██████▌   | 65/100 [00:08<00:05,  6.80it/s, distance=30.6] 67%|██████▋   | 67/100 [00:08<00:04,  7.74it/s, distance=29.9] 69%|██████▉   | 69/100 [00:08<00:03,  8.54it/s, distance=29.4] 71%|███████   | 71/100 [00:08<00:03,  9.20it/s, distance=28.8] 73%|███████▎  | 73/100 [00:09<00:03,  6.79it/s, distance=28.3] 75%|███████▌  | 75/100 [00:09<00:03,  7.74it/s, distance=27.9] 77%|███████▋  | 77/100 [00:09<00:02,  8.55it/s, distance=27.4] 79%|███████▉  | 79/100 [00:09<00:02,  9.22it/s, distance=26.9] 81%|████████  | 81/100 [00:10<00:02,  6.81it/s, distance=26.4] 83%|████████▎ | 83/100 [00:10<00:02,  7.75it/s, distance=25.9] 85%|████████▌ | 85/100 [00:10<00:01,  8.55it/s, distance=25.5] 87%|████████▋ | 87/100 [00:10<00:01,  9.23it/s, distance=25]   89%|████████▉ | 89/100 [00:11<00:01,  6.78it/s, distance=24.4] 91%|█████████ | 91/100 [00:11<00:01,  7.73it/s, distance=23.8] 93%|█████████▎| 93/100 [00:11<00:00,  8.53it/s, distance=23.1] 95%|█████████▌| 95/100 [00:11<00:00,  9.20it/s, distance=22.3] 97%|█████████▋| 97/100 [00:12<00:00,  9.73it/s, distance=21.1] 99%|█████████▉| 99/100 [00:12<00:00, 10.14it/s, distance=19]  100%|██████████| 100/100 [00:12<00:00,  8.13it/s, distance=15.9]
2025-06-18 20:44:06,895 [MPGD] >> Inference for image 61
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08, -2.1643e+00,
        -2.2505e+00, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0091, -1.9319, -1.9922, -2.0116, -2.1004, -2.0865, -1.9520, -2.0366],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08255854 0.38638856 0.11564875 0.07849795 0.01330026 0.01754592
 0.25848159 0.04757841]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6556, -1.5957, -1.7052, -1.5590, -1.5744, -1.4340, -1.6680, -1.6157],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00965114 0.03196666 0.00357623 0.06656389 0.0488888  0.81041734
 0.00753097 0.02140498]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2878, -1.3109, -1.4436, -1.2892, -1.3540, -1.3930, -1.3313, -1.3590],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.2706149  0.17044338 0.01201111 0.2634052  0.07199309 0.03301676
 0.11334276 0.0651728 ]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1118, -1.2003, -1.0810, -1.1660, -1.2881, -1.2898, -1.1791, -1.1564],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.24468979 0.04162192 0.45310092 0.08267736 0.00718897 0.00695962
 0.06362778 0.10013364]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0405, -0.9565, -1.0347, -0.9102, -0.8993, -1.0199, -1.0902, -1.0522],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02464197 0.13227005 0.0276962  0.33421115 0.41531972 0.03724468
 0.00911965 0.01949657]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8130, -0.8480, -0.8957, -0.7732, -0.8988, -0.8739, -0.9476, -0.8358],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.19684024 0.09770888 0.03759764 0.43625842 0.03539583 0.05817037
 0.01333583 0.12469279]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7592, -0.7903, -0.7527, -0.7585, -0.7717, -0.7738, -0.7578, -0.7844],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.14614202 0.07843998 0.16641484 0.14802813 0.11370232 0.10902054
 0.15007339 0.08817878]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6871, -0.7307, -0.7315, -0.7421, -0.7792, -0.7339, -0.8321, -0.7304],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.31360443 0.1310931  0.12895984 0.10449728 0.04972629 0.12290723
 0.01725465 0.13195718]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7173, -0.7195, -0.6753, -0.7141, -0.7218, -0.7138, -0.7299, -0.7122],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10854298 0.10398335 0.25144212 0.11576444 0.09914033 0.11638919
 0.08443609 0.12030151]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6809, -0.5935, -0.6450, -0.6743, -0.6399, -0.6207, -0.6261, -0.6273],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04660767 0.26783275 0.09561161 0.05314025 0.10576924 0.15549329
 0.13947146 0.13607371]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5673, -0.6026, -0.6025, -0.6169, -0.6219, -0.6101, -0.6225, -0.6269],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.26628809 0.13158132 0.13176875 0.09871578 0.08930396 0.11308016
 0.0883458  0.08091614]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 27.907
key: ssim
value: 0.839
key: lpips
value: 0.138
key: facenet_l2
value: 0.395
key: adaface_l2
value: 0.598
ref_face_img: tensor([[[[-0.6627, -0.6627, -0.6706,  ..., -0.5294, -0.5294, -0.5373],
          [-0.6627, -0.6627, -0.6706,  ..., -0.5373, -0.5373, -0.5373],
          [-0.6627, -0.6627, -0.6627,  ..., -0.5373, -0.5373, -0.5373],
          ...,
          [-0.3647, -0.3647, -0.3647,  ..., -0.3804, -0.3804, -0.3804],
          [-0.3647, -0.3647, -0.3647,  ..., -0.3804, -0.3804, -0.3804],
          [-0.3647, -0.3647, -0.3647,  ..., -0.3804, -0.3804, -0.3804]],

         [[-0.6392, -0.6392, -0.6471,  ..., -0.6706, -0.6706, -0.6706],
          [-0.6392, -0.6392, -0.6471,  ..., -0.6784, -0.6784, -0.6784],
          [-0.6392, -0.6392, -0.6392,  ..., -0.6784, -0.6784, -0.6784],
          ...,
          [-0.3255, -0.3255, -0.3255,  ..., -0.5216, -0.5216, -0.5216],
          [-0.3255, -0.3255, -0.3255,  ..., -0.5216, -0.5216, -0.5216],
          [-0.3255, -0.3255, -0.3255,  ..., -0.5216, -0.5216, -0.5216]],

         [[-0.6941, -0.6941, -0.7020,  ..., -0.7804, -0.7804, -0.7804],
          [-0.6941, -0.6941, -0.7020,  ..., -0.7882, -0.7882, -0.7882],
          [-0.6941, -0.6941, -0.6941,  ..., -0.7882, -0.7882, -0.7882],
          ...,
          [-0.3725, -0.3725, -0.3725,  ..., -0.6627, -0.6627, -0.6627],
          [-0.3725, -0.3725, -0.3725,  ..., -0.6627, -0.6627, -0.6627],
          [-0.3725, -0.3725, -0.3725,  ..., -0.6627, -0.6627, -0.6627]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 0, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.96it/s, distance=305]  3%|▎         | 3/100 [00:00<00:14,  6.56it/s, distance=171]  5%|▌         | 5/100 [00:00<00:11,  8.36it/s, distance=147]  7%|▋         | 7/100 [00:00<00:09,  9.39it/s, distance=125]  9%|▉         | 9/100 [00:01<00:13,  6.51it/s, distance=105] 11%|█         | 11/100 [00:01<00:11,  7.67it/s, distance=93.7] 13%|█▎        | 13/100 [00:01<00:10,  8.60it/s, distance=82.9] 15%|█▌        | 15/100 [00:01<00:09,  9.32it/s, distance=75.9] 17%|█▋        | 17/100 [00:02<00:12,  6.78it/s, distance=73.3] 19%|█▉        | 19/100 [00:02<00:10,  7.77it/s, distance=63]   21%|██        | 21/100 [00:02<00:09,  8.59it/s, distance=58.1] 23%|██▎       | 23/100 [00:02<00:08,  9.25it/s, distance=55.3] 25%|██▌       | 25/100 [00:03<00:11,  6.82it/s, distance=51.8] 27%|██▋       | 27/100 [00:03<00:09,  7.77it/s, distance=53.4] 29%|██▉       | 29/100 [00:03<00:08,  8.57it/s, distance=52.4] 31%|███       | 31/100 [00:03<00:07,  9.23it/s, distance=50.1] 33%|███▎      | 33/100 [00:04<00:09,  6.84it/s, distance=47.2] 35%|███▌      | 35/100 [00:04<00:08,  7.77it/s, distance=44.5] 37%|███▋      | 37/100 [00:04<00:07,  8.57it/s, distance=40.6] 39%|███▉      | 39/100 [00:04<00:06,  9.24it/s, distance=38.9] 41%|████      | 41/100 [00:05<00:08,  6.86it/s, distance=36.7] 43%|████▎     | 43/100 [00:05<00:07,  7.80it/s, distance=36.1] 45%|████▌     | 45/100 [00:05<00:06,  8.59it/s, distance=34.9] 47%|████▋     | 47/100 [00:05<00:05,  9.25it/s, distance=34.3] 49%|████▉     | 49/100 [00:06<00:07,  6.87it/s, distance=33.6] 51%|█████     | 51/100 [00:06<00:06,  7.80it/s, distance=32.6] 53%|█████▎    | 53/100 [00:06<00:05,  8.59it/s, distance=31.9] 55%|█████▌    | 55/100 [00:06<00:04,  9.26it/s, distance=31.2] 57%|█████▋    | 57/100 [00:07<00:06,  6.88it/s, distance=30.8] 59%|█████▉    | 59/100 [00:07<00:05,  7.81it/s, distance=30.3] 61%|██████    | 61/100 [00:07<00:04,  8.61it/s, distance=29.9] 63%|██████▎   | 63/100 [00:07<00:03,  9.27it/s, distance=29.5] 65%|██████▌   | 65/100 [00:08<00:05,  6.89it/s, distance=29]   67%|██████▋   | 67/100 [00:08<00:04,  7.82it/s, distance=28.6] 69%|██████▉   | 69/100 [00:08<00:03,  8.61it/s, distance=28.3] 71%|███████   | 71/100 [00:08<00:03,  9.27it/s, distance=27.8] 73%|███████▎  | 73/100 [00:09<00:03,  6.88it/s, distance=27.4] 75%|███████▌  | 75/100 [00:09<00:03,  7.82it/s, distance=27]   77%|███████▋  | 77/100 [00:09<00:02,  8.61it/s, distance=26.6] 79%|███████▉  | 79/100 [00:09<00:02,  9.26it/s, distance=26.2] 81%|████████  | 81/100 [00:10<00:02,  6.87it/s, distance=25.9] 83%|████████▎ | 83/100 [00:10<00:02,  7.81it/s, distance=25.4] 85%|████████▌ | 85/100 [00:10<00:01,  8.60it/s, distance=25]   87%|████████▋ | 87/100 [00:10<00:01,  9.25it/s, distance=24.6] 89%|████████▉ | 89/100 [00:11<00:01,  6.87it/s, distance=24.1] 91%|█████████ | 91/100 [00:11<00:01,  7.80it/s, distance=23.5] 93%|█████████▎| 93/100 [00:11<00:00,  8.60it/s, distance=22.9] 95%|█████████▌| 95/100 [00:11<00:00,  9.26it/s, distance=22.1] 97%|█████████▋| 97/100 [00:12<00:00,  9.78it/s, distance=21]   99%|█████████▉| 99/100 [00:12<00:00, 10.18it/s, distance=18.9]100%|██████████| 100/100 [00:12<00:00,  8.15it/s, distance=15.9]
2025-06-18 20:44:20,447 [MPGD] >> Inference for image 62
reward_name: adaface, curr_reward: tensor([-5.1200e+08, -5.1200e+08, -5.1200e+08, -5.1200e+08, -1.9970e+00,
        -1.9071e+00, -5.1200e+08, -2.0312e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.9216, -2.0528, -1.9981, -1.8679, -1.8540, -1.9392, -1.9407, -1.9494],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09961964 0.00722003 0.02156223 0.29127328 0.38513194 0.07009016
 0.06798446 0.05711827]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.6010, -1.7905, -1.6963, -1.6003, -1.4574, -1.6151, -1.4833, -1.7509],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.03207271 0.00072418 0.00476812 0.03251496 0.56645353 0.0241959
 0.33767016 0.00160044]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2516, -1.2382, -1.2707, -1.4331, -1.4622, -1.2169, -1.2793, -1.2999],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.16691343 0.2181725  0.11404487 0.00442697 0.00247309 0.33450165
 0.09591702 0.06355048]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.2786, -1.2279, -1.2180, -1.2378, -1.1664, -1.2373, -1.3227, -1.2994],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04514636 0.12427888 0.15158151 0.10192212 0.425532   0.1031036
 0.01868013 0.02975541]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0631, -1.1112, -1.1797, -1.1864, -1.1330, -1.0734, -1.3041, -1.2084],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.37203471 0.14210723 0.0361123  0.03163136 0.09186948 0.30286777
 0.00300319 0.02037395]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9349, -0.9643, -0.9952, -0.8905, -1.0877, -0.8658, -0.9544, -1.0444],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.10985155 0.06108747 0.03290928 0.26684407 0.00517533 0.43741709
 0.07440915 0.01230606]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8451, -0.8263, -0.7620, -0.7190, -0.7527, -0.8504, -0.7877, -0.7652],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.02813137 0.04098814 0.14830799 0.35060501 0.17859581 0.02534102
 0.08877633 0.13925433]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6473, -0.7056, -0.6861, -0.6963, -0.7451, -0.6406, -0.7080, -0.6443],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.20885701 0.06505751 0.09610498 0.07827501 0.02953348 0.23858471
 0.06194204 0.22164526]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6046, -0.6651, -0.6403, -0.6492, -0.6199, -0.6669, -0.7257, -0.6756],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.28155426 0.08399191 0.13788239 0.11541891 0.2071313  0.08101995
 0.02495977 0.06804152]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5762, -0.6290, -0.5731, -0.5864, -0.5760, -0.5839, -0.6316, -0.6340],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17449247 0.06063274 0.18551795 0.14234493 0.17502184 0.14941011
 0.05764637 0.05493359]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.5568, -0.5566, -0.5730, -0.5213, -0.6312, -0.6002, -0.5764, -0.5977],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.15318784 0.15397912 0.11080316 0.31197401 0.03459354 0.06427497
 0.10360526 0.0675821 ]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.442
key: ssim
value: 0.844
key: lpips
value: 0.107
key: facenet_l2
value: 0.248
key: adaface_l2
value: 0.598
ref_face_img: tensor([[[[-0.8275, -0.8353, -0.8431,  ...,  0.2000,  0.2000,  0.2000],
          [-0.8275, -0.8353, -0.8431,  ...,  0.2078,  0.2078,  0.2078],
          [-0.8275, -0.8353, -0.8431,  ...,  0.2941,  0.3020,  0.3020],
          ...,
          [-0.5137, -0.5137, -0.5137,  ..., -0.2863, -0.2863, -0.2784],
          [-0.5059, -0.5059, -0.5137,  ..., -0.2863, -0.2863, -0.2784],
          [-0.5059, -0.5059, -0.5059,  ..., -0.2863, -0.2863, -0.2784]],

         [[-0.7961, -0.8039, -0.8118,  ...,  0.2314,  0.2314,  0.2314],
          [-0.7961, -0.8039, -0.8118,  ...,  0.2392,  0.2392,  0.2392],
          [-0.7961, -0.8039, -0.8118,  ...,  0.3255,  0.3333,  0.3333],
          ...,
          [-0.7176, -0.7176, -0.7176,  ..., -0.4039, -0.4039, -0.4039],
          [-0.7176, -0.7176, -0.7176,  ..., -0.4118, -0.4118, -0.4039],
          [-0.7098, -0.7098, -0.7176,  ..., -0.4039, -0.4118, -0.4039]],

         [[-0.8353, -0.8353, -0.8431,  ...,  0.2078,  0.2000,  0.2078],
          [-0.8353, -0.8353, -0.8431,  ...,  0.2157,  0.2078,  0.2157],
          [-0.8353, -0.8353, -0.8431,  ...,  0.3020,  0.3098,  0.3098],
          ...,
          [-0.8824, -0.8824, -0.8824,  ..., -0.5843, -0.5843, -0.5843],
          [-0.8745, -0.8745, -0.8745,  ..., -0.5843, -0.5843, -0.5843],
          [-0.8745, -0.8745, -0.8745,  ..., -0.5843, -0.5843, -0.5843]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 2, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:34,  2.91it/s, distance=316]  3%|▎         | 3/100 [00:00<00:14,  6.50it/s, distance=162]  5%|▌         | 5/100 [00:00<00:11,  8.32it/s, distance=123]  7%|▋         | 7/100 [00:00<00:09,  9.35it/s, distance=114]  9%|▉         | 9/100 [00:01<00:14,  6.42it/s, distance=104] 11%|█         | 11/100 [00:01<00:11,  7.59it/s, distance=87.6] 13%|█▎        | 13/100 [00:01<00:10,  8.52it/s, distance=81.3] 15%|█▌        | 15/100 [00:01<00:09,  9.25it/s, distance=66.9] 17%|█▋        | 17/100 [00:02<00:12,  6.73it/s, distance=63.5] 19%|█▉        | 19/100 [00:02<00:10,  7.73it/s, distance=56.4] 21%|██        | 21/100 [00:02<00:09,  8.55it/s, distance=51.3] 23%|██▎       | 23/100 [00:02<00:08,  9.22it/s, distance=47.9] 25%|██▌       | 25/100 [00:03<00:10,  6.82it/s, distance=47.9] 27%|██▋       | 27/100 [00:03<00:09,  7.77it/s, distance=41.8] 29%|██▉       | 29/100 [00:03<00:08,  8.58it/s, distance=39.5] 31%|███       | 31/100 [00:03<00:07,  9.24it/s, distance=38.2] 33%|███▎      | 33/100 [00:04<00:09,  6.82it/s, distance=37.7] 35%|███▌      | 35/100 [00:04<00:08,  7.76it/s, distance=35.2] 37%|███▋      | 37/100 [00:04<00:07,  8.56it/s, distance=34]   39%|███▉      | 39/100 [00:04<00:06,  9.23it/s, distance=33] 41%|████      | 41/100 [00:05<00:08,  6.79it/s, distance=32.6] 43%|████▎     | 43/100 [00:05<00:07,  7.75it/s, distance=31.7] 45%|████▌     | 45/100 [00:05<00:06,  8.53it/s, distance=30.7] 47%|████▋     | 47/100 [00:05<00:05,  9.21it/s, distance=29.9] 49%|████▉     | 49/100 [00:06<00:07,  6.77it/s, distance=29.3] 51%|█████     | 51/100 [00:06<00:06,  7.72it/s, distance=28.9] 53%|█████▎    | 53/100 [00:06<00:05,  8.52it/s, distance=28.5] 55%|█████▌    | 55/100 [00:06<00:04,  9.20it/s, distance=28]   57%|█████▋    | 57/100 [00:07<00:06,  6.77it/s, distance=27.6] 59%|█████▉    | 59/100 [00:07<00:05,  7.72it/s, distance=27.2] 61%|██████    | 61/100 [00:07<00:04,  8.52it/s, distance=26.9] 63%|██████▎   | 63/100 [00:07<00:04,  9.20it/s, distance=26.5] 65%|██████▌   | 65/100 [00:08<00:05,  6.78it/s, distance=26.2] 67%|██████▋   | 67/100 [00:08<00:04,  7.72it/s, distance=25.9] 69%|██████▉   | 69/100 [00:08<00:03,  8.53it/s, distance=25.6] 71%|███████   | 71/100 [00:08<00:03,  9.20it/s, distance=25.3] 73%|███████▎  | 73/100 [00:09<00:03,  6.78it/s, distance=25]   75%|███████▌  | 75/100 [00:09<00:03,  7.72it/s, distance=24.7] 77%|███████▋  | 77/100 [00:09<00:02,  8.52it/s, distance=24.4] 79%|███████▉  | 79/100 [00:09<00:02,  9.18it/s, distance=24.1] 81%|████████  | 81/100 [00:10<00:02,  6.77it/s, distance=23.9] 83%|████████▎ | 83/100 [00:10<00:02,  7.72it/s, distance=23.5] 85%|████████▌ | 85/100 [00:10<00:01,  8.52it/s, distance=23.2] 87%|████████▋ | 87/100 [00:10<00:01,  9.20it/s, distance=22.8] 89%|████████▉ | 89/100 [00:11<00:01,  6.78it/s, distance=22.4] 91%|█████████ | 91/100 [00:11<00:01,  7.72it/s, distance=21.9] 93%|█████████▎| 93/100 [00:11<00:00,  8.52it/s, distance=21.4] 95%|█████████▌| 95/100 [00:11<00:00,  9.19it/s, distance=20.7] 97%|█████████▋| 97/100 [00:12<00:00,  9.72it/s, distance=19.8] 99%|█████████▉| 99/100 [00:12<00:00, 10.14it/s, distance=17.8]100%|██████████| 100/100 [00:12<00:00,  8.09it/s, distance=14.7]
2025-06-18 20:44:34,020 [MPGD] >> Inference for image 63
reward_name: adaface, curr_reward: tensor([-2.0345e+00, -2.1380e+00, -5.1200e+08, -5.1200e+08, -2.0996e+00,
        -2.0677e+00, -5.1200e+08, -5.1200e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-2.0006, -1.9398, -1.9547, -2.0849, -1.9610, -1.9257, -1.9073, -2.0240],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04795739 0.16179206 0.1203089  0.00888462 0.10586178 0.21473311
 0.31039719 0.03006496]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4734, -1.6169, -1.5772, -1.4548, -1.4833, -1.6298, -1.4880, -1.4940],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.20379939 0.01156153 0.02556089 0.29582702 0.16723881 0.00892501
 0.15209693 0.13499042]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.3618, -1.3106, -1.3262, -1.4393, -1.3899, -1.3680, -1.2783, -1.4184],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07618355 0.21207069 0.15533522 0.01617956 0.04340131 0.06731142
 0.40498281 0.02453544]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.0716, -1.1818, -1.0375, -1.2268, -1.1043, -1.1279, -1.1163, -1.1059],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.20455558 0.02257819 0.40430558 0.00917425 0.10631937 0.06636694
 0.0836869  0.10301319]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8535, -0.9851, -0.8661, -1.0233, -0.8857, -0.8889, -0.8249, -0.9112],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.20068039 0.01441605 0.15578505 0.00671514 0.10530984 0.09869842
 0.35522317 0.06317194]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9195, -0.8185, -0.8316, -0.8051, -0.8555, -0.7962, -0.7809, -0.8893],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.01743189 0.13141337 0.10112241 0.17173235 0.06266545 0.2052368
 0.27852481 0.03187291]
greedy resampling
resampled_idxs: [6 6 6 6 6 6 6 6]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.8227, -0.7387, -0.7494, -0.8367, -0.7447, -0.7966, -0.7666, -0.7861],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.04340807 0.23264061 0.18782184 0.03277928 0.20663951 0.07317813
 0.13331055 0.090222  ]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7010, -0.7823, -0.7449, -0.7741, -0.7986, -0.7194, -0.7184, -0.7484],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.26515306 0.05210539 0.11017905 0.06138509 0.03763491 0.1835292
 0.18727173 0.10274155]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7163, -0.7563, -0.7016, -0.7833, -0.7282, -0.7134, -0.7031, -0.6897],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.12644803 0.05680319 0.16987294 0.03309489 0.09970682 0.13411298
 0.16481937 0.21514179]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7099, -0.7101, -0.7122, -0.6731, -0.7177, -0.6801, -0.6662, -0.6448],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07261641 0.07223471 0.06924602 0.15136988 0.06210922 0.13168684
 0.17391962 0.2668173 ]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6549, -0.6599, -0.5956, -0.6707, -0.6558, -0.6347, -0.6535, -0.6595],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.09672116 0.08765235 0.31708575 0.0706027  0.0950937  0.1450306
 0.09954104 0.0882727 ]
greedy resampling
resampled_idxs: [2 2 2 2 2 2 2 2]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 31.525
key: ssim
value: 0.847
key: lpips
value: 0.119
key: facenet_l2
value: 0.428
key: adaface_l2
value: 0.624
ref_face_img: tensor([[[[ 0.8431,  0.8431,  0.8510,  ...,  0.8902,  0.8902,  0.8902],
          [ 0.8431,  0.8431,  0.8510,  ...,  0.8902,  0.8902,  0.8902],
          [ 0.8431,  0.8431,  0.8510,  ...,  0.8902,  0.8902,  0.8902],
          ...,
          [ 0.3333,  0.3333,  0.3333,  ...,  0.8431,  0.8431,  0.8431],
          [ 0.3412,  0.3412,  0.3412,  ...,  0.8431,  0.8431,  0.8431],
          [ 0.3490,  0.3490,  0.3490,  ...,  0.8431,  0.8431,  0.8431]],

         [[ 0.6941,  0.6941,  0.7020,  ...,  0.7569,  0.7569,  0.7569],
          [ 0.6863,  0.6941,  0.7020,  ...,  0.7569,  0.7569,  0.7569],
          [ 0.6863,  0.6941,  0.7020,  ...,  0.7569,  0.7569,  0.7569],
          ...,
          [-0.2078, -0.2078, -0.2078,  ...,  0.6863,  0.6863,  0.6863],
          [-0.2078, -0.2078, -0.2078,  ...,  0.6863,  0.6863,  0.6863],
          [-0.2000, -0.1922, -0.1922,  ...,  0.6863,  0.6863,  0.6863]],

         [[ 0.6314,  0.6392,  0.6471,  ...,  0.6941,  0.6941,  0.6941],
          [ 0.6314,  0.6392,  0.6471,  ...,  0.6941,  0.6941,  0.6941],
          [ 0.6314,  0.6392,  0.6471,  ...,  0.6941,  0.6941,  0.6941],
          ...,
          [-0.5059, -0.5059, -0.4980,  ...,  0.6157,  0.6235,  0.6235],
          [-0.5059, -0.4980, -0.4980,  ...,  0.6157,  0.6157,  0.6235],
          [-0.4902, -0.4902, -0.4824,  ...,  0.6157,  0.6235,  0.6235]]]],
       device='cuda:0')
ref_img shape: torch.Size([1, 3, 256, 256])
ref_face_img shape: torch.Size([1, 3, 256, 256])
x_start shape: torch.Size([8, 3, 256, 256])
img:  torch.Size([8, 3, 256, 256])
  0%|          | 0/100 [00:00<?, ?it/s]in main loop alpha_bar: 4.8370478907600045e-05 alpha_bar_prev: 5.9037512983195484e-05
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 1, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 3, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 4, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 5, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
Face detection Failed due to error.
list index out of range
Error in face alignment at index 7, adding fallback embedding.
  1%|          | 1/100 [00:00<00:33,  2.99it/s, distance=313]  3%|▎         | 3/100 [00:00<00:14,  6.61it/s, distance=180]  5%|▌         | 5/100 [00:00<00:11,  8.40it/s, distance=140]  7%|▋         | 7/100 [00:00<00:09,  9.42it/s, distance=123]  9%|▉         | 9/100 [00:01<00:14,  6.50it/s, distance=104] 11%|█         | 11/100 [00:01<00:11,  7.65it/s, distance=88.8] 13%|█▎        | 13/100 [00:01<00:10,  8.58it/s, distance=78.1] 15%|█▌        | 15/100 [00:01<00:09,  9.30it/s, distance=69.9]reward_name: adaface, curr_reward: tensor([-2.1949e+00, -5.1201e+08, -2.1504e+00, -5.1201e+08, -5.1201e+08,
        -5.1201e+08, -5.1201e+08, -5.1201e+08], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
group size is 1 or step is 0 so no resampling
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 5.9037512983195484e-05 alpha_bar_prev: 7.191066833911464e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 7.191066833911464e-05 alpha_bar_prev: 8.74130564625375e-05
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 8.74130564625375e-05 alpha_bar_prev: 0.00010604182898532599
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00010604182898532599 alpha_bar_prev: 0.00012837965914513916
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00012837965914513916 alpha_bar_prev: 0.00015510775847360492
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00015510775847360492 alpha_bar_prev: 0.00018702053057495505
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00018702053057495505 alpha_bar_prev: 0.0002250420511700213
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0002250420511700213 alpha_bar_prev: 0.00027024451992474496
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.8361, -2.0087, -1.9712, -1.7686, -1.8623, -1.9995, -2.0690, -2.0751],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 8, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.17849261 0.00565049 0.01196136 0.6881395  0.1057684  0.0067975
 0.0016922  0.00149792]
greedy resampling
resampled_idxs: [3 3 3 3 3 3 3 3]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00027024451992474496 alpha_bar_prev: 0.0003238687932025641
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0003238687932025641 alpha_bar_prev: 0.00038734727422706783
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.00038734727422706783 alpha_bar_prev: 0.0004623291315510869
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0004623291315510869 alpha_bar_prev: 0.000550708151422441
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.000550708151422441 alpha_bar_prev: 0.0006546535296365619
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0006546535296365619 alpha_bar_prev: 0.0007766429334878922
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0007766429334878922 alpha_bar_prev: 0.0009194992017000914
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0009194992017000914 alpha_bar_prev: 0.0010864294599741697
using sigma in the main loop
Face detection Failed due to error.
list index out of range
Error in face alignment at index 6, adding fallback embedding.
 17%|█▋        | 17/100 [00:02<00:12,  6.77it/s, distance=62.9] 19%|█▉        | 19/100 [00:02<00:10,  7.76it/s, distance=58.4] 21%|██        | 21/100 [00:02<00:09,  8.58it/s, distance=53.5] 23%|██▎       | 23/100 [00:02<00:08,  9.26it/s, distance=51.7] 25%|██▌       | 25/100 [00:03<00:10,  6.82it/s, distance=49]   27%|██▋       | 27/100 [00:03<00:09,  7.77it/s, distance=47.3] 29%|██▉       | 29/100 [00:03<00:08,  8.58it/s, distance=44.9] 31%|███       | 31/100 [00:03<00:07,  9.23it/s, distance=43.3] 33%|███▎      | 33/100 [00:04<00:09,  6.82it/s, distance=41.7] 35%|███▌      | 35/100 [00:04<00:08,  7.77it/s, distance=40.4] 37%|███▋      | 37/100 [00:04<00:07,  8.57it/s, distance=38.7] 39%|███▉      | 39/100 [00:04<00:06,  9.24it/s, distance=37.7] 41%|████      | 41/100 [00:05<00:08,  6.81it/s, distance=36.1] 43%|████▎     | 43/100 [00:05<00:07,  7.76it/s, distance=35.5] 45%|████▌     | 45/100 [00:05<00:06,  8.56it/s, distance=34.1] 47%|████▋     | 47/100 [00:05<00:05,  9.22it/s, distance=33.5] 49%|████▉     | 49/100 [00:06<00:07,  6.77it/s, distance=32.9] 51%|█████     | 51/100 [00:06<00:06,  7.72it/s, distance=32.2] 53%|█████▎    | 53/100 [00:06<00:05,  8.52it/s, distance=31.5] 55%|█████▌    | 55/100 [00:06<00:04,  9.20it/s, distance=30.8] 57%|█████▋    | 57/100 [00:07<00:06,  6.76it/s, distance=30.2] 59%|█████▉    | 59/100 [00:07<00:05,  7.71it/s, distance=29.7] 61%|██████    | 61/100 [00:07<00:04,  8.51it/s, distance=29.3] 63%|██████▎   | 63/100 [00:07<00:04,  9.19it/s, distance=28.8] 65%|██████▌   | 65/100 [00:08<00:05,  6.73it/s, distance=28.4] 67%|██████▋   | 67/100 [00:08<00:04,  7.68it/s, distance=28]   69%|██████▉   | 69/100 [00:08<00:03,  8.49it/s, distance=27.7] 71%|███████   | 71/100 [00:08<00:03,  9.16it/s, distance=27.2] 73%|███████▎  | 73/100 [00:09<00:04,  6.71it/s, distance=26.8] 75%|███████▌  | 75/100 [00:09<00:03,  7.66it/s, distance=26.5] 77%|███████▋  | 77/100 [00:09<00:02,  8.48it/s, distance=26.1] 79%|███████▉  | 79/100 [00:09<00:02,  9.16it/s, distance=25.7] 81%|████████  | 81/100 [00:10<00:02,  6.71it/s, distance=25.3] 83%|████████▎ | 83/100 [00:10<00:02,  7.66it/s, distance=25]   85%|████████▌ | 85/100 [00:10<00:01,  8.47it/s, distance=24.6] 87%|████████▋ | 87/100 [00:10<00:01,  9.16it/s, distance=24.1] 89%|████████▉ | 89/100 [00:11<00:01,  6.71it/s, distance=23.7] 91%|█████████ | 91/100 [00:11<00:01,  7.67it/s, distance=23.1] 93%|█████████▎| 93/100 [00:11<00:00,  8.48it/s, distance=22.5] 95%|█████████▌| 95/100 [00:11<00:00,  9.17it/s, distance=21.8] 97%|█████████▋| 97/100 [00:12<00:00,  9.72it/s, distance=20.7] 99%|█████████▉| 99/100 [00:12<00:00, 10.13it/s, distance=18.6]100%|██████████| 100/100 [00:12<00:00,  8.08it/s, distance=15.5]
reward_name: adaface, curr_reward: tensor([-1.3965e+00, -1.6298e+00, -1.5754e+00, -1.5218e+00, -1.3915e+00,
        -1.4177e+00, -5.1201e+08, -1.4205e+00], device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 16, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.28586357 0.00269124 0.00799252 0.02333006 0.31585127 0.1871712
 0.         0.17710014]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0010864294599741697 alpha_bar_prev: 0.0012810679618269205
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0012810679618269205 alpha_bar_prev: 0.0015075210249051452
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0015075210249051452 alpha_bar_prev: 0.0017704162746667862
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0017704162746667862 alpha_bar_prev: 0.0020749534014612436
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0020749534014612436 alpha_bar_prev: 0.0024269591085612774
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0024269591085612774 alpha_bar_prev: 0.0028329433407634497
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.0028329433407634497 alpha_bar_prev: 0.003300158306956291
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003300158306956291 alpha_bar_prev: 0.003836660413071513
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.4570, -1.2452, -1.4135, -1.2379, -1.3128, -1.2124, -1.3223, -1.4163],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 24, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.00311964 0.21569705 0.00743934 0.24918233 0.05577742 0.41562798
 0.04612672 0.00702953]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.003836660413071513 alpha_bar_prev: 0.004451370798051357
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.004451370798051357 alpha_bar_prev: 0.005154140293598175
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005154140293598175 alpha_bar_prev: 0.005955810658633709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.005955810658633709 alpha_bar_prev: 0.006868279073387384
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.006868279073387384 alpha_bar_prev: 0.007904556579887867
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.007904556579887867 alpha_bar_prev: 0.009078828617930412
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.009078828617930412 alpha_bar_prev: 0.010406509041786194
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.010406509041786194 alpha_bar_prev: 0.011904287151992321
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-1.1164, -1.0189, -1.1074, -1.2116, -1.1827, -1.1932, -1.1031, -1.2722],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 32, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.08915969 0.62740172 0.10679126 0.01329878 0.02368943 0.0192203
 0.11648422 0.00395459]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.011904287151992321 alpha_bar_prev: 0.013590172864496708
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.013590172864496708 alpha_bar_prev: 0.015483532100915909
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.015483532100915909 alpha_bar_prev: 0.01760510727763176
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.01760510727763176 alpha_bar_prev: 0.019977040588855743
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.019977040588855743 alpha_bar_prev: 0.022622862830758095
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.022622862830758095 alpha_bar_prev: 0.025567492470145226
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.025567492470145226 alpha_bar_prev: 0.02883719652891159
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.02883719652891159 alpha_bar_prev: 0.03245954588055611
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.9367, -0.8734, -0.8744, -0.9391, -0.8773, -0.9463, -0.8973, -0.9882],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 40, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.06396194 0.22672365 0.22227853 0.06096308 0.20987289 0.05276158
 0.14060461 0.02283373]
greedy resampling
resampled_idxs: [1 1 1 1 1 1 1 1]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03245954588055611 alpha_bar_prev: 0.03646334633231163
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.03646334633231163 alpha_bar_prev: 0.040878549218177795
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.040878549218177795 alpha_bar_prev: 0.04573613032698631
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.04573613032698631 alpha_bar_prev: 0.05106797069311142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.05106797069311142 alpha_bar_prev: 0.056906670331954956
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.056906670331954956 alpha_bar_prev: 0.06328536570072174
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.06328536570072174 alpha_bar_prev: 0.07023751735687256
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07023751735687256 alpha_bar_prev: 0.07779666036367416
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7670, -0.8218, -0.8620, -0.8181, -0.7752, -0.7574, -0.7915, -0.7939],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 48, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.19603011 0.0654834  0.02930941 0.07057085 0.16634392 0.23756572
 0.12022812 0.11446847]
greedy resampling
resampled_idxs: [5 5 5 5 5 5 5 5]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.07779666036367416 alpha_bar_prev: 0.085996113717556
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.085996113717556 alpha_bar_prev: 0.09486869722604752
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.09486869722604752 alpha_bar_prev: 0.1044464036822319
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1044464036822319 alpha_bar_prev: 0.11476004123687744
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.11476004123687744 alpha_bar_prev: 0.12583883106708527
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.12583883106708527 alpha_bar_prev: 0.13771003484725952
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.13771003484725952 alpha_bar_prev: 0.15039856731891632
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.15039856731891632 alpha_bar_prev: 0.16392646729946136
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.7497, -0.7659, -0.7247, -0.7589, -0.6654, -0.7794, -0.6656, -0.6542],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 56, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0448906  0.03248846 0.07397412 0.03736495 0.24228759 0.02479191
 0.2411451  0.30305728]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.16392646729946136 alpha_bar_prev: 0.17831258475780487
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.17831258475780487 alpha_bar_prev: 0.1935720145702362
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.1935720145702362 alpha_bar_prev: 0.20971570909023285
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.20971570909023285 alpha_bar_prev: 0.22675004601478577
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.22675004601478577 alpha_bar_prev: 0.2446763664484024
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2446763664484024 alpha_bar_prev: 0.2634905278682709
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2634905278682709 alpha_bar_prev: 0.2831825911998749
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.2831825911998749 alpha_bar_prev: 0.3037363588809967
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6814, -0.6249, -0.6557, -0.6891, -0.6493, -0.6699, -0.6998, -0.6225],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 64, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07283362 0.22545881 0.12196033 0.06250798 0.13844342 0.09171911
 0.05039947 0.23667725]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3037363588809967 alpha_bar_prev: 0.3251291811466217
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3251291811466217 alpha_bar_prev: 0.3473314940929413
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.3473314940929413 alpha_bar_prev: 0.37030673027038574
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.37030673027038574 alpha_bar_prev: 0.39401111006736755
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.39401111006736755 alpha_bar_prev: 0.4183935225009918
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4183935225009918 alpha_bar_prev: 0.4433954060077667
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4433954060077667 alpha_bar_prev: 0.46895086765289307
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.46895086765289307 alpha_bar_prev: 0.4949868321418762
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6216, -0.6428, -0.7139, -0.6290, -0.6377, -0.6739, -0.6871, -0.6447],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 72, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.21497757 0.14070726 0.03395867 0.1855779  0.15578572 0.07558283
 0.05803415 0.1353759 ]
greedy resampling
resampled_idxs: [0 0 0 0 0 0 0 0]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.4949868321418762 alpha_bar_prev: 0.5214230418205261
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5214230418205261 alpha_bar_prev: 0.5481724739074707
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5481724739074707 alpha_bar_prev: 0.5751417875289917
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.5751417875289917 alpha_bar_prev: 0.6022314429283142
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6022314429283142 alpha_bar_prev: 0.629336416721344
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.629336416721344 alpha_bar_prev: 0.6563469767570496
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6563469767570496 alpha_bar_prev: 0.6831490397453308
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.6831490397453308 alpha_bar_prev: 0.7096250653266907
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6582, -0.6433, -0.6307, -0.6701, -0.5961, -0.6779, -0.6163, -0.6214],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 80, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.0745675  0.10053733 0.1292523  0.05881873 0.25812305 0.05029731
 0.17260692 0.15579685]
greedy resampling
resampled_idxs: [4 4 4 4 4 4 4 4]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7096250653266907 alpha_bar_prev: 0.7356548309326172
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7356548309326172 alpha_bar_prev: 0.7611164450645447
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7611164450645447 alpha_bar_prev: 0.7858870029449463
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.7858870029449463 alpha_bar_prev: 0.8098439574241638
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8098439574241638 alpha_bar_prev: 0.8328656554222107
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8328656554222107 alpha_bar_prev: 0.854832649230957
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.854832649230957 alpha_bar_prev: 0.875628650188446
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.875628650188446 alpha_bar_prev: 0.8951416015625
using sigma in the main loop
reward_name: adaface, curr_reward: tensor([-0.6356, -0.6242, -0.6078, -0.6046, -0.6045, -0.6045, -0.6350, -0.5965],
       device='cuda:0'), curr_scale: 1
group_size: 8, resample_rate: 8
step: 88, resample_rate: 8, divides evenly: True
at the right step so resampling
p: [0.07817921 0.09820184 0.13653814 0.14541606 0.14567683 0.14573449
 0.07912977 0.17112366]
greedy resampling
resampled_idxs: [7 7 7 7 7 7 7 7]
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.8951416015625 alpha_bar_prev: 0.9132644534111023
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9132644534111023 alpha_bar_prev: 0.9298965334892273
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9298965334892273 alpha_bar_prev: 0.9449440836906433
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9449440836906433 alpha_bar_prev: 0.9583213925361633
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9583213925361633 alpha_bar_prev: 0.9699515104293823
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9699515104293823 alpha_bar_prev: 0.9797669053077698
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9797669053077698 alpha_bar_prev: 0.9877104163169861
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9877104163169861 alpha_bar_prev: 0.9937354326248169
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9937354326248169 alpha_bar_prev: 0.9978065490722656
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9978065490722656 alpha_bar_prev: 0.9998999834060669
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
in main loop alpha_bar: 0.9998999834060669 alpha_bar_prev: 1.0
using sigma in the main loop
measurement torch.Size([1, 3, 256, 256])
x_0_hat torch.Size([8, 3, 256, 256])
difference torch.Size([8, 3, 256, 256])
difference_vec torch.Size([8, 196608])
norm torch.Size([8])
norm_grad torch.Size([8, 3, 256, 256])
taking gradients
num_groups:  1
num_particles:  8
reshaped img:  torch.Size([1, 8, 3, 256, 256])
final_rewards:  torch.Size([1, 8])
best_img:  torch.Size([1, 3, 256, 256])
sample shape: torch.Size([1, 8, 3, 256, 256])
best_sample shape: torch.Size([1, 3, 256, 256])
x0_flatten torch.Size([1, 3, 256, 256])
x_flatten torch.Size([1, 3, 256, 256])
broadcasted_shape torch.Size([1, 1, 3, 256, 256])
z_tilde shape: torch.Size([1, 512])
key: psnr
value: 29.480
key: ssim
value: 0.866
key: lpips
value: 0.102
key: facenet_l2
value: 0.326
key: adaface_l2
value: 0.608
